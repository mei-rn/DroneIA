{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "bBX0zw6KLQGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6WTp0fe_6KhH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining constants"
      ],
      "metadata": {
        "id": "nsm1FtoqLXmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STATE_SIZE = (10,10)\n",
        "ACTION_SIZE = 4"
      ],
      "metadata": {
        "id": "Fy8GkK8y6suf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining loading and saving of files"
      ],
      "metadata": {
        "id": "78prn4sdLunY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "Zmz1j9eb7gA7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(filename, Q_table):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(Q_table, f)"
      ],
      "metadata": {
        "id": "NqD37L7z7lC0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the static environment\n",
        "\n"
      ],
      "metadata": {
        "id": "CAxlCYl7LcDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneGrid():\n",
        "\n",
        "    def __init__(self, grid):\n",
        "\n",
        "        self.grid = grid\n",
        "        self.empty_grid = grid\n",
        "        self.grid_size = np.array(grid).shape\n",
        "        self.observation_space = (self.grid_size[0]), (self.grid_size[1])\n",
        "        self.action_space = [0, 1, 2, 3] # 4 discrete actions: 0 = up, 1 = down, 2 = left, 3 = right\n",
        "        self.start_pos = (0, 0)  # Starting position at top left corner\n",
        "        self.goal_pos = (self.grid_size[0] - 1, self.grid_size[1] - 1)  # Goal position at bottom right corner\n",
        "        self.current_pos = self.start_pos  # Initialize current position\n",
        "        self.grid[self.current_pos[1]][self.current_pos[0]] = 3\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_pos = self.start_pos  # Reset current position to start position\n",
        "        self.grid = self.empty_grid\n",
        "        return self.current_pos, self.grid  # Return initial state\n"
      ],
      "metadata": {
        "id": "TS8ylwsB6w8c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLEnvironment(DroneGrid):\n",
        "    def __init__(self, grid):\n",
        "        super().__init__(grid)\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        assert action in self.action_space, f\"Invalid action {action}\"  # Check if action is valid\n",
        "\n",
        "        # Define movement based on action\n",
        "        if action == 0:  # Up\n",
        "            new_pos = (self.current_pos[0], self.current_pos[1] - 1)\n",
        "        elif action == 1:  # Down\n",
        "            new_pos = (self.current_pos[0], self.current_pos[1] + 1)\n",
        "        elif action == 2:  # Left\n",
        "            new_pos = (self.current_pos[0] - 1, self.current_pos[1])\n",
        "        elif action == 3:  # Right\n",
        "            new_pos = (self.current_pos[0] + 1, self.current_pos[1])\n",
        "\n",
        "        # Check if new position is within bounds and not an obstacle\n",
        "        if 0 <= new_pos[0] < self.grid_size[0] and 0 <= new_pos[1] < self.grid_size[1] and self.grid[new_pos[1]][new_pos[0]] != 1:\n",
        "\n",
        "            self.current_pos = new_pos  # Update current position\n",
        "            self.grid = self.empty_grid # Erase previous position of the drone\n",
        "\n",
        "            # Check if goal state is reached\n",
        "            done = (self.current_pos == self.goal_pos)\n",
        "\n",
        "            # Calculate reward\n",
        "            if done:\n",
        "                reward = 1.0  # Positive reward for reaching the goal\n",
        "\n",
        "            else:\n",
        "                reward = 0 #Negative reward for non-goal state\n",
        "                self.grid[new_pos[1]][new_pos[0]] = 3 # Update new position of the drone\n",
        "\n",
        "\n",
        "        elif 0 <= new_pos[0] < self.grid_size[0] and 0 <= new_pos[1] < self.grid_size[1] and self.grid[new_pos[1]][new_pos[0]] == 1:\n",
        "                done = False\n",
        "                reward = 0 # Negative reward for going in a wall\n",
        "\n",
        "\n",
        "        else:\n",
        "            done = False\n",
        "            reward = 0  # Negative reward for going out of bounds\n",
        "\n",
        "        return self.current_pos, self.grid, reward, done"
      ],
      "metadata": {
        "id": "kjRZ2jnusiED"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute an action in function of the epsilon-greedy algorith"
      ],
      "metadata": {
        "id": "INRXclRKfUL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_action(current_state, Q_table, epsilon, environment):\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "        return np.random.choice(range(len(environment.action_space)))\n",
        "\n",
        "    else:\n",
        "        return np.argmax(Q_table[current_state])"
      ],
      "metadata": {
        "id": "jggC9KIOffdR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a personalized map"
      ],
      "metadata": {
        "id": "trQ9r7NkL3lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_simple = load('map_simple.pkl')\n",
        "print(map_simple)\n",
        "\n",
        "map_mid = load('map_mid.pkl')\n",
        "print(map_mid)\n",
        "\n",
        "map_hard = load('map_hard.pkl')\n",
        "print(map_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JQF9q-v-AQI",
        "outputId": "6e517014-ad1f-4412-98ef-ffc201beaf6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an instance of the environment through the loaded map"
      ],
      "metadata": {
        "id": "NUWCssuaL9Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "environment_simple = QLEnvironment(map_simple)\n",
        "print(environment_simple.observation_space)\n",
        "print(environment_simple.action_space)\n",
        "\n",
        "environment_mid = QLEnvironment(map_mid)\n",
        "print(environment_mid.observation_space)\n",
        "print(environment_mid.action_space)\n",
        "\n",
        "environment_hard = QLEnvironment(map_hard)\n",
        "print(environment_hard.observation_space)\n",
        "print(environment_hard.action_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRYMCmkS-eqB",
        "outputId": "7915b3da-d8f9-435c-b92b-f277b9a4673f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 10)\n",
            "[0, 1, 2, 3]\n",
            "(10, 10)\n",
            "[0, 1, 2, 3]\n",
            "(10, 10)\n",
            "[0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Q-Learning\n",
        "---\n"
      ],
      "metadata": {
        "id": "ha7rhcl9BUpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_learning(env, alpha=0.9, gamma=0.9,  epsilon=0.99, epsilon_decay=0.0001, episodes = 10000, max_iter_episode = 100):\n",
        "\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state in function of the epsilon_greedy\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) #Send your action to OpenAI and get back the tuple\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0]\n",
        "\n",
        "            total_reward += reward #Increment your reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma * np.max(Q[state_tp1_index]) - Q[current_state_index][action])\n",
        "\n",
        "             #Make sure to keep random at 10%\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "                break\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "\n",
        "        if epsilon>0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "        #rewards.append(total_reward)\n",
        "\n",
        "    return Q, rewards"
      ],
      "metadata": {
        "id": "513kKA3J7CLh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of the Q-Learning and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "fqBNpVXhMDGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_simple, _ = q_learning(environment_simple, epsilon_decay = 0.0005, episodes = 5000)\n",
        "save('Simple - Q-Learning.pkl', q_simple)\n",
        "\n",
        "q_mid, _ = q_learning(environment_mid, episodes = 3000, epsilon_decay = 0.0003, max_iter_episode = 200)\n",
        "save('Mid - Q-Learning.pkl', q_mid)\n",
        "\n",
        "q_hard, _ = q_learning(environment_hard, episodes = 5000, epsilon_decay = 0.0001, max_iter_episode = 300)\n",
        "save('Hard - Q-Learning.pkl', q_hard)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ybGupCf-PAW",
        "outputId": "53c50df4-d545-48a8-a9e8-606c14003d4f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.604, Epsilon: 0.6004653531155191\n",
            "Episode: 2000, Mean reward: 0.998, Epsilon: 0.36420064675974256\n",
            "Episode: 3000, Mean reward: 1.0, Epsilon: 0.220898858546959\n",
            "Episode: 4000, Mean reward: 1.0, Epsilon: 0.1339819304042573\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.755, Epsilon: 0.7334100384749153\n",
            "Episode: 2000, Mean reward: 1.0, Epsilon: 0.5433235197331082\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.154, Epsilon: 0.8957890438555989\n",
            "Episode: 2000, Mean reward: 0.727, Epsilon: 0.810543445547201\n",
            "Episode: 3000, Mean reward: 0.985, Epsilon: 0.7334100384749007\n",
            "Episode: 4000, Mean reward: 1.0, Epsilon: 0.663616845575281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - Q-Learning.pkl')\n",
        "files.download('Mid - Q-Learning.pkl')\n",
        "files.download('Hard - Q-Learning.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tj708eRQB6r-",
        "outputId": "691c872e-8324-4390-be59-14bdebd0e7d8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49a7a4a8-4c16-4455-a393-f200f353e5e3\", \"Simple - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d09bf906-d189-430e-8d3d-5a2590ed8e89\", \"Mid - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e678199-a074-41f6-a8a9-292b2f69e586\", \"Hard - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Q-Learning trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "9xF7_Sc3K9AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_q_simple = load('Simple - Q-Learning.pkl')\n",
        "print('simple', trained_q_simple)\n",
        "\n",
        "#trained_q_mid = load('Mid - Q-Learning.pkl')\n",
        "#print('mid', trained_q_mid)\n",
        "\n",
        "#trained_q_hard = load('Hard - Q-Learning.pkl')\n",
        "#print('hard', trained_q_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WSOe6ObK73i",
        "outputId": "0af407a9-34ce-4f7d-b460-d16b5086684f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple [[0.15009463 0.16677181 0.15009463 0.16677181]\n",
            " [0.16677181 0.18530202 0.15009463 0.18530202]\n",
            " [0.18530202 0.20589113 0.16677181 0.20589113]\n",
            " [0.20589113 0.22876792 0.18530202 0.22876792]\n",
            " [0.22876792 0.25418657 0.20589113 0.25418657]\n",
            " [0.25418657 0.28242952 0.22876792 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.3138106  0.34867844 0.3138106  0.34867844]\n",
            " [0.34867844 0.38742048 0.3138106  0.38742048]\n",
            " [0.38742048 0.4304672  0.34867844 0.38742048]\n",
            " [0.15009463 0.18530202 0.16677181 0.18530202]\n",
            " [0.16677181 0.20589113 0.16677181 0.20589113]\n",
            " [0.18530202 0.20589113 0.18530202 0.22876792]\n",
            " [0.20589113 0.22876792 0.20589113 0.25418657]\n",
            " [0.22876792 0.28242952 0.22876792 0.28242952]\n",
            " [0.25418657 0.3138106  0.25418657 0.3138106 ]\n",
            " [0.3138106  0.34867844 0.28242952 0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.4304672 ]\n",
            " [0.16677181 0.20589113 0.18530202 0.20589113]\n",
            " [0.18530202 0.22876792 0.18530202 0.20589113]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25418657 0.3138106  0.28242952 0.3138106 ]\n",
            " [0.28242952 0.34867844 0.28242952 0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.47829688]\n",
            " [0.4304672  0.531441   0.4304672  0.47829688]\n",
            " [0.18530202 0.22876792 0.20589113 0.22876792]\n",
            " [0.20589113 0.25418657 0.20589113 0.22876792]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28242952 0.34867844 0.3138106  0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.47829688]\n",
            " [0.4304672  0.531441   0.4304672  0.531441  ]\n",
            " [0.47829688 0.59049    0.47829688 0.531441  ]\n",
            " [0.20589113 0.25418657 0.22876792 0.25418657]\n",
            " [0.22876792 0.28242952 0.22876792 0.28242952]\n",
            " [0.28242952 0.3138106  0.25418657 0.3138106 ]\n",
            " [0.3138106  0.34867844 0.28242952 0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.38742048 0.34867844 0.4304672 ]\n",
            " [0.38742048 0.4304672  0.38742048 0.47829688]\n",
            " [0.4304672  0.531441   0.4304672  0.531441  ]\n",
            " [0.47829688 0.59049    0.47829688 0.59049   ]\n",
            " [0.531441   0.6561     0.531441   0.59049   ]\n",
            " [0.22876792 0.25418657 0.25418657 0.28242952]\n",
            " [0.25418657 0.3138106  0.25418657 0.3138106 ]\n",
            " [0.28242952 0.34867844 0.28242952 0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.38742048]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.47829688 0.59049    0.531441   0.59049   ]\n",
            " [0.531441   0.6561     0.531441   0.6561    ]\n",
            " [0.59049    0.729      0.59049    0.6561    ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28242952 0.34867844 0.3138106  0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.4304672 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.531441   0.6561     0.59049    0.6561    ]\n",
            " [0.59049    0.729      0.59049    0.729     ]\n",
            " [0.6561     0.81       0.6561     0.729     ]\n",
            " [0.3138106  0.34867844 0.3138106  0.34867844]\n",
            " [0.3138106  0.38742048 0.3138106  0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.47829688]\n",
            " [0.4304672  0.531441   0.4304672  0.531441  ]\n",
            " [0.531441   0.59049    0.47829688 0.59049   ]\n",
            " [0.59049    0.6561     0.531441   0.6561    ]\n",
            " [0.59049    0.729      0.59049    0.729     ]\n",
            " [0.6561     0.81       0.6561     0.81      ]\n",
            " [0.729      0.9        0.729      0.81      ]\n",
            " [0.3138106  0.38742048 0.34867844 0.38742048]\n",
            " [0.34867844 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.38742048 0.47829688 0.38742048 0.47829688]\n",
            " [0.4304672  0.531441   0.4304672  0.531441  ]\n",
            " [0.47829688 0.59049    0.47829688 0.59049   ]\n",
            " [0.531441   0.6561     0.531441   0.6561    ]\n",
            " [0.59049    0.729      0.59049    0.729     ]\n",
            " [0.6561     0.81       0.6561     0.81      ]\n",
            " [0.729      0.9        0.729      0.9       ]\n",
            " [0.81       1.         0.81       0.9       ]\n",
            " [0.34867844 0.38742048 0.38742048 0.4304672 ]\n",
            " [0.38742048 0.4304672  0.38742048 0.47829688]\n",
            " [0.4304672  0.47829688 0.4304672  0.531441  ]\n",
            " [0.47829688 0.531441   0.47829688 0.59049   ]\n",
            " [0.531441   0.59049    0.531441   0.6561    ]\n",
            " [0.59049    0.6561     0.59049    0.729     ]\n",
            " [0.6561     0.729      0.6561     0.81      ]\n",
            " [0.729      0.81       0.729      0.9       ]\n",
            " [0.81       0.9        0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# SARSA\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "awOMcLSaLO6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sarsa(env, alpha=0.8, gamma=0.9,  epsilon=0.99, epsilon_decay=0.0005, episodes = 2000, max_iter_episode = 100):\n",
        "\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state using Q-Table\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) # Send the action to the environment and obtain the new position, the reward and the termination flag\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0] # Compute the index of the state at t+1\n",
        "            action_tp1 = compute_action(state_tp1_index, Q, epsilon, env) # Compute the action for the next state using Q-Table\n",
        "\n",
        "            total_reward += reward # Increment the reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma*Q[state_tp1_index][action_tp1] - Q[current_state_index][action])\n",
        "\n",
        "             #Make sure to keep random at 10%\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "        if epsilon > 0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "    return Q, rewards"
      ],
      "metadata": {
        "id": "TbhauTm8Qx5q"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of SARSA and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "6GIdo4_LQ7es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_simple, _ = sarsa(environment_simple, epsilon_decay = 0.0002, episodes = 5001, gamma  = 0.99)\n",
        "save('Simple - SARSA.pkl', s_simple)\n",
        "\n",
        "s_mid, _ = sarsa(environment_mid, epsilon_decay = 0.0001, episodes = 6001, gamma = 0.99, max_iter_episode = 200)\n",
        "save('Mid - SARSA.pkl', s_mid)\n",
        "\n",
        "s_hard, _ = sarsa(environment_hard, epsilon_decay = 0.00005, episodes = 8000, max_iter_episode = 300)\n",
        "save('Hard - SARSA.pkl', s_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnzk9PyvRYN3",
        "outputId": "557b0bb2-c31e-4b6b-92b5-ebbdd2c2df0c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.164, Epsilon: 0.8105434455472116\n",
            "Episode: 2000, Mean reward: 0.553, Epsilon: 0.663616845575298\n",
            "Episode: 3000, Mean reward: 0.854, Epsilon: 0.5433235197331054\n",
            "Episode: 4000, Mean reward: 0.961, Epsilon: 0.44483567447607075\n",
            "Episode: 5000, Mean reward: 0.994, Epsilon: 0.3642006467597492\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.347, Epsilon: 0.8957890438555989\n",
            "Episode: 2000, Mean reward: 0.669, Epsilon: 0.810543445547201\n",
            "Episode: 3000, Mean reward: 0.892, Epsilon: 0.7334100384749007\n",
            "Episode: 4000, Mean reward: 0.972, Epsilon: 0.663616845575281\n",
            "Episode: 5000, Mean reward: 0.994, Epsilon: 0.6004653531155044\n",
            "Episode: 6000, Mean reward: 0.998, Epsilon: 0.5433235197330827\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.007, Epsilon: 0.9417171302556689\n",
            "Episode: 2000, Mean reward: 0.022, Epsilon: 0.8957890438555278\n",
            "Episode: 3000, Mean reward: 0.318, Epsilon: 0.8521008966607033\n",
            "Episode: 4000, Mean reward: 0.52, Epsilon: 0.8105434455470705\n",
            "Episode: 5000, Mean reward: 0.74, Epsilon: 0.7710127752405335\n",
            "Episode: 6000, Mean reward: 0.853, Epsilon: 0.733410038474721\n",
            "Episode: 7000, Mean reward: 0.928, Epsilon: 0.6976412088213267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading SARSA trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "_r3rgdWRRgJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_s_simple = load('Simple - SARSA.pkl')\n",
        "print('simple', trained_s_simple)\n",
        "\n",
        "trained_s_mid = load('Mid - SARSA.pkl')\n",
        "print('mid', trained_s_mid)\n",
        "\n",
        "trained_s_hard = load('Hard - SARSA.pkl')\n",
        "print('hard',trained_s_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8usIp5HRq7K",
        "outputId": "eebbf624-3bf6-4769-e947-08c2a758bf24"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple [[0.6651668  0.6711016  0.67648506 0.64353186]\n",
            " [0.6702843  0.64424086 0.67784745 0.6598697 ]\n",
            " [0.65125084 0.65126467 0.65766484 0.6592029 ]\n",
            " [0.6315701  0.57606083 0.676229   0.56586254]\n",
            " [0.57473755 0.56312364 0.5674773  0.5678167 ]\n",
            " [0.57005876 0.5755015  0.5760961  0.5717389 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.44950172 0.4538672  0.4491796  0.61958146]\n",
            " [0.44380555 0.6367181  0.59559745 0.38081813]\n",
            " [0.48307768 0.512017   0.5663717  0.47522688]\n",
            " [0.6724536  0.673248   0.6740694  0.639313  ]\n",
            " [0.65860957 0.6983793  0.6567824  0.640837  ]\n",
            " [0.64522696 0.6479361  0.66133153 0.65385205]\n",
            " [0.5605307  0.6585772  0.66888285 0.5903315 ]\n",
            " [0.5926953  0.5795789  0.5403397  0.57996655]\n",
            " [0.5748859  0.6450872  0.5469083  0.581073  ]\n",
            " [0.58726645 0.57270694 0.55600363 0.566109  ]\n",
            " [0.44942838 0.70069796 0.67445165 0.53893965]\n",
            " [0.617715   0.74383557 0.5103356  0.6438113 ]\n",
            " [0.4841985  0.5155457  0.60856074 0.5131288 ]\n",
            " [0.66850656 0.77620876 0.6757953  0.7007479 ]\n",
            " [0.67038643 0.67534053 0.7142488  0.6681072 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.55693644 0.6798278  0.5769968  0.55871594]\n",
            " [0.5436973  0.67532796 0.56835985 0.6655021 ]\n",
            " [0.6805608  0.6634694  0.55221945 0.6902268 ]\n",
            " [0.5261238  0.8396321  0.6804515  0.71303916]\n",
            " [0.5088226  0.68738633 0.79274666 0.57502455]\n",
            " [0.59695584 0.5934875  0.68435544 0.57289   ]\n",
            " [0.6743873  0.7209018  0.7134669  0.7201722 ]\n",
            " [0.6799375  0.76724535 0.7145714  0.7306993 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.57887256 0.7732793  0.6786048  0.75038433]\n",
            " [0.6640174  0.75828344 0.67714536 0.7554175 ]\n",
            " [0.716443   0.7578387  0.76236874 0.75352323]\n",
            " [0.72193503 0.81421787 0.74134177 0.7978364 ]\n",
            " [0.7332297  0.77751166 0.81392795 0.5726519 ]\n",
            " [0.5794806  0.61463267 0.7788645  0.60287935]\n",
            " [0.71556365 0.75595057 0.71182066 0.7845916 ]\n",
            " [0.7569759  0.7558401  0.7713504  0.75258446]\n",
            " [0.7571281  0.76304895 0.7563339  0.75765705]\n",
            " [0.7464457  0.770656   0.7641577  0.7588454 ]\n",
            " [0.6070664  0.7782386  0.75546235 0.7605255 ]\n",
            " [0.7544761  0.7589549  0.76158726 0.7500046 ]\n",
            " [0.71214914 0.75937474 0.7622217  0.7607099 ]\n",
            " [0.73847204 0.8194873  0.7061083  0.90683246]\n",
            " [0.60698116 0.8920081  0.84085244 0.65024805]\n",
            " [0.6023667  0.8675128  0.844768   0.6998118 ]\n",
            " [0.7752724  0.7661012  0.77807045 0.7572998 ]\n",
            " [0.77544636 0.7543952  0.7460461  0.7918056 ]\n",
            " [0.7694897  0.83699316 0.7551554  0.76565933]\n",
            " [0.76671994 0.8454738  0.76537377 0.7668759 ]\n",
            " [0.7552456  0.77356696 0.7717289  0.7690495 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.8250035  0.91605437 0.84512436 0.82444435]\n",
            " [0.65170133 0.9001731  0.8403183  0.8680766 ]\n",
            " [0.8048335  0.8731379  0.8732186  0.87240994]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.7468546  0.7373     0.7455258  0.8365994 ]\n",
            " [0.8146189  0.8118159  0.74568534 0.8468289 ]\n",
            " [0.77668303 0.85388243 0.8209315  0.7697518 ]\n",
            " [0.77210695 0.8602691  0.7736719  0.7810916 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.88927406 0.90955734 0.8649223  0.93848294]\n",
            " [0.8988769  0.9027394  0.8733091  0.91312337]\n",
            " [0.86963713 0.9686953  0.9195022  0.8744004 ]\n",
            " [0.7431435  0.7447869  0.76884174 0.8036341 ]\n",
            " [0.7781268  0.74821603 0.7415065  0.80107224]\n",
            " [0.8135792  0.79527426 0.8104358  0.8586002 ]\n",
            " [0.8317851  0.82626855 0.8134588  0.8644578 ]\n",
            " [0.79452235 0.8215215  0.85757875 0.90116113]\n",
            " [0.8741393  0.9122095  0.82784194 0.879041  ]\n",
            " [0.8758071  0.8634014  0.8808594  0.8628064 ]\n",
            " [0.87544763 0.94938594 0.8866598  0.90148824]\n",
            " [0.9182941  0.9787805  0.93222475 0.8997117 ]\n",
            " [0.9341174  0.9812689  0.8926615  0.8967106 ]\n",
            " [0.7482278  0.7498166  0.74635035 0.75280076]\n",
            " [0.7543437  0.7500431  0.745724   0.8139978 ]\n",
            " [0.7959328  0.8104434  0.7907609  0.81571573]\n",
            " [0.8705674  0.87566984 0.82129407 0.89063513]\n",
            " [0.87537146 0.88904965 0.88092667 0.9282462 ]\n",
            " [0.83815545 0.88696796 0.88373    0.916843  ]\n",
            " [0.8647237  0.96089333 0.9185477  0.9129712 ]\n",
            " [0.93629974 0.9651591  0.9209069  0.94976896]\n",
            " [0.9517807  0.9899868  0.9562572  0.9450057 ]\n",
            " [0.9337626  1.         0.943189   0.9820742 ]\n",
            " [0.74789894 0.75558734 0.756269   0.7577757 ]\n",
            " [0.744989   0.75766724 0.8228483  0.80820864]\n",
            " [0.8117731  0.8066204  0.81561637 0.8190248 ]\n",
            " [0.8767286  0.87026113 0.81534016 0.905252  ]\n",
            " [0.9045394  0.89838886 0.8950729  0.9203356 ]\n",
            " [0.8877867  0.91533226 0.8741253  0.9661781 ]\n",
            " [0.89413774 0.9038539  0.94597566 0.9658372 ]\n",
            " [0.95481193 0.9670017  0.94152397 0.9872072 ]\n",
            " [0.98000336 0.9853076  0.97501755 1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "mid [[0.54048043 0.544925   0.57711345 0.6464662 ]\n",
            " [0.5406916  0.59115463 0.54126704 0.66651416]\n",
            " [0.636787   0.67172223 0.54166067 0.6354768 ]\n",
            " [0.56586015 0.58906335 0.6223296  0.65345603]\n",
            " [0.58461326 0.6422708  0.58613914 0.5830624 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.65483916 0.68322605 0.67879736 0.6790746 ]\n",
            " [0.6813942  0.6785209  0.67526275 0.684993  ]\n",
            " [0.6105711  0.70292866 0.6766965  0.6038149 ]\n",
            " [0.54447436 0.5504912  0.5606765  0.575209  ]\n",
            " [0.58697855 0.57563657 0.5620432  0.5755596 ]\n",
            " [0.6451576  0.6687629  0.5709559  0.65649384]\n",
            " [0.566732   0.66179246 0.6424615  0.6250954 ]\n",
            " [0.6216404  0.7060388  0.6959765  0.6535445 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6752399  0.6888549  0.6841279  0.67695814]\n",
            " [0.68226105 0.8001835  0.6756328  0.6876515 ]\n",
            " [0.69158    0.7469622  0.6723757  0.7046963 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.66074514 0.6533901  0.6731366  0.67211026]\n",
            " [0.6669262  0.62546337 0.66663444 0.64409304]\n",
            " [0.67965615 0.6735104  0.6433474  0.72189325]\n",
            " [0.72868603 0.729772   0.7127354  0.72328305]\n",
            " [0.72774255 0.7030412  0.7146628  0.68905234]\n",
            " [0.6796646  0.7660252  0.7544301  0.758113  ]\n",
            " [0.7641684  0.8624959  0.76016206 0.80761796]\n",
            " [0.7499048  0.8268816  0.8044214  0.7716186 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6561206  0.6770173  0.6516384  0.6581832 ]\n",
            " [0.6742989  0.66890126 0.66245157 0.6291811 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.75016195 0.6940892  0.731894   0.7462089 ]\n",
            " [0.75366706 0.80396986 0.75189376 0.76573676]\n",
            " [0.79600406 0.8187863  0.74245155 0.8550532 ]\n",
            " [0.75807804 0.89545274 0.7991458  0.85904133]\n",
            " [0.6334469  0.6332442  0.6351148  0.6613394 ]\n",
            " [0.65320325 0.6523637  0.65288043 0.6628639 ]\n",
            " [0.6639175  0.6353052  0.65942985 0.67568266]\n",
            " [0.6698423  0.73596543 0.6542331  0.6530622 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.696487   0.7237866  0.70154446 0.7923921 ]\n",
            " [0.7619624  0.8037343  0.6936752  0.84428334]\n",
            " [0.7541646  0.7931258  0.8029418  0.8699774 ]\n",
            " [0.8579352  0.8665331  0.8447259  0.8487185 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6836092  0.6277624  0.664524   0.69333136]\n",
            " [0.6769085  0.6825667  0.66628873 0.80307925]\n",
            " [0.81351995 0.81191885 0.7592883  0.7157987 ]\n",
            " [0.7845186  0.8443514  0.7980937  0.6960669 ]\n",
            " [0.69747037 0.7980014  0.7382692  0.7848602 ]\n",
            " [0.8116291  0.80217576 0.85660255 0.8042539 ]\n",
            " [0.85394293 0.8029985  0.78635836 0.9183457 ]\n",
            " [0.8559336  0.91203487 0.8621332  0.8508727 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6946279  0.6103017  0.6826955  0.6570788 ]\n",
            " [0.695536   0.774591   0.66831994 0.7856857 ]\n",
            " [0.7781202  0.7940049  0.7780577  0.78847647]\n",
            " [0.7848558  0.84944    0.7672061  0.82761174]\n",
            " [0.79581773 0.80554    0.82818586 0.835714  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.88681537 0.9297515  0.86450934 0.87185204]\n",
            " [0.54785365 0.58909714 0.5453242  0.6564681 ]\n",
            " [0.59398174 0.59350157 0.55555207 0.6285932 ]\n",
            " [0.61973965 0.62120855 0.6021419  0.68072224]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.80819076 0.8491814  0.890367   0.81176335]\n",
            " [0.7960161  0.8700585  0.8816691  0.8812979 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.8783136  0.95809275 0.884251   0.88338673]\n",
            " [0.5492039  0.5729168  0.571638   0.6607357 ]\n",
            " [0.5793677  0.6112281  0.55254364 0.61624163]\n",
            " [0.6327715  0.61930746 0.6023819  0.6731017 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.8533338  0.8808151  0.89072365 0.8896389 ]\n",
            " [0.8908834  0.8782531  0.89574784 0.86915046]\n",
            " [0.91227126 0.89782137 0.85890406 0.97913945]\n",
            " [0.976056   0.9440913  0.952544   0.9738224 ]\n",
            " [0.9262195  1.         0.9750601  0.983972  ]\n",
            " [0.5522807  0.5498371  0.5470128  0.79113096]\n",
            " [0.57111096 0.7671786  0.5428811  0.83502066]\n",
            " [0.68000567 0.60533744 0.69273454 0.83258367]\n",
            " [0.86430955 0.8739625  0.830664   0.8751576 ]\n",
            " [0.84735525 0.8729839  0.8061489  0.87440044]\n",
            " [0.89014477 0.8791377  0.87517947 0.8754058 ]\n",
            " [0.8913874  0.91918147 0.8770994  0.9076112 ]\n",
            " [0.9009818  0.9075421  0.90765685 0.92972744]\n",
            " [0.9420975  0.9875991  0.91293895 1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "hard [[3.0115554e-05 3.1855878e-05 3.3473323e-05 2.9239789e-05]\n",
            " [3.1075560e-05 3.1676434e-05 2.7835675e-05 3.2261505e-05]\n",
            " [3.3139313e-05 3.1996999e-05 3.5817455e-05 3.0485613e-05]\n",
            " [2.8968769e-05 3.8701492e-05 3.3497025e-05 3.0155035e-05]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.8425653e-04 4.0355776e-04 9.2622606e-05 1.4715637e-04]\n",
            " [1.4239343e-04 1.4310476e-04 1.2662991e-04 1.6508499e-04]\n",
            " [1.4018459e-04 1.2648443e-04 1.4378935e-04 1.4987672e-04]\n",
            " [2.1091070e-04 2.6151031e-04 1.4642980e-04 1.6231554e-04]\n",
            " [3.5041841e-05 3.5362427e-05 3.2474600e-05 3.1307478e-05]\n",
            " [3.1527405e-05 4.2412557e-05 3.3132663e-05 4.1179715e-05]\n",
            " [3.5309782e-05 1.8665583e-04 3.7686234e-05 3.7672427e-05]\n",
            " [3.3746684e-05 4.4769378e-05 1.1776674e-04 3.2548229e-05]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.8329744e-04 4.3725083e-04 2.1460703e-04 2.4262727e-04]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.5937783e-04 6.6454482e-04 2.4540976e-04 1.8223285e-04]\n",
            " [3.9138547e-05 4.0851446e-05 4.0835563e-05 3.5398327e-05]\n",
            " [3.1533629e-05 4.9007347e-05 4.0983661e-05 1.8653828e-04]\n",
            " [3.2691467e-05 2.3121791e-04 3.1272506e-05 3.9312279e-05]\n",
            " [4.1267838e-05 4.5731686e-05 1.3437468e-04 1.7302453e-04]\n",
            " [7.2479692e-05 6.3528825e-04 4.1181553e-05 2.2923255e-04]\n",
            " [2.3960638e-04 2.3042008e-04 1.8611996e-04 2.5428610e-04]\n",
            " [1.2715894e-04 4.6630931e-04 1.8622460e-04 2.8114411e-04]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.7182222e-04 3.8326459e-04 2.7864953e-04 3.9660564e-04]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [3.4903456e-05 7.1272661e-05 6.9055939e-05 4.9397793e-05]\n",
            " [1.0615454e-04 2.4713378e-04 7.9820267e-05 1.8373813e-04]\n",
            " [2.2638323e-04 3.5741462e-04 1.7687783e-04 9.1319415e-04]\n",
            " [2.5358598e-04 3.4697066e-04 2.7699050e-04 6.1220245e-04]\n",
            " [4.6828922e-04 5.6422694e-04 4.7319513e-04 1.0619200e-03]\n",
            " [1.1092677e-03 8.8384305e-04 6.1848509e-04 2.6221745e-04]\n",
            " [1.3930933e-03 2.2438413e-04 1.2017109e-03 3.5897241e-04]\n",
            " [3.9957277e-04 4.6054155e-04 1.5354872e-03 1.7871181e-04]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [9.7799720e-04 3.4505569e-03 1.2384115e-03 6.0962047e-04]\n",
            " [4.9017841e-04 9.1009226e-04 5.0125457e-04 2.4513464e-04]\n",
            " [9.4153004e-04 1.2632416e-03 4.9577456e-04 4.1199036e-04]\n",
            " [6.1653857e-03 1.6895460e-02 6.1575496e-03 6.3561709e-03]\n",
            " [5.9139361e-03 5.4303263e-03 6.0363426e-03 4.9353149e-03]\n",
            " [4.7765262e-03 5.7185320e-03 5.3250943e-03 4.8989337e-03]\n",
            " [5.3191115e-03 6.2610582e-03 5.0751949e-03 6.4036846e-03]\n",
            " [2.3415133e-03 4.1298019e-03 5.3070867e-03 1.8304141e-03]\n",
            " [2.1110720e-03 2.8416442e-03 2.1599378e-03 2.4319247e-03]\n",
            " [2.4347203e-03 3.4878692e-03 5.0094025e-03 3.7922482e-03]\n",
            " [1.1987791e-03 1.1390779e-03 4.4920347e-03 2.1104869e-03]\n",
            " [1.6134268e-03 3.9285672e-04 3.4072709e-03 3.6444029e-04]\n",
            " [4.8213027e-04 3.8453317e-04 9.4538077e-04 5.7286420e-04]\n",
            " [6.3821436e-03 1.3167386e-02 4.8311730e-03 1.7459838e-02]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [6.3860137e-03 3.3786673e-02 2.9925056e-02 9.1232238e-03]\n",
            " [2.9470767e-03 9.6739195e-03 2.6394496e-02 6.3369381e-03]\n",
            " [4.2715049e-03 5.8921068e-03 3.7937784e-03 5.1766168e-03]\n",
            " [2.9834483e-03 4.6534026e-03 5.8375481e-03 3.6635373e-03]\n",
            " [2.2738127e-03 2.4001836e-03 5.3750155e-03 2.6302412e-03]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [5.2818018e-03 4.0632173e-02 7.7361660e-03 1.0916250e-02]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.3444407e-02 6.0465023e-02 4.1645497e-02 3.7456196e-02]\n",
            " [7.3724384e-03 9.8548960e-03 4.3061830e-02 1.0163491e-02]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [8.2081333e-03 1.4941301e-02 4.3388441e-02 2.5768219e-02]\n",
            " [4.3835364e-02 5.1561177e-02 2.1022238e-02 6.4054266e-02]\n",
            " [4.4491746e-02 5.9212189e-02 4.7622431e-02 4.0581852e-02]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.6459265e-01 2.2305188e-01 1.8076408e-01 3.9557549e-01]\n",
            " [3.5031202e-01 3.5106623e-01 2.1604420e-01 3.4571511e-01]\n",
            " [2.4595007e-01 3.9794096e-01 3.7075025e-01 7.5987470e-01]\n",
            " [6.3975757e-01 6.3807744e-01 2.3832376e-01 7.5553244e-01]\n",
            " [8.5439199e-01 1.0000000e+00 7.2765809e-01 7.2743082e-01]\n",
            " [1.5225360e-02 6.9064878e-02 6.5067343e-02 5.7647232e-02]\n",
            " [4.6340361e-02 2.0584157e-02 5.8532409e-02 4.7007348e-02]\n",
            " [6.1741725e-02 4.4805896e-02 5.6584567e-02 1.5783533e-01]\n",
            " [1.1599481e-01 9.6072234e-02 5.5097219e-02 2.0764700e-01]\n",
            " [2.1656930e-01 2.5555840e-01 8.4200233e-02 3.0741069e-01]\n",
            " [1.6485333e-01 3.4808609e-01 2.6381037e-01 4.6421626e-01]\n",
            " [3.5503367e-01 3.3463958e-01 3.4083086e-01 5.3768164e-01]\n",
            " [3.0479038e-01 5.3655398e-01 3.9668679e-01 8.8504499e-01]\n",
            " [2.8185573e-01 5.5101401e-01 3.6882785e-01 1.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - SARSA.pkl')\n",
        "files.download('Mid - SARSA.pkl')\n",
        "files.download('Hard - SARSA.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N2jNnqvmEh89",
        "outputId": "d663226c-82e6-427a-bcc8-7bc1280d3fe8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62485aae-1fdb-435e-9356-7130028fad2a\", \"Simple - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5da0250d-4dda-4409-ae23-c906c0b8ffad\", \"Mid - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e1605df-f375-4cc8-952a-1425b86a10e0\", \"Hard - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Alternating Q-Learning / SARSA\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7wHNHgF7R0Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alternating(env, alpha=1, gamma=0.9,  epsilon=1, epsilon_decay=0.005, episodes = 2000, max_iter_episode = 200):\n",
        "\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "\n",
        "            random_num = random.random() # Generate a random number between 0 and 1\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state using Q-Table\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) # Send the action to the environment and obtain the new position, the reward and the termination flag\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0] # Compute the index of the state at t+1\n",
        "            action_tp1 = compute_action(state_tp1_index, Q, epsilon, env) # Compute the action for the next state using Q-Table\n",
        "\n",
        "            total_reward += reward # Increment the reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            if (random_num <= 0.5): # We use Q-learning\n",
        "                Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma * np.max(Q[state_tp1_index]) - Q[current_state_index][action])\n",
        "\n",
        "            else: # We use SARSA\n",
        "                Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma*Q[state_tp1_index][action_tp1] - Q[current_state_index][action])\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "        if epsilon > 0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "    return Q, rewards"
      ],
      "metadata": {
        "id": "Fv7jMbGIR219"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of alternating Q-Learning/SARSA and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "n6YOUC1AccKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_simple, _ = alternating(environment_simple, epsilon_decay = 0.0003, episodes = 3001)\n",
        "save('Simple - Alternating.pkl', a_simple)\n",
        "\n",
        "a_mid, _ = alternating(environment_mid, epsilon_decay = 0.0003, episodes = 3001)\n",
        "save('Mid - Alternating.pkl', a_mid)\n",
        "\n",
        "a_hard, _ = alternating(environment_hard, epsilon_decay = 0.00008, episodes = 7001, max_iter_episode = 250)\n",
        "save('Hard - Alternating.pkl', a_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb-whO11ccrf",
        "outputId": "4c67114d-a494-4dfb-8d4f-4c44c48c3d50"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: 0.635, Epsilon: 0.7408182206817333\n",
            "Episode: 2000, Mean reward: 0.97, Epsilon: 0.5488116360940487\n",
            "Episode: 3000, Mean reward: 0.999, Epsilon: 0.40656965974062376\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: 0.557, Epsilon: 0.7408182206817333\n",
            "Episode: 2000, Mean reward: 0.957, Epsilon: 0.5488116360940487\n",
            "Episode: 3000, Mean reward: 0.998, Epsilon: 0.40656965974062376\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: 0.031, Epsilon: 0.9231163463866633\n",
            "Episode: 2000, Mean reward: 0.129, Epsilon: 0.8521437889662616\n",
            "Episode: 3000, Mean reward: 0.252, Epsilon: 0.7866278610666239\n",
            "Episode: 4000, Mean reward: 0.484, Epsilon: 0.7261490370737775\n",
            "Episode: 5000, Mean reward: 0.642, Epsilon: 0.6703200460357392\n",
            "Episode: 6000, Mean reward: 0.744, Epsilon: 0.6187833918062509\n",
            "Episode: 7000, Mean reward: 0.809, Epsilon: 0.5712090638489334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading alternating trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "SpPjMa9NceFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_a_simple = load('Simple - Alternating.pkl')\n",
        "print(trained_a_simple)\n",
        "\n",
        "trained_a_mid = load('Mid - Alternating.pkl')\n",
        "print(trained_a_mid)\n",
        "\n",
        "trained_a_hard = load('Hard - Alternating.pkl')\n",
        "print(trained_a_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzTcbx-cdPk",
        "outputId": "c92dd2cf-1157-49d1-85b8-134e9bd2eee1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.06461082 0.0717898  0.06461082 0.0717898 ]\n",
            " [0.0717898  0.06461082 0.07976644 0.07976644]\n",
            " [0.0717898  0.06461082 0.05814974 0.07976644]\n",
            " [0.09847709 0.05233477 0.08862938 0.10941899]\n",
            " [0.09847709 0.12157665 0.09847709 0.10941899]\n",
            " [0.12157665 0.18530202 0.09847709 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.16677181 0.22876792 0.25418657 0.16677181]\n",
            " [0.13508517 0.13508517 0.25418657 0.0717898 ]\n",
            " [0.12157665 0.28242952 0.07976644 0.0717898 ]\n",
            " [0.06461082 0.15009463 0.0717898  0.07976644]\n",
            " [0.0717898  0.05814974 0.04710129 0.0717898 ]\n",
            " [0.0717898  0.0717898  0.04239116 0.05233477]\n",
            " [0.09847709 0.09847709 0.09847709 0.05814974]\n",
            " [0.12157665 0.12157665 0.12157665 0.18530202]\n",
            " [0.13508517 0.13508517 0.16677181 0.20589113]\n",
            " [0.20589113 0.20589113 0.12157665 0.25418657]\n",
            " [0.25418657 0.3138106  0.22876792 0.25418657]\n",
            " [0.13508517 0.28242952 0.18530202 0.22876792]\n",
            " [0.20589113 0.34867844 0.25418657 0.25418657]\n",
            " [0.0717898  0.15009463 0.05814974 0.05814974]\n",
            " [0.04239116 0.06461082 0.06461082 0.05814974]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.16677181 0.15009463 0.13508517]\n",
            " [0.16677181 0.15009463 0.22876792 0.22876792]\n",
            " [0.22876792 0.3138106  0.22876792 0.20589113]\n",
            " [0.28242952 0.34867844 0.22876792 0.25418657]\n",
            " [0.25418657 0.47829688 0.28242952 0.25418657]\n",
            " [0.3138106  0.4304672  0.25418657 0.25418657]\n",
            " [0.05814974 0.08862938 0.16677181 0.16677181]\n",
            " [0.06461082 0.18530202 0.08862938 0.16677181]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.13508517 0.15009463 0.18530202]\n",
            " [0.12157665 0.18530202 0.20589113 0.28242952]\n",
            " [0.15009463 0.22876792 0.22876792 0.4304672 ]\n",
            " [0.3138106  0.25418657 0.28242952 0.38742048]\n",
            " [0.28242952 0.4304672  0.22876792 0.38742048]\n",
            " [0.25418657 0.22876792 0.38742048 0.38742048]\n",
            " [0.05233477 0.20589113 0.08862938 0.09847709]\n",
            " [0.16677181 0.15009463 0.10941899 0.16677181]\n",
            " [0.15009463 0.20589113 0.16677181 0.12157665]\n",
            " [0.20589113 0.25418657 0.16677181 0.16677181]\n",
            " [0.13508517 0.15009463 0.22876792 0.16677181]\n",
            " [0.22876792 0.18530202 0.18530202 0.18530202]\n",
            " [0.25418657 0.22876792 0.16677181 0.3138106 ]\n",
            " [0.28242952 0.4304672  0.28242952 0.4304672 ]\n",
            " [0.38742048 0.4304672  0.38742048 0.25418657]\n",
            " [0.20589113 0.531441   0.28242952 0.34867844]\n",
            " [0.09847709 0.0717898  0.22876792 0.15009463]\n",
            " [0.12157665 0.15009463 0.08862938 0.15009463]\n",
            " [0.16677181 0.22876792 0.15009463 0.18530202]\n",
            " [0.22876792 0.3138106  0.25418657 0.20589113]\n",
            " [0.18530202 0.16677181 0.22876792 0.16677181]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25418657 0.38742048 0.34867844 0.59049   ]\n",
            " [0.4304672  0.531441   0.34867844 0.34867844]\n",
            " [0.47829688 0.47829688 0.47829688 0.34867844]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.15009463 0.22876792 0.16677181 0.18530202]\n",
            " [0.16677181 0.22876792 0.18530202 0.18530202]\n",
            " [0.13508517 0.25418657 0.20589113 0.22876792]\n",
            " [0.16677181 0.38742048 0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.4304672  0.4304672  0.34867844]\n",
            " [0.4304672  0.47829688 0.4304672  0.47829688]\n",
            " [0.47829688 0.531441   0.34867844 0.531441  ]\n",
            " [0.16677181 0.13508517 0.15009463 0.20589113]\n",
            " [0.16677181 0.22876792 0.18530202 0.20589113]\n",
            " [0.20589113 0.22876792 0.16677181 0.28242952]\n",
            " [0.22876792 0.25418657 0.18530202 0.28242952]\n",
            " [0.28242952 0.25418657 0.25418657 0.3138106 ]\n",
            " [0.28242952 0.3138106  0.3138106  0.47829688]\n",
            " [0.38742048 0.3138106  0.34867844 0.6561    ]\n",
            " [0.47829688 0.729      0.47829688 0.729     ]\n",
            " [0.531441   0.531441   0.531441   0.6561    ]\n",
            " [0.47829688 0.9        0.59049    0.531441  ]\n",
            " [0.15009463 0.16677181 0.13508517 0.12157665]\n",
            " [0.22876792 0.18530202 0.15009463 0.15009463]\n",
            " [0.25418657 0.20589113 0.16677181 0.15009463]\n",
            " [0.16677181 0.22876792 0.18530202 0.28242952]\n",
            " [0.28242952 0.3138106  0.28242952 0.3138106 ]\n",
            " [0.4304672  0.34867844 0.34867844 0.25418657]\n",
            " [0.34867844 0.28242952 0.3138106  0.729     ]\n",
            " [0.4304672  0.81       0.4304672  0.6561    ]\n",
            " [0.59049    0.9        0.59049    0.729     ]\n",
            " [0.81       1.         0.81       0.9       ]\n",
            " [0.16677181 0.16677181 0.13508517 0.22876792]\n",
            " [0.22876792 0.20589113 0.16677181 0.18530202]\n",
            " [0.22876792 0.22876792 0.20589113 0.20589113]\n",
            " [0.25418657 0.22876792 0.25418657 0.25418657]\n",
            " [0.28242952 0.3138106  0.28242952 0.34867844]\n",
            " [0.38742048 0.34867844 0.3138106  0.3138106 ]\n",
            " [0.4304672  0.3138106  0.34867844 0.81      ]\n",
            " [0.47829688 0.4304672  0.729      0.9       ]\n",
            " [0.6561     0.9        0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.07976644 0.07976644 0.07976644 0.0717898 ]\n",
            " [0.07976644 0.07976644 0.07976644 0.10941899]\n",
            " [0.09847709 0.08862938 0.09847709 0.09847709]\n",
            " [0.10941899 0.10941899 0.10941899 0.13508517]\n",
            " [0.12157665 0.15009463 0.12157665 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.20589113 0.13508517 0.15009463]\n",
            " [0.18530202 0.22876792 0.15009463 0.13508517]\n",
            " [0.15009463 0.25418657 0.13508517 0.15009463]\n",
            " [0.07976644 0.0717898  0.07976644 0.09847709]\n",
            " [0.0717898  0.07976644 0.07976644 0.09847709]\n",
            " [0.10941899 0.09847709 0.06461082 0.09847709]\n",
            " [0.09847709 0.09847709 0.10941899 0.06461082]\n",
            " [0.13508517 0.28242952 0.16677181 0.15009463]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.22876792 0.22876792 0.22876792]\n",
            " [0.20589113 0.25418657 0.20589113 0.22876792]\n",
            " [0.25418657 0.4304672  0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.09847709 0.10941899 0.10941899 0.10941899]\n",
            " [0.08862938 0.20589113 0.09847709 0.08862938]\n",
            " [0.06461082 0.12157665 0.09847709 0.28242952]\n",
            " [0.18530202 0.18530202 0.13508517 0.18530202]\n",
            " [0.16677181 0.28242952 0.18530202 0.18530202]\n",
            " [0.20589113 0.20589113 0.20589113 0.25418657]\n",
            " [0.13508517 0.25418657 0.22876792 0.47829688]\n",
            " [0.28242952 0.38742048 0.25418657 0.22876792]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.10941899 0.25418657 0.12157665 0.12157665]\n",
            " [0.10941899 0.22876792 0.10941899 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28242952 0.20589113 0.3138106  0.18530202]\n",
            " [0.22876792 0.3138106  0.28242952 0.34867844]\n",
            " [0.22876792 0.34867844 0.25418657 0.20589113]\n",
            " [0.34867844 0.3138106  0.34867844 0.3138106 ]\n",
            " [0.13508517 0.07976644 0.07976644 0.18530202]\n",
            " [0.10941899 0.10941899 0.0717898  0.12157665]\n",
            " [0.10941899 0.10941899 0.12157665 0.3138106 ]\n",
            " [0.25418657 0.34867844 0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.20589113 0.22876792 0.20589113]\n",
            " [0.25418657 0.22876792 0.22876792 0.34867844]\n",
            " [0.22876792 0.3138106  0.3138106  0.38742048]\n",
            " [0.3138106  0.38742048 0.34867844 0.34867844]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.15009463 0.25418657 0.34867844]\n",
            " [0.25418657 0.20589113 0.25418657 0.38742048]\n",
            " [0.20589113 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.4304672  0.47829688 0.34867844 0.38742048]\n",
            " [0.20589113 0.531441   0.4304672  0.22876792]\n",
            " [0.38742048 0.25418657 0.38742048 0.18530202]\n",
            " [0.34867844 0.3138106  0.34867844 0.6561    ]\n",
            " [0.34867844 0.729      0.4304672  0.6561    ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25418657 0.16677181 0.16677181 0.16677181]\n",
            " [0.20589113 0.20589113 0.15009463 0.22876792]\n",
            " [0.16677181 0.18530202 0.16677181 0.4304672 ]\n",
            " [0.4304672  0.47829688 0.4304672  0.531441  ]\n",
            " [0.38742048 0.47829688 0.4304672  0.531441  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.47829688 0.47829688 0.59049   ]\n",
            " [0.09847709 0.08862938 0.10941899 0.10941899]\n",
            " [0.10941899 0.18530202 0.10941899 0.09847709]\n",
            " [0.15009463 0.12157665 0.10941899 0.09847709]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.531441   0.531441   0.59049   ]\n",
            " [0.47829688 0.6561     0.531441   0.47829688]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.9        0.47829688 0.531441  ]\n",
            " [0.09847709 0.18530202 0.12157665 0.16677181]\n",
            " [0.16677181 0.16677181 0.12157665 0.12157665]\n",
            " [0.13508517 0.09847709 0.12157665 0.10941899]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.34867844 0.531441   0.531441   0.6561    ]\n",
            " [0.47829688 0.59049    0.59049    0.729     ]\n",
            " [0.729      0.729      0.6561     0.38742048]\n",
            " [0.6561     0.9        0.6561     0.4304672 ]\n",
            " [0.81       1.         0.729      0.9       ]\n",
            " [0.12157665 0.16677181 0.16677181 0.34867844]\n",
            " [0.18530202 0.18530202 0.15009463 0.38742048]\n",
            " [0.10941899 0.22876792 0.13508517 0.3138106 ]\n",
            " [0.25418657 0.25418657 0.22876792 0.47829688]\n",
            " [0.34867844 0.34867844 0.3138106  0.531441  ]\n",
            " [0.38742048 0.25418657 0.47829688 0.47829688]\n",
            " [0.6561     0.531441   0.531441   0.47829688]\n",
            " [0.729      0.729      0.47829688 0.729     ]\n",
            " [0.81       0.9        0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.00785517 0.00872796 0.00872796 0.01077527]\n",
            " [0.01077527 0.00969774 0.00872796 0.01197252]\n",
            " [0.00706965 0.00706965 0.00872796 0.0133028 ]\n",
            " [0.0133028  0.01478088 0.00706965 0.01478088]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.01077527 0.00969774 0.01077527 0.02027556]\n",
            " [0.01077527 0.01077527 0.00969774 0.0225284 ]\n",
            " [0.00572642 0.0225284  0.00706965 0.0225284 ]\n",
            " [0.02027556 0.03433684 0.00636269 0.02027556]\n",
            " [0.00872796 0.00872796 0.00969774 0.00969774]\n",
            " [0.00969774 0.00969774 0.01077527 0.00785517]\n",
            " [0.01197252 0.01478088 0.00785517 0.01077527]\n",
            " [0.0133028  0.0164232  0.01077527 0.0164232 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.00969774 0.02503156 0.02503156 0.018248  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.03433684 0.03433684 0.03433684 0.03433684]\n",
            " [0.00872796 0.00969774 0.00872796 0.00969774]\n",
            " [0.00969774 0.00636269 0.00872796 0.01077527]\n",
            " [0.00969774 0.01197252 0.01077527 0.0133028 ]\n",
            " [0.01478088 0.01478088 0.01478088 0.018248  ]\n",
            " [0.018248   0.0133028  0.0164232  0.00636269]\n",
            " [0.00706965 0.01478088 0.018248   0.02027556]\n",
            " [0.0164232  0.0225284  0.018248   0.01478088]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.03433684 0.03433684 0.02781284 0.03815204]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.01197252 0.01197252 0.0133028  0.01478088]\n",
            " [0.0133028  0.0133028  0.01077527 0.03815204]\n",
            " [0.018248   0.01478088 0.01197252 0.04239116]\n",
            " [0.018248   0.0225284  0.0164232  0.05233477]\n",
            " [0.02027556 0.0225284  0.04239116 0.05814974]\n",
            " [0.02781284 0.05814974 0.03090315 0.03815204]\n",
            " [0.01478088 0.02503156 0.05233477 0.02027556]\n",
            " [0.03815204 0.0717898  0.0225284  0.0164232 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.02781284 0.08862938 0.05814974 0.02503156]\n",
            " [0.03815204 0.07976644 0.02781284 0.08862938]\n",
            " [0.06461082 0.0717898  0.07976644 0.03090315]\n",
            " [0.0717898  0.0717898  0.08862938 0.09847709]\n",
            " [0.09847709 0.09847709 0.08862938 0.10941899]\n",
            " [0.10941899 0.10941899 0.09847709 0.13508517]\n",
            " [0.09847709 0.10941899 0.10941899 0.10941899]\n",
            " [0.10941899 0.10941899 0.09847709 0.12157665]\n",
            " [0.09847709 0.07976644 0.10941899 0.05233477]\n",
            " [0.07976644 0.06461082 0.09847709 0.07976644]\n",
            " [0.03433684 0.08862938 0.08862938 0.07976644]\n",
            " [0.03433684 0.03090315 0.02781284 0.08862938]\n",
            " [0.02781284 0.03090315 0.07976644 0.07976644]\n",
            " [0.08862938 0.15009463 0.10941899 0.08862938]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.09847709 0.13508517 0.12157665 0.12157665]\n",
            " [0.10941899 0.12157665 0.12157665 0.12157665]\n",
            " [0.10941899 0.07976644 0.10941899 0.08862938]\n",
            " [0.08862938 0.09847709 0.10941899 0.04239116]\n",
            " [0.0717898  0.05814974 0.09847709 0.0717898 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.0717898  0.13508517 0.12157665 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.18530202 0.13508517 0.15009463]\n",
            " [0.12157665 0.10941899 0.13508517 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.13508517 0.12157665 0.15009463]\n",
            " [0.12157665 0.13508517 0.12157665 0.13508517]\n",
            " [0.13508517 0.10941899 0.13508517 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.59049    0.531441   0.47829688 0.47829688]\n",
            " [0.4304672  0.47829688 0.531441   0.729     ]\n",
            " [0.6561     0.729      0.47829688 0.81      ]\n",
            " [0.81       0.729      0.6561     0.9       ]\n",
            " [0.9        1.         0.81       0.9       ]\n",
            " [0.16677181 0.15009463 0.15009463 0.13508517]\n",
            " [0.13508517 0.13508517 0.13508517 0.22876792]\n",
            " [0.12157665 0.25418657 0.20589113 0.4304672 ]\n",
            " [0.38742048 0.38742048 0.25418657 0.4304672 ]\n",
            " [0.38742048 0.34867844 0.38742048 0.47829688]\n",
            " [0.47829688 0.38742048 0.47829688 0.38742048]\n",
            " [0.6561     0.729      0.47829688 0.81      ]\n",
            " [0.729      0.81       0.6561     0.9       ]\n",
            " [0.729      0.729      0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - Alternating.pkl')\n",
        "files.download('Mid - Alternating.pkl')\n",
        "files.download('Hard - Alternating.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vUP5r9NFqT1f",
        "outputId": "bc97e667-16e1-4daa-d39e-6a9bee06e580"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e2834b9-ba4a-4ca7-b558-562cff07556b\", \"Simple - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8fba3c7-1e57-49e0-90a9-353f5d5c155f\", \"Mid - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0afc0bd7-9b55-4f5f-802c-03d1e69dd032\", \"Hard - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Deep Q-Learning\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bhy-qxHIR45Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "36TWCaB8R8ZR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking availability of CUDA"
      ],
      "metadata": {
        "id": "c3GfUBB_Jhey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP8ku5ZJJpK_",
        "outputId": "61d7d2eb-b576-423d-c239-751fa7a83f4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the neural network"
      ],
      "metadata": {
        "id": "zmF91Wy1KSP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepQNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(DeepQNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "xx6AEfJJKYW3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the exploration-exploit function\n"
      ],
      "metadata": {
        "id": "CSA3fLnAlB8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_action_torch(environment, epsilon, policy_net):\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "        return np.random.choice(range(len(environment.action_space))) # Exploration\n",
        "\n",
        "    else:\n",
        "        current_state = torch.FloatTensor(environment.grid).unsqueeze(0)\n",
        "        q = policy_net(current_state)\n",
        "        return torch.argmax(q).item() # Exploit"
      ],
      "metadata": {
        "id": "XIhsEsI5lGFB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the optimizing function\n"
      ],
      "metadata": {
        "id": "Mk0msX6Om8yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(memory, policy_net, target_net, gamma, optimizer, batch_size = 32):\n",
        "\n",
        "    if len(memory) < batch_size:\n",
        "        return\n",
        "\n",
        "    batch = random.sample(memory, batch_size)\n",
        "    state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
        "\n",
        "    state_batch = torch.FloatTensor(np.array(state_batch))\n",
        "    action_batch = torch.LongTensor(np.array(action_batch)).unsqueeze(1)\n",
        "    reward_batch = torch.FloatTensor(np.array(reward_batch))\n",
        "    next_state_batch = torch.FloatTensor(np.array(next_state_batch))\n",
        "    done_batch = torch.FloatTensor(np.array(done_batch))\n",
        "\n",
        "    # Compute Q-values for current states\n",
        "    q_values = policy_net(state_batch).gather(1, action_batch).squeeze()\n",
        "\n",
        "    # Compute target Q-values using the target network\n",
        "    with torch.no_grad():\n",
        "        max_next_q_values = target_net(next_state_batch).max(1)[0]\n",
        "        target_q_values = reward_batch + gamma * max_next_q_values * (1 - done_batch)\n",
        "\n",
        "    loss = nn.MSELoss()(q_values, target_q_values)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "sGvxmkdVm76A"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Deep Q-Learning function"
      ],
      "metadata": {
        "id": "jEilwyivJrVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IL FAUDRAIT ENVOYER LA GRILLE CONTENANT LA POSITION DU DRONE EN TANT QU'ETAT DANS LE RESEAU ET NON PAS SEULEMENT L'INDEX DE L'ETAT COMME POUR LE Q-LEARNING**"
      ],
      "metadata": {
        "id": "MpqrOeFxr9yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_q_learning(env, memory, policy_net, target_net, optimizer, alpha=0.01, gamma=0.9,  epsilon=1, epsilon_decay=0.005, target_update_freq = 400, episodes = 1000):\n",
        "\n",
        "    steps = 0\n",
        "    rewards = []\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        step_per_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            #current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            current_state = np.copy(env.grid)\n",
        "\n",
        "            action = compute_action_torch(env, epsilon, policy_net) # Compute the action for the current state in function of the epsilon_greedy\n",
        "\n",
        "            posp1, new_state, reward, done = env.step(action)\n",
        "\n",
        "            #state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0]\n",
        "\n",
        "            memory.append((current_state, action, reward, new_state, done))\n",
        "\n",
        "            total_reward += reward #Increment your reward\n",
        "\n",
        "            optimize(memory, policy_net, target_net, gamma, optimizer)\n",
        "\n",
        "            if steps % target_update_freq == 0:\n",
        "                target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                print(f\"Episode: {e}, Reward: {total_reward}, Steps in the episode: {step_per_episode}\")\n",
        "                break\n",
        "\n",
        "            steps += 1\n",
        "            step_per_episode += 1\n",
        "\n",
        "\n",
        "        if epsilon>0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    return rewards, steps"
      ],
      "metadata": {
        "id": "nuiIigURJqfq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to save the weights of the policy_net and the target_net"
      ],
      "metadata": {
        "id": "aBmAU6Cro-Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_weights(filename, neural_net):\n",
        "    torch.save(neural_net.state_dict(), filename)"
      ],
      "metadata": {
        "id": "rSC-D-bbtv3h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights(filename, blank_net):\n",
        "    blank_net.load_state_dict(torch.load(filename))"
      ],
      "metadata": {
        "id": "ogARufmHumjo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the agent"
      ],
      "metadata": {
        "id": "zh97o3FTvXvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_net = DeepQNetwork(STATE_SIZE[0]*STATE_SIZE[1], 100, ACTION_SIZE)\n",
        "target_net = DeepQNetwork(STATE_SIZE[0]*STATE_SIZE[1], 100, ACTION_SIZE)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "learning_rate = 0.001\n",
        "memory_size = 300\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr = learning_rate)\n",
        "memory = deque(maxlen = memory_size)"
      ],
      "metadata": {
        "id": "ap4CE5jVvbXa"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running of the training"
      ],
      "metadata": {
        "id": "1SK1Fj59xU8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dql_simple = deep_q_learning(environment_simple, memory, policy_net, target_net, optimizer)\n",
        "#dql_mid = deep_q_learning(environment_mid, memory, policy_net, target_net, optimizer)\n",
        "#dql_hard = deep_q_learning(environment_hard, memory, policy_net, target_net, optimizer)"
      ],
      "metadata": {
        "id": "vzag5RVNxWXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c9362d-bbc3-4c63-c040-88e5dec44f3b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Reward: 1.0, Steps in the episode: 1342\n",
            "Episode: 1, Reward: 1.0, Steps in the episode: 262\n",
            "Episode: 2, Reward: 1.0, Steps in the episode: 90\n",
            "Episode: 3, Reward: 1.0, Steps in the episode: 349\n",
            "Episode: 4, Reward: 1.0, Steps in the episode: 1219\n",
            "Episode: 5, Reward: 1.0, Steps in the episode: 574\n",
            "Episode: 6, Reward: 1.0, Steps in the episode: 495\n",
            "Episode: 7, Reward: 1.0, Steps in the episode: 1049\n",
            "Episode: 8, Reward: 1.0, Steps in the episode: 1572\n",
            "Episode: 9, Reward: 1.0, Steps in the episode: 300\n",
            "Episode: 10, Reward: 1.0, Steps in the episode: 777\n",
            "Episode: 11, Reward: 1.0, Steps in the episode: 529\n",
            "Episode: 12, Reward: 1.0, Steps in the episode: 764\n",
            "Episode: 13, Reward: 1.0, Steps in the episode: 226\n",
            "Episode: 14, Reward: 1.0, Steps in the episode: 2435\n",
            "Episode: 15, Reward: 1.0, Steps in the episode: 451\n",
            "Episode: 16, Reward: 1.0, Steps in the episode: 294\n",
            "Episode: 17, Reward: 1.0, Steps in the episode: 153\n",
            "Episode: 18, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 19, Reward: 1.0, Steps in the episode: 523\n",
            "Episode: 20, Reward: 1.0, Steps in the episode: 218\n",
            "Episode: 21, Reward: 1.0, Steps in the episode: 452\n",
            "Episode: 22, Reward: 1.0, Steps in the episode: 137\n",
            "Episode: 23, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 24, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 25, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 26, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 27, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 28, Reward: 1.0, Steps in the episode: 829\n",
            "Episode: 29, Reward: 1.0, Steps in the episode: 805\n",
            "Episode: 30, Reward: 1.0, Steps in the episode: 542\n",
            "Episode: 31, Reward: 1.0, Steps in the episode: 576\n",
            "Episode: 32, Reward: 1.0, Steps in the episode: 781\n",
            "Episode: 33, Reward: 1.0, Steps in the episode: 515\n",
            "Episode: 34, Reward: 1.0, Steps in the episode: 183\n",
            "Episode: 35, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 36, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 37, Reward: 1.0, Steps in the episode: 292\n",
            "Episode: 38, Reward: 1.0, Steps in the episode: 183\n",
            "Episode: 39, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 40, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 41, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 42, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 43, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 44, Reward: 1.0, Steps in the episode: 474\n",
            "Episode: 45, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 46, Reward: 1.0, Steps in the episode: 485\n",
            "Episode: 47, Reward: 1.0, Steps in the episode: 59\n",
            "Episode: 48, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 49, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 50, Reward: 1.0, Steps in the episode: 216\n",
            "Episode: 51, Reward: 1.0, Steps in the episode: 114\n",
            "Episode: 52, Reward: 1.0, Steps in the episode: 414\n",
            "Episode: 53, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 54, Reward: 1.0, Steps in the episode: 119\n",
            "Episode: 55, Reward: 1.0, Steps in the episode: 117\n",
            "Episode: 56, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 57, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 58, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 59, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 60, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 61, Reward: 1.0, Steps in the episode: 103\n",
            "Episode: 62, Reward: 1.0, Steps in the episode: 282\n",
            "Episode: 63, Reward: 1.0, Steps in the episode: 268\n",
            "Episode: 64, Reward: 1.0, Steps in the episode: 447\n",
            "Episode: 65, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 66, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 67, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 68, Reward: 1.0, Steps in the episode: 168\n",
            "Episode: 69, Reward: 1.0, Steps in the episode: 186\n",
            "Episode: 70, Reward: 1.0, Steps in the episode: 303\n",
            "Episode: 71, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 72, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 73, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 74, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 75, Reward: 1.0, Steps in the episode: 77\n",
            "Episode: 76, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 77, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 78, Reward: 1.0, Steps in the episode: 79\n",
            "Episode: 79, Reward: 1.0, Steps in the episode: 350\n",
            "Episode: 80, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 81, Reward: 1.0, Steps in the episode: 98\n",
            "Episode: 82, Reward: 1.0, Steps in the episode: 196\n",
            "Episode: 83, Reward: 1.0, Steps in the episode: 49\n",
            "Episode: 84, Reward: 1.0, Steps in the episode: 256\n",
            "Episode: 85, Reward: 1.0, Steps in the episode: 344\n",
            "Episode: 86, Reward: 1.0, Steps in the episode: 223\n",
            "Episode: 87, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 88, Reward: 1.0, Steps in the episode: 105\n",
            "Episode: 89, Reward: 1.0, Steps in the episode: 614\n",
            "Episode: 90, Reward: 1.0, Steps in the episode: 189\n",
            "Episode: 91, Reward: 1.0, Steps in the episode: 81\n",
            "Episode: 92, Reward: 1.0, Steps in the episode: 188\n",
            "Episode: 93, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 94, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 95, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 96, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 97, Reward: 1.0, Steps in the episode: 136\n",
            "Episode: 98, Reward: 1.0, Steps in the episode: 236\n",
            "Episode: 99, Reward: 1.0, Steps in the episode: 179\n",
            "Episode: 100, Reward: 1.0, Steps in the episode: 264\n",
            "Episode: 101, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 102, Reward: 1.0, Steps in the episode: 30\n",
            "Episode: 103, Reward: 1.0, Steps in the episode: 232\n",
            "Episode: 104, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 105, Reward: 1.0, Steps in the episode: 158\n",
            "Episode: 106, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 107, Reward: 1.0, Steps in the episode: 49\n",
            "Episode: 108, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 109, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 110, Reward: 1.0, Steps in the episode: 160\n",
            "Episode: 111, Reward: 1.0, Steps in the episode: 141\n",
            "Episode: 112, Reward: 1.0, Steps in the episode: 163\n",
            "Episode: 113, Reward: 1.0, Steps in the episode: 81\n",
            "Episode: 114, Reward: 1.0, Steps in the episode: 381\n",
            "Episode: 115, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 116, Reward: 1.0, Steps in the episode: 136\n",
            "Episode: 117, Reward: 1.0, Steps in the episode: 180\n",
            "Episode: 118, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 119, Reward: 1.0, Steps in the episode: 570\n",
            "Episode: 120, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 121, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 122, Reward: 1.0, Steps in the episode: 62\n",
            "Episode: 123, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 124, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 125, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 126, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 127, Reward: 1.0, Steps in the episode: 113\n",
            "Episode: 128, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 129, Reward: 1.0, Steps in the episode: 74\n",
            "Episode: 130, Reward: 1.0, Steps in the episode: 27\n",
            "Episode: 131, Reward: 1.0, Steps in the episode: 354\n",
            "Episode: 132, Reward: 1.0, Steps in the episode: 344\n",
            "Episode: 133, Reward: 1.0, Steps in the episode: 477\n",
            "Episode: 134, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 135, Reward: 1.0, Steps in the episode: 97\n",
            "Episode: 136, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 137, Reward: 1.0, Steps in the episode: 135\n",
            "Episode: 138, Reward: 1.0, Steps in the episode: 161\n",
            "Episode: 139, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 140, Reward: 1.0, Steps in the episode: 663\n",
            "Episode: 141, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 142, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 143, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 144, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 145, Reward: 1.0, Steps in the episode: 22\n",
            "Episode: 146, Reward: 1.0, Steps in the episode: 685\n",
            "Episode: 147, Reward: 1.0, Steps in the episode: 46\n",
            "Episode: 148, Reward: 1.0, Steps in the episode: 358\n",
            "Episode: 149, Reward: 1.0, Steps in the episode: 321\n",
            "Episode: 150, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 151, Reward: 1.0, Steps in the episode: 184\n",
            "Episode: 152, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 153, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 154, Reward: 1.0, Steps in the episode: 118\n",
            "Episode: 155, Reward: 1.0, Steps in the episode: 119\n",
            "Episode: 156, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 157, Reward: 1.0, Steps in the episode: 208\n",
            "Episode: 158, Reward: 1.0, Steps in the episode: 163\n",
            "Episode: 159, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 160, Reward: 1.0, Steps in the episode: 331\n",
            "Episode: 161, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 162, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 163, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 164, Reward: 1.0, Steps in the episode: 379\n",
            "Episode: 165, Reward: 1.0, Steps in the episode: 461\n",
            "Episode: 166, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 167, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 168, Reward: 1.0, Steps in the episode: 96\n",
            "Episode: 169, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 170, Reward: 1.0, Steps in the episode: 245\n",
            "Episode: 171, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 172, Reward: 1.0, Steps in the episode: 155\n",
            "Episode: 173, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 174, Reward: 1.0, Steps in the episode: 154\n",
            "Episode: 175, Reward: 1.0, Steps in the episode: 157\n",
            "Episode: 176, Reward: 1.0, Steps in the episode: 644\n",
            "Episode: 177, Reward: 1.0, Steps in the episode: 266\n",
            "Episode: 178, Reward: 1.0, Steps in the episode: 24\n",
            "Episode: 179, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 180, Reward: 1.0, Steps in the episode: 68\n",
            "Episode: 181, Reward: 1.0, Steps in the episode: 754\n",
            "Episode: 182, Reward: 1.0, Steps in the episode: 591\n",
            "Episode: 183, Reward: 1.0, Steps in the episode: 294\n",
            "Episode: 184, Reward: 1.0, Steps in the episode: 27\n",
            "Episode: 185, Reward: 1.0, Steps in the episode: 154\n",
            "Episode: 186, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 187, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 188, Reward: 1.0, Steps in the episode: 166\n",
            "Episode: 189, Reward: 1.0, Steps in the episode: 373\n",
            "Episode: 190, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 191, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 192, Reward: 1.0, Steps in the episode: 144\n",
            "Episode: 193, Reward: 1.0, Steps in the episode: 124\n",
            "Episode: 194, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 195, Reward: 1.0, Steps in the episode: 185\n",
            "Episode: 196, Reward: 1.0, Steps in the episode: 93\n",
            "Episode: 197, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 198, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 199, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 200, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 201, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 202, Reward: 1.0, Steps in the episode: 142\n",
            "Episode: 203, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 204, Reward: 1.0, Steps in the episode: 87\n",
            "Episode: 205, Reward: 1.0, Steps in the episode: 309\n",
            "Episode: 206, Reward: 1.0, Steps in the episode: 68\n",
            "Episode: 207, Reward: 1.0, Steps in the episode: 327\n",
            "Episode: 208, Reward: 1.0, Steps in the episode: 253\n",
            "Episode: 209, Reward: 1.0, Steps in the episode: 415\n",
            "Episode: 210, Reward: 1.0, Steps in the episode: 785\n",
            "Episode: 211, Reward: 1.0, Steps in the episode: 277\n",
            "Episode: 212, Reward: 1.0, Steps in the episode: 72\n",
            "Episode: 213, Reward: 1.0, Steps in the episode: 204\n",
            "Episode: 214, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 215, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 216, Reward: 1.0, Steps in the episode: 197\n",
            "Episode: 217, Reward: 1.0, Steps in the episode: 275\n",
            "Episode: 218, Reward: 1.0, Steps in the episode: 212\n",
            "Episode: 219, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 220, Reward: 1.0, Steps in the episode: 201\n",
            "Episode: 221, Reward: 1.0, Steps in the episode: 935\n",
            "Episode: 222, Reward: 1.0, Steps in the episode: 347\n",
            "Episode: 223, Reward: 1.0, Steps in the episode: 350\n",
            "Episode: 224, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 225, Reward: 1.0, Steps in the episode: 375\n",
            "Episode: 226, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 227, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 228, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 229, Reward: 1.0, Steps in the episode: 199\n",
            "Episode: 230, Reward: 1.0, Steps in the episode: 121\n",
            "Episode: 231, Reward: 1.0, Steps in the episode: 46\n",
            "Episode: 232, Reward: 1.0, Steps in the episode: 641\n",
            "Episode: 233, Reward: 1.0, Steps in the episode: 35\n",
            "Episode: 234, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 235, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 236, Reward: 1.0, Steps in the episode: 131\n",
            "Episode: 237, Reward: 1.0, Steps in the episode: 153\n",
            "Episode: 238, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 239, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 240, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 241, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 242, Reward: 1.0, Steps in the episode: 211\n",
            "Episode: 243, Reward: 1.0, Steps in the episode: 544\n",
            "Episode: 244, Reward: 1.0, Steps in the episode: 406\n",
            "Episode: 245, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 246, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 247, Reward: 1.0, Steps in the episode: 152\n",
            "Episode: 248, Reward: 1.0, Steps in the episode: 113\n",
            "Episode: 249, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 250, Reward: 1.0, Steps in the episode: 251\n",
            "Episode: 251, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 252, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 253, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 254, Reward: 1.0, Steps in the episode: 61\n",
            "Episode: 255, Reward: 1.0, Steps in the episode: 337\n",
            "Episode: 256, Reward: 1.0, Steps in the episode: 369\n",
            "Episode: 257, Reward: 1.0, Steps in the episode: 338\n",
            "Episode: 258, Reward: 1.0, Steps in the episode: 186\n",
            "Episode: 259, Reward: 1.0, Steps in the episode: 72\n",
            "Episode: 260, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 261, Reward: 1.0, Steps in the episode: 358\n",
            "Episode: 262, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 263, Reward: 1.0, Steps in the episode: 111\n",
            "Episode: 264, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 265, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 266, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 267, Reward: 1.0, Steps in the episode: 123\n",
            "Episode: 268, Reward: 1.0, Steps in the episode: 242\n",
            "Episode: 269, Reward: 1.0, Steps in the episode: 156\n",
            "Episode: 270, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 271, Reward: 1.0, Steps in the episode: 371\n",
            "Episode: 272, Reward: 1.0, Steps in the episode: 1017\n",
            "Episode: 273, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 274, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 275, Reward: 1.0, Steps in the episode: 172\n",
            "Episode: 276, Reward: 1.0, Steps in the episode: 334\n",
            "Episode: 277, Reward: 1.0, Steps in the episode: 647\n",
            "Episode: 278, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 279, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 280, Reward: 1.0, Steps in the episode: 52\n",
            "Episode: 281, Reward: 1.0, Steps in the episode: 317\n",
            "Episode: 282, Reward: 1.0, Steps in the episode: 29\n",
            "Episode: 283, Reward: 1.0, Steps in the episode: 520\n",
            "Episode: 284, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 285, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 286, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 287, Reward: 1.0, Steps in the episode: 115\n",
            "Episode: 288, Reward: 1.0, Steps in the episode: 215\n",
            "Episode: 289, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 290, Reward: 1.0, Steps in the episode: 490\n",
            "Episode: 291, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 292, Reward: 1.0, Steps in the episode: 335\n",
            "Episode: 293, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 294, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 295, Reward: 1.0, Steps in the episode: 64\n",
            "Episode: 296, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 297, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 298, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 299, Reward: 1.0, Steps in the episode: 52\n",
            "Episode: 300, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 301, Reward: 1.0, Steps in the episode: 280\n",
            "Episode: 302, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 303, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 304, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 305, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 306, Reward: 1.0, Steps in the episode: 1141\n",
            "Episode: 307, Reward: 1.0, Steps in the episode: 359\n",
            "Episode: 308, Reward: 1.0, Steps in the episode: 224\n",
            "Episode: 309, Reward: 1.0, Steps in the episode: 231\n",
            "Episode: 310, Reward: 1.0, Steps in the episode: 288\n",
            "Episode: 311, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 312, Reward: 1.0, Steps in the episode: 209\n",
            "Episode: 313, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 314, Reward: 1.0, Steps in the episode: 107\n",
            "Episode: 315, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 316, Reward: 1.0, Steps in the episode: 255\n",
            "Episode: 317, Reward: 1.0, Steps in the episode: 280\n",
            "Episode: 318, Reward: 1.0, Steps in the episode: 337\n",
            "Episode: 319, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 320, Reward: 1.0, Steps in the episode: 121\n",
            "Episode: 321, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 322, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 323, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 324, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 325, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 326, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 327, Reward: 1.0, Steps in the episode: 313\n",
            "Episode: 328, Reward: 1.0, Steps in the episode: 790\n",
            "Episode: 329, Reward: 1.0, Steps in the episode: 212\n",
            "Episode: 330, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 331, Reward: 1.0, Steps in the episode: 117\n",
            "Episode: 332, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 333, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 334, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 335, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 336, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 337, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 338, Reward: 1.0, Steps in the episode: 228\n",
            "Episode: 339, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 340, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 341, Reward: 1.0, Steps in the episode: 159\n",
            "Episode: 342, Reward: 1.0, Steps in the episode: 33\n",
            "Episode: 343, Reward: 1.0, Steps in the episode: 94\n",
            "Episode: 344, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 345, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 346, Reward: 1.0, Steps in the episode: 60\n",
            "Episode: 347, Reward: 1.0, Steps in the episode: 139\n",
            "Episode: 348, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 349, Reward: 1.0, Steps in the episode: 58\n",
            "Episode: 350, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 351, Reward: 1.0, Steps in the episode: 507\n",
            "Episode: 352, Reward: 1.0, Steps in the episode: 131\n",
            "Episode: 353, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 354, Reward: 1.0, Steps in the episode: 672\n",
            "Episode: 355, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 356, Reward: 1.0, Steps in the episode: 482\n",
            "Episode: 357, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 358, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 359, Reward: 1.0, Steps in the episode: 402\n",
            "Episode: 360, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 361, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 362, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 363, Reward: 1.0, Steps in the episode: 576\n",
            "Episode: 364, Reward: 1.0, Steps in the episode: 416\n",
            "Episode: 365, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 366, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 367, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 368, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 369, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 370, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 371, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 372, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 373, Reward: 1.0, Steps in the episode: 167\n",
            "Episode: 374, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 375, Reward: 1.0, Steps in the episode: 1219\n",
            "Episode: 376, Reward: 1.0, Steps in the episode: 783\n",
            "Episode: 377, Reward: 1.0, Steps in the episode: 333\n",
            "Episode: 378, Reward: 1.0, Steps in the episode: 285\n",
            "Episode: 379, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 380, Reward: 1.0, Steps in the episode: 244\n",
            "Episode: 381, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 382, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 383, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 384, Reward: 1.0, Steps in the episode: 97\n",
            "Episode: 385, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 386, Reward: 1.0, Steps in the episode: 764\n",
            "Episode: 387, Reward: 1.0, Steps in the episode: 743\n",
            "Episode: 388, Reward: 1.0, Steps in the episode: 306\n",
            "Episode: 389, Reward: 1.0, Steps in the episode: 500\n",
            "Episode: 390, Reward: 1.0, Steps in the episode: 314\n",
            "Episode: 391, Reward: 1.0, Steps in the episode: 302\n",
            "Episode: 392, Reward: 1.0, Steps in the episode: 226\n",
            "Episode: 393, Reward: 1.0, Steps in the episode: 216\n",
            "Episode: 394, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 395, Reward: 1.0, Steps in the episode: 366\n",
            "Episode: 396, Reward: 1.0, Steps in the episode: 600\n",
            "Episode: 397, Reward: 1.0, Steps in the episode: 347\n",
            "Episode: 398, Reward: 1.0, Steps in the episode: 359\n",
            "Episode: 399, Reward: 1.0, Steps in the episode: 388\n",
            "Episode: 400, Reward: 1.0, Steps in the episode: 325\n",
            "Episode: 401, Reward: 1.0, Steps in the episode: 335\n",
            "Episode: 402, Reward: 1.0, Steps in the episode: 1052\n",
            "Episode: 403, Reward: 1.0, Steps in the episode: 293\n",
            "Episode: 404, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 405, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 406, Reward: 1.0, Steps in the episode: 295\n",
            "Episode: 407, Reward: 1.0, Steps in the episode: 150\n",
            "Episode: 408, Reward: 1.0, Steps in the episode: 214\n",
            "Episode: 409, Reward: 1.0, Steps in the episode: 187\n",
            "Episode: 410, Reward: 1.0, Steps in the episode: 91\n",
            "Episode: 411, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 412, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 413, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 414, Reward: 1.0, Steps in the episode: 144\n",
            "Episode: 415, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 416, Reward: 1.0, Steps in the episode: 336\n",
            "Episode: 417, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 418, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 419, Reward: 1.0, Steps in the episode: 281\n",
            "Episode: 420, Reward: 1.0, Steps in the episode: 18\n",
            "Episode: 421, Reward: 1.0, Steps in the episode: 774\n",
            "Episode: 422, Reward: 1.0, Steps in the episode: 826\n",
            "Episode: 423, Reward: 1.0, Steps in the episode: 555\n",
            "Episode: 424, Reward: 1.0, Steps in the episode: 341\n",
            "Episode: 425, Reward: 1.0, Steps in the episode: 449\n",
            "Episode: 426, Reward: 1.0, Steps in the episode: 274\n",
            "Episode: 427, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 428, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 429, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 430, Reward: 1.0, Steps in the episode: 79\n",
            "Episode: 431, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 432, Reward: 1.0, Steps in the episode: 35\n",
            "Episode: 433, Reward: 1.0, Steps in the episode: 77\n",
            "Episode: 434, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 435, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 436, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 437, Reward: 1.0, Steps in the episode: 660\n",
            "Episode: 438, Reward: 1.0, Steps in the episode: 667\n",
            "Episode: 439, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 440, Reward: 1.0, Steps in the episode: 274\n",
            "Episode: 441, Reward: 1.0, Steps in the episode: 248\n",
            "Episode: 442, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 443, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 444, Reward: 1.0, Steps in the episode: 299\n",
            "Episode: 445, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 446, Reward: 1.0, Steps in the episode: 145\n",
            "Episode: 447, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 448, Reward: 1.0, Steps in the episode: 130\n",
            "Episode: 449, Reward: 1.0, Steps in the episode: 366\n",
            "Episode: 450, Reward: 1.0, Steps in the episode: 318\n",
            "Episode: 451, Reward: 1.0, Steps in the episode: 879\n",
            "Episode: 452, Reward: 1.0, Steps in the episode: 1233\n",
            "Episode: 453, Reward: 1.0, Steps in the episode: 179\n",
            "Episode: 454, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 455, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 456, Reward: 1.0, Steps in the episode: 140\n",
            "Episode: 457, Reward: 1.0, Steps in the episode: 160\n",
            "Episode: 458, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 459, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 460, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 461, Reward: 1.0, Steps in the episode: 307\n",
            "Episode: 462, Reward: 1.0, Steps in the episode: 319\n",
            "Episode: 463, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 464, Reward: 1.0, Steps in the episode: 306\n",
            "Episode: 465, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 466, Reward: 1.0, Steps in the episode: 386\n",
            "Episode: 467, Reward: 1.0, Steps in the episode: 1199\n",
            "Episode: 468, Reward: 1.0, Steps in the episode: 400\n",
            "Episode: 469, Reward: 1.0, Steps in the episode: 1407\n",
            "Episode: 470, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 471, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 472, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 473, Reward: 1.0, Steps in the episode: 30\n",
            "Episode: 474, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 475, Reward: 1.0, Steps in the episode: 39\n",
            "Episode: 476, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 477, Reward: 1.0, Steps in the episode: 550\n",
            "Episode: 478, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 479, Reward: 1.0, Steps in the episode: 461\n",
            "Episode: 480, Reward: 1.0, Steps in the episode: 744\n",
            "Episode: 481, Reward: 1.0, Steps in the episode: 353\n",
            "Episode: 482, Reward: 1.0, Steps in the episode: 162\n",
            "Episode: 483, Reward: 1.0, Steps in the episode: 688\n",
            "Episode: 484, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 485, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 486, Reward: 1.0, Steps in the episode: 135\n",
            "Episode: 487, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 488, Reward: 1.0, Steps in the episode: 1000\n",
            "Episode: 489, Reward: 1.0, Steps in the episode: 814\n",
            "Episode: 490, Reward: 1.0, Steps in the episode: 389\n",
            "Episode: 491, Reward: 1.0, Steps in the episode: 247\n",
            "Episode: 492, Reward: 1.0, Steps in the episode: 355\n",
            "Episode: 493, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 494, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 495, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 496, Reward: 1.0, Steps in the episode: 233\n",
            "Episode: 497, Reward: 1.0, Steps in the episode: 621\n",
            "Episode: 498, Reward: 1.0, Steps in the episode: 767\n",
            "Episode: 499, Reward: 1.0, Steps in the episode: 234\n",
            "Episode: 500, Reward: 1.0, Steps in the episode: 554\n",
            "Episode: 501, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 502, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 503, Reward: 1.0, Steps in the episode: 864\n",
            "Episode: 504, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 505, Reward: 1.0, Steps in the episode: 290\n",
            "Episode: 506, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 507, Reward: 1.0, Steps in the episode: 450\n",
            "Episode: 508, Reward: 1.0, Steps in the episode: 174\n",
            "Episode: 509, Reward: 1.0, Steps in the episode: 612\n",
            "Episode: 510, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 511, Reward: 1.0, Steps in the episode: 479\n",
            "Episode: 512, Reward: 1.0, Steps in the episode: 398\n",
            "Episode: 513, Reward: 1.0, Steps in the episode: 403\n",
            "Episode: 514, Reward: 1.0, Steps in the episode: 1598\n",
            "Episode: 515, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 516, Reward: 1.0, Steps in the episode: 488\n",
            "Episode: 517, Reward: 1.0, Steps in the episode: 1202\n",
            "Episode: 518, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 519, Reward: 1.0, Steps in the episode: 475\n",
            "Episode: 520, Reward: 1.0, Steps in the episode: 474\n",
            "Episode: 521, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 522, Reward: 1.0, Steps in the episode: 320\n",
            "Episode: 523, Reward: 1.0, Steps in the episode: 247\n",
            "Episode: 524, Reward: 1.0, Steps in the episode: 123\n",
            "Episode: 525, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 526, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 527, Reward: 1.0, Steps in the episode: 23\n",
            "Episode: 528, Reward: 1.0, Steps in the episode: 88\n",
            "Episode: 529, Reward: 1.0, Steps in the episode: 185\n",
            "Episode: 530, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 531, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 532, Reward: 1.0, Steps in the episode: 708\n",
            "Episode: 533, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 534, Reward: 1.0, Steps in the episode: 383\n",
            "Episode: 535, Reward: 1.0, Steps in the episode: 662\n",
            "Episode: 536, Reward: 1.0, Steps in the episode: 360\n",
            "Episode: 537, Reward: 1.0, Steps in the episode: 90\n",
            "Episode: 538, Reward: 1.0, Steps in the episode: 88\n",
            "Episode: 539, Reward: 1.0, Steps in the episode: 64\n",
            "Episode: 540, Reward: 1.0, Steps in the episode: 152\n",
            "Episode: 541, Reward: 1.0, Steps in the episode: 130\n",
            "Episode: 542, Reward: 1.0, Steps in the episode: 853\n",
            "Episode: 543, Reward: 1.0, Steps in the episode: 631\n",
            "Episode: 544, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 545, Reward: 1.0, Steps in the episode: 38\n",
            "Episode: 546, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 547, Reward: 1.0, Steps in the episode: 58\n",
            "Episode: 548, Reward: 1.0, Steps in the episode: 633\n",
            "Episode: 549, Reward: 1.0, Steps in the episode: 199\n",
            "Episode: 550, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 551, Reward: 1.0, Steps in the episode: 53\n",
            "Episode: 552, Reward: 1.0, Steps in the episode: 456\n",
            "Episode: 553, Reward: 1.0, Steps in the episode: 411\n",
            "Episode: 554, Reward: 1.0, Steps in the episode: 44\n",
            "Episode: 555, Reward: 1.0, Steps in the episode: 747\n",
            "Episode: 556, Reward: 1.0, Steps in the episode: 209\n",
            "Episode: 557, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 558, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 559, Reward: 1.0, Steps in the episode: 331\n",
            "Episode: 560, Reward: 1.0, Steps in the episode: 796\n",
            "Episode: 561, Reward: 1.0, Steps in the episode: 246\n",
            "Episode: 562, Reward: 1.0, Steps in the episode: 724\n",
            "Episode: 563, Reward: 1.0, Steps in the episode: 281\n",
            "Episode: 564, Reward: 1.0, Steps in the episode: 255\n",
            "Episode: 565, Reward: 1.0, Steps in the episode: 222\n",
            "Episode: 566, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 567, Reward: 1.0, Steps in the episode: 2255\n",
            "Episode: 568, Reward: 1.0, Steps in the episode: 450\n",
            "Episode: 569, Reward: 1.0, Steps in the episode: 1147\n",
            "Episode: 570, Reward: 1.0, Steps in the episode: 423\n",
            "Episode: 571, Reward: 1.0, Steps in the episode: 150\n",
            "Episode: 572, Reward: 1.0, Steps in the episode: 96\n",
            "Episode: 573, Reward: 1.0, Steps in the episode: 329\n",
            "Episode: 574, Reward: 1.0, Steps in the episode: 605\n",
            "Episode: 575, Reward: 1.0, Steps in the episode: 1196\n",
            "Episode: 576, Reward: 1.0, Steps in the episode: 1981\n",
            "Episode: 577, Reward: 1.0, Steps in the episode: 816\n",
            "Episode: 578, Reward: 1.0, Steps in the episode: 636\n",
            "Episode: 579, Reward: 1.0, Steps in the episode: 327\n",
            "Episode: 580, Reward: 1.0, Steps in the episode: 1042\n",
            "Episode: 581, Reward: 1.0, Steps in the episode: 339\n",
            "Episode: 582, Reward: 1.0, Steps in the episode: 383\n",
            "Episode: 583, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 584, Reward: 1.0, Steps in the episode: 59\n",
            "Episode: 585, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 586, Reward: 1.0, Steps in the episode: 43\n",
            "Episode: 587, Reward: 1.0, Steps in the episode: 78\n",
            "Episode: 588, Reward: 1.0, Steps in the episode: 203\n",
            "Episode: 589, Reward: 1.0, Steps in the episode: 93\n",
            "Episode: 590, Reward: 1.0, Steps in the episode: 230\n",
            "Episode: 591, Reward: 1.0, Steps in the episode: 406\n",
            "Episode: 592, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 593, Reward: 1.0, Steps in the episode: 352\n",
            "Episode: 594, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 595, Reward: 1.0, Steps in the episode: 145\n",
            "Episode: 596, Reward: 1.0, Steps in the episode: 1061\n",
            "Episode: 597, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 598, Reward: 1.0, Steps in the episode: 499\n",
            "Episode: 599, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 600, Reward: 1.0, Steps in the episode: 18\n",
            "Episode: 601, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 602, Reward: 1.0, Steps in the episode: 515\n",
            "Episode: 603, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 604, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 605, Reward: 1.0, Steps in the episode: 304\n",
            "Episode: 606, Reward: 1.0, Steps in the episode: 332\n",
            "Episode: 607, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 608, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 609, Reward: 1.0, Steps in the episode: 1196\n",
            "Episode: 610, Reward: 1.0, Steps in the episode: 317\n",
            "Episode: 611, Reward: 1.0, Steps in the episode: 563\n",
            "Episode: 612, Reward: 1.0, Steps in the episode: 275\n",
            "Episode: 613, Reward: 1.0, Steps in the episode: 633\n",
            "Episode: 614, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 615, Reward: 1.0, Steps in the episode: 257\n",
            "Episode: 616, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 617, Reward: 1.0, Steps in the episode: 320\n",
            "Episode: 618, Reward: 1.0, Steps in the episode: 326\n",
            "Episode: 619, Reward: 1.0, Steps in the episode: 775\n",
            "Episode: 620, Reward: 1.0, Steps in the episode: 554\n",
            "Episode: 621, Reward: 1.0, Steps in the episode: 439\n",
            "Episode: 622, Reward: 1.0, Steps in the episode: 262\n",
            "Episode: 623, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 624, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 625, Reward: 1.0, Steps in the episode: 114\n",
            "Episode: 626, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 627, Reward: 1.0, Steps in the episode: 161\n",
            "Episode: 628, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 629, Reward: 1.0, Steps in the episode: 299\n",
            "Episode: 630, Reward: 1.0, Steps in the episode: 654\n",
            "Episode: 631, Reward: 1.0, Steps in the episode: 303\n",
            "Episode: 632, Reward: 1.0, Steps in the episode: 178\n",
            "Episode: 633, Reward: 1.0, Steps in the episode: 23\n",
            "Episode: 634, Reward: 1.0, Steps in the episode: 605\n",
            "Episode: 635, Reward: 1.0, Steps in the episode: 400\n",
            "Episode: 636, Reward: 1.0, Steps in the episode: 631\n",
            "Episode: 637, Reward: 1.0, Steps in the episode: 159\n",
            "Episode: 638, Reward: 1.0, Steps in the episode: 22\n",
            "Episode: 639, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 640, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 641, Reward: 1.0, Steps in the episode: 224\n",
            "Episode: 642, Reward: 1.0, Steps in the episode: 741\n",
            "Episode: 643, Reward: 1.0, Steps in the episode: 319\n",
            "Episode: 644, Reward: 1.0, Steps in the episode: 727\n",
            "Episode: 645, Reward: 1.0, Steps in the episode: 581\n",
            "Episode: 646, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 647, Reward: 1.0, Steps in the episode: 349\n",
            "Episode: 648, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 649, Reward: 1.0, Steps in the episode: 329\n",
            "Episode: 650, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 651, Reward: 1.0, Steps in the episode: 599\n",
            "Episode: 652, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 653, Reward: 1.0, Steps in the episode: 251\n",
            "Episode: 654, Reward: 1.0, Steps in the episode: 851\n",
            "Episode: 655, Reward: 1.0, Steps in the episode: 877\n",
            "Episode: 656, Reward: 1.0, Steps in the episode: 446\n",
            "Episode: 657, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 658, Reward: 1.0, Steps in the episode: 1562\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6e21233bf3d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdql_simple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_q_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dql_mid = deep_q_learning(environment_mid, memory, policy_net, target_net, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dql_hard = deep_q_learning(environment_hard, memory, policy_net, target_net, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-3dabd1928bbb>\u001b[0m in \u001b[0;36mdeep_q_learning\u001b[0;34m(env, memory, policy_net, target_net, optimizer, alpha, gamma, epsilon, epsilon_decay, target_update_freq, episodes)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;31m#Increment your reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtarget_update_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-80112b421041>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(memory, policy_net, target_net, gamma, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Spatial Computing for Path Planning - SCPP - Personalized algorithm\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2F69AEnJR85v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tqdk5DiyG2Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking availability of CUDA"
      ],
      "metadata": {
        "id": "JZ0LGCpfIltd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63O6X_KHIlZs",
        "outputId": "bb694669-21ec-471d-fe9f-a19d0e41a464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a new type of environment with a different step() method"
      ],
      "metadata": {
        "id": "MDc1Q2Oqr0VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SCPPEnvironment(DroneGrid):\n",
        "    def __init__(self, grid):\n",
        "        super().__init__(grid)\n",
        "\n",
        "    def step(self, action):\n",
        "        pass"
      ],
      "metadata": {
        "id": "Pv9gU_N6rw-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the neural network"
      ],
      "metadata": {
        "id": "TluBOVXiG2tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralAgent(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralAgent, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2W0_1r92HzDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute the input tensor during training"
      ],
      "metadata": {
        "id": "H4hTNDcOIYXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_input_tensor(env):\n",
        "    # Get the dimensions of the grid\n",
        "    height, width = env.grid.shape\n",
        "\n",
        "    # Get the agent's position\n",
        "    x, y = env.current_pos\n",
        "\n",
        "    # Initialize the input tensor with zeros\n",
        "    input_tensor = np.zeros(6)\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the left direction\n",
        "    for i in range(x-1, -1, -1):\n",
        "        if grid[i, y] == 1:\n",
        "            input_tensor[0] = x - i\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the right direction\n",
        "    for i in range(x+1, height):\n",
        "        if grid[i, y] == 1:\n",
        "            input_tensor[1] = i - x\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the up direction\n",
        "    for j in range(y-1, -1, -1):\n",
        "        if grid[x, j] == 1:\n",
        "            input_tensor[2] = y - j\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the down direction\n",
        "    for j in range(y+1, width):\n",
        "        if grid[x, j] == 1:\n",
        "            input_tensor[3] = j - y\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the goal in the horizontal direction\n",
        "    goal_position = np.argwhere(grid == 2)[0]\n",
        "    input_tensor[4] = goal_position[1] - y\n",
        "\n",
        "    # Calculate the distance to the goal in the vertical direction\n",
        "    input_tensor[5] = goal_position[0] - x\n",
        "\n",
        "    # Convert the input tensor to a PyTorch tensor\n",
        "    input_tensor = torch.tensor(input_tensor, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    return input_tensor"
      ],
      "metadata": {
        "id": "jz9K3bMWIX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of the training"
      ],
      "metadata": {
        "id": "j1CH12riHz1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scpp(agent, env, num_episodes, criterion, optimizer):\n",
        "    # Train the agent for a specified number of episodes\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset the environment\n",
        "        state = env.reset()\n",
        "\n",
        "        # Initialize the episode reward\n",
        "        episode_reward = 0\n",
        "\n",
        "        # Loop through the episode\n",
        "        while True:\n",
        "            # Convert the state to a PyTorch tensor\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            # Forward pass\n",
        "            action_probs = agent(state_tensor)\n",
        "\n",
        "            # Sample an action from the action probabilities\n",
        "            action = torch.multinomial(action_probs, num_samples=1).item()\n",
        "\n",
        "            # Take the action and observe the next state and reward\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # Update the episode reward\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Convert the next state to a PyTorch tensor\n",
        "            next_state_tensor = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            # Calculate the target tensor\n",
        "            with torch.no_grad():\n",
        "                next_action_probs = agent(next_state_tensor)\n",
        "                target = reward + 0.99 * torch.max(next_action_probs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(action_probs[0, action], target)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the state\n",
        "            state = next_state\n",
        "\n",
        "            # Check if the episode is done\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Print the episode reward every 100 episodes\n",
        "        if (episode + 1) % 100 == 0:\n",
        "            print(f'Episode [{episode+1}/{num_episodes}], Episode Reward: {episode_reward:.2f}')"
      ],
      "metadata": {
        "id": "KSyym_qEH3w0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}