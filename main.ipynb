{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "bBX0zw6KLQGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6WTp0fe_6KhH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining constants"
      ],
      "metadata": {
        "id": "nsm1FtoqLXmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STATE_SIZE = (10,10)\n",
        "ACTION_SIZE = 4"
      ],
      "metadata": {
        "id": "Fy8GkK8y6suf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining loading and saving of files"
      ],
      "metadata": {
        "id": "78prn4sdLunY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "Zmz1j9eb7gA7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(filename, Q_table):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(Q_table, f)"
      ],
      "metadata": {
        "id": "NqD37L7z7lC0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the static environment\n",
        "\n"
      ],
      "metadata": {
        "id": "CAxlCYl7LcDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneGrid():\n",
        "\n",
        "    def __init__(self, grid):\n",
        "\n",
        "        self.grid = grid\n",
        "        self.empty_grid = grid\n",
        "        self.grid_size = np.array(grid).shape\n",
        "        self.observation_space = (self.grid_size[0]), (self.grid_size[1])\n",
        "        self.action_space = [0, 1, 2, 3] # 4 discrete actions: 0 = up, 1 = down, 2 = left, 3 = right\n",
        "        self.start_pos = (0, 0)  # Starting position at top left corner\n",
        "        self.goal_pos = (self.grid_size[0] - 1, self.grid_size[1] - 1)  # Goal position at bottom right corner\n",
        "        self.current_pos = self.start_pos  # Initialize current position\n",
        "        self.grid[self.current_pos[1]][self.current_pos[0]] = 3\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_pos = self.start_pos  # Reset current position to start position\n",
        "        self.grid = self.empty_grid\n",
        "        return self.current_pos, self.grid  # Return initial state\n"
      ],
      "metadata": {
        "id": "TS8ylwsB6w8c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLEnvironment(DroneGrid):\n",
        "    def __init__(self, grid):\n",
        "        super().__init__(grid)\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        assert action in self.action_space, f\"Invalid action {action}\"  # Check if action is valid\n",
        "\n",
        "        # Define movement based on action\n",
        "        if action == 0:  # Up\n",
        "            new_pos = (self.current_pos[0], self.current_pos[1] - 1)\n",
        "        elif action == 1:  # Down\n",
        "            new_pos = (self.current_pos[0], self.current_pos[1] + 1)\n",
        "        elif action == 2:  # Left\n",
        "            new_pos = (self.current_pos[0] - 1, self.current_pos[1])\n",
        "        elif action == 3:  # Right\n",
        "            new_pos = (self.current_pos[0] + 1, self.current_pos[1])\n",
        "\n",
        "        # Check if new position is within bounds and not an obstacle\n",
        "        if 0 <= new_pos[0] < self.grid_size[0] and 0 <= new_pos[1] < self.grid_size[1] and self.grid[new_pos[1]][new_pos[0]] != 1:\n",
        "\n",
        "            self.current_pos = new_pos  # Update current position\n",
        "            self.grid = self.empty_grid # Erase previous position of the drone\n",
        "\n",
        "            # Check if goal state is reached\n",
        "            done = (self.current_pos == self.goal_pos)\n",
        "\n",
        "            # Calculate reward\n",
        "            if done:\n",
        "                reward = 1.0  # Positive reward for reaching the goal\n",
        "\n",
        "            else:\n",
        "                reward = 0 #Negative reward for non-goal state\n",
        "                self.grid[new_pos[1]][new_pos[0]] = 3 # Update new position of the drone\n",
        "\n",
        "\n",
        "        elif 0 <= new_pos[0] < self.grid_size[0] and 0 <= new_pos[1] < self.grid_size[1] and self.grid[new_pos[1]][new_pos[0]] == 1:\n",
        "                done = False\n",
        "                reward = -0.1 # Negative reward for going in a wall\n",
        "\n",
        "\n",
        "        else:\n",
        "            done = False\n",
        "            reward = 0  # Negative reward for going out of bounds\n",
        "\n",
        "        return self.current_pos, self.grid, reward, done"
      ],
      "metadata": {
        "id": "kjRZ2jnusiED"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute an action in function of the epsilon-greedy algorith"
      ],
      "metadata": {
        "id": "INRXclRKfUL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_action(current_state, Q_table, epsilon, environment):\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "        return np.random.choice(range(len(environment.action_space)))\n",
        "\n",
        "    else:\n",
        "        return np.argmax(Q_table[current_state])"
      ],
      "metadata": {
        "id": "jggC9KIOffdR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a personalized map"
      ],
      "metadata": {
        "id": "trQ9r7NkL3lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_simple = load('map_simple.pkl')\n",
        "print(map_simple)\n",
        "\n",
        "map_mid = load('map_mid.pkl')\n",
        "print(map_mid)\n",
        "\n",
        "map_hard = load('map_hard.pkl')\n",
        "print(map_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JQF9q-v-AQI",
        "outputId": "a23bda3f-6c3a-4216-87ba-373889d67776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an instance of the environment through the loaded map"
      ],
      "metadata": {
        "id": "NUWCssuaL9Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "environment_simple = QLEnvironment(map_simple)\n",
        "print(environment_simple.observation_space)\n",
        "print(environment_simple.action_space)\n",
        "\n",
        "environment_mid = QLEnvironment(map_mid)\n",
        "print(environment_mid.observation_space)\n",
        "print(environment_mid.action_space)\n",
        "\n",
        "environment_hard = QLEnvironment(map_hard)\n",
        "print(environment_hard.observation_space)\n",
        "print(environment_hard.action_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRYMCmkS-eqB",
        "outputId": "72f61d1d-83ce-4b18-8363-3fd6f9eff244"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 10)\n",
            "[0, 1, 2, 3]\n",
            "(10, 10)\n",
            "[0, 1, 2, 3]\n",
            "(10, 10)\n",
            "[0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Q-Learning\n",
        "---\n"
      ],
      "metadata": {
        "id": "ha7rhcl9BUpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_learning(env, alpha=1, gamma=0.99,  epsilon=0.99, epsilon_decay=0.00025, episodes = 10001, max_iter_episode = 500):\n",
        "    start_time = time.time()\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state in function of the epsilon_greedy\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) #Send your action to OpenAI and get back the tuple\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0]\n",
        "\n",
        "            total_reward += reward #Increment your reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma * np.max(Q[state_tp1_index]) - Q[current_state_index][action])\n",
        "\n",
        "             #Make sure to keep random at 10%\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "                break\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "\n",
        "        if epsilon>0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "    print(f\"Time: {delta_time}\")\n",
        "\n",
        "    return Q, rewards, delta_time"
      ],
      "metadata": {
        "id": "513kKA3J7CLh"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of the Q-Learning and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "fqBNpVXhMDGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_simple, rewards_q_simple, time_q_simple = q_learning(environment_simple)\n",
        "save('Simple - Q-Learning.pkl', q_simple)\n",
        "save('Rewards - Simple - Q-Learning.pkl', rewards_q_simple)\n",
        "save('Time - Simple - Q-Learning.pkl', time_q_simple)\n",
        "\n",
        "q_mid, rewards_q_mid, time_q_mid = q_learning(environment_mid)\n",
        "save('Mid - Q-Learning.pkl', q_mid)\n",
        "save('Rewards - Mid - Q-Learning.pkl', rewards_q_mid)\n",
        "save('Time - Mid - Q-Learning.pkl', time_q_mid)\n",
        "\n",
        "q_hard, rewards_q_hard, time_q_hard = q_learning(environment_hard)\n",
        "save('Hard - Q-Learning.pkl', q_hard)\n",
        "save('Rewards - Hard - Q-Learning.pkl', rewards_q_hard)\n",
        "save('Time - Hard - Q-Learning.pkl', time_q_hard)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ybGupCf-PAW",
        "outputId": "f38f1f25-a035-4903-93d0-fc2c13bbd379"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: 0.04600000000003276, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: 0.8229999999999797, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: 0.9215999999999895, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: 0.9551999999999933, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: 0.9702999999999958, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: 0.979499999999997, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: 0.9872999999999982, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.9910999999999985, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.9934999999999989, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: 0.9943999999999992, Epsilon: 0.09997847803039572\n",
            "Time: 17.49876308441162\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: -1.3165999999993647, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: 0.4241999999999832, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: 0.714799999999971, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: 0.8233999999999768, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: 0.8780999999999834, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: 0.9167999999999884, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: 0.940299999999991, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.955099999999993, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.968399999999995, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: 0.9704999999999956, Epsilon: 0.09997847803039572\n",
            "Time: 17.91339659690857\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: -4.4174999999987925, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: -0.4076000000001701, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: 0.309200000000005, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: 0.5879999999999671, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: 0.7326999999999675, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: 0.8021999999999739, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: 0.8631999999999813, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.8995999999999852, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.921199999999988, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: 0.9400999999999913, Epsilon: 0.09997847803039572\n",
            "Time: 30.50448775291443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - Q-Learning.pkl')\n",
        "files.download('Mid - Q-Learning.pkl')\n",
        "files.download('Hard - Q-Learning.pkl')\n",
        "\n",
        "files.download('Rewards - Simple - Q-Learning.pkl')\n",
        "files.download('Rewards - Mid - Q-Learning.pkl')\n",
        "files.download('Rewards - Hard - Q-Learning.pkl')\n",
        "\n",
        "files.download('Time - Simple - Q-Learning.pkl')\n",
        "files.download('Time - Mid - Q-Learning.pkl')\n",
        "files.download('Time - Hard - Q-Learning.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tj708eRQB6r-",
        "outputId": "d6a9760b-87d1-410e-b033-a6af8af87a8c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b2dcfda-4e60-4a2f-a2e2-18c19b648cd9\", \"Simple - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5edd8bc7-712d-4eab-826c-1af23856ba97\", \"Mid - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ca11731-8c9b-4215-8d4b-0f1a4a0c993e\", \"Hard - Q-Learning.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5cd10a04-c89d-4d87-a893-fe6c87bff0b1\", \"Rewards - Simple - Q-Learning.pkl\", 90153)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_457bbbc8-1bc7-4403-95de-07c1d0ffc5da\", \"Rewards - Mid - Q-Learning.pkl\", 90153)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d7f3d11-2ca4-41bd-abb4-61ccfcf65050\", \"Rewards - Hard - Q-Learning.pkl\", 90153)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_860e5c43-9532-4c83-b710-10cba12a34ca\", \"Time - Simple - Q-Learning.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4f5eadf-f3b2-42c5-aec1-09d2521a1f08\", \"Time - Mid - Q-Learning.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b80f441e-9200-432f-802b-220e0ce7698d\", \"Time - Hard - Q-Learning.pkl\", 21)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Q-Learning trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "9xF7_Sc3K9AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_q_simple = load('Simple - Q-Learning.pkl')\n",
        "rewards_q_simple = load('Rewards - Simple - Q-Learning.pkl')\n",
        "time_q_simple = load('Time - Simple - Q-Learning.pkl')\n",
        "#print('simple', trained_q_simple)\n",
        "print('rewards simple', len(rewards_q_simple))\n",
        "print('time simple', time_q_simple)\n",
        "\n",
        "#trained_q_mid = load('Mid - Q-Learning.pkl')\n",
        "#print('mid', trained_q_mid)\n",
        "rewards_q_mid = load('Rewards - Mid - Q-Learning.pkl')\n",
        "time_q_mid = load('Time - Mid - Q-Learning.pkl')\n",
        "\n",
        "print('rewards mid', len(rewards_q_mid))\n",
        "print('time mid', time_q_mid)\n",
        "\n",
        "#trained_q_hard = load('Hard - Q-Learning.pkl')\n",
        "#print('hard', trained_q_hard)\n",
        "rewards_q_hard = load('Rewards - Hard - Q-Learning.pkl')\n",
        "time_q_hard = load('Time - Hard - Q-Learning.pkl')\n",
        "\n",
        "print('rewards hard', len(rewards_q_hard))\n",
        "print('time hard', time_q_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WSOe6ObK73i",
        "outputId": "01f2ecd4-e759-4545-8fec-2d5e7bec714c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rewards simple 15017\n",
            "time simple 21.7232449054718\n",
            "rewards mid 15017\n",
            "time mid 22.858484029769897\n",
            "rewards hard 15017\n",
            "time hard 35.07642364501953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# SARSA\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "awOMcLSaLO6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sarsa(env, alpha=0.9, gamma=0.9,  epsilon=1, epsilon_decay=0.00025, episodes = 10001, max_iter_episode = 500):\n",
        "    start_time = time.time()\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state using Q-Table\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) # Send the action to the environment and obtain the new position, the reward and the termination flag\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0] # Compute the index of the state at t+1\n",
        "            action_tp1 = compute_action(state_tp1_index, Q, epsilon, env) # Compute the action for the next state using Q-Table\n",
        "\n",
        "            total_reward += reward # Increment the reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma*Q[state_tp1_index][action_tp1] - Q[current_state_index][action])\n",
        "\n",
        "             #Make sure to keep random at 10%\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "        if epsilon > 0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "    print(f\"Time: {delta_time}\")\n",
        "    return Q, rewards, delta_time"
      ],
      "metadata": {
        "id": "TbhauTm8Qx5q"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of SARSA and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "6GIdo4_LQ7es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_simple, rewards_s_simple, time_s_simple = sarsa(environment_simple)\n",
        "save('Simple - SARSA.pkl', s_simple)\n",
        "save('Rewards - Simple - SARSA.pkl', rewards_s_simple)\n",
        "save('Time - Simple - SARSA.pkl', time_s_simple)\n",
        "\n",
        "s_mid, rewards_s_mid, time_s_mid = sarsa(environment_mid)\n",
        "save('Mid - SARSA.pkl', s_mid)\n",
        "save('Rewards - Mid - SARSA.pkl', rewards_s_mid)\n",
        "save('Time - Mid - SARSA.pkl', time_s_mid)\n",
        "\n",
        "s_hard, rewards_s_hard, time_s_hard = sarsa(environment_hard)\n",
        "save('Hard - SARSA.pkl', s_hard)\n",
        "save('Rewards - Hard - SARSA.pkl', rewards_s_hard)\n",
        "save('Time - Hard - SARSA.pkl', time_s_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnzk9PyvRYN3",
        "outputId": "41d4411d-369b-4b4f-df78-34508feebc92"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: -1.0357000000001755, Epsilon: 0.7788007830714335\n",
            "Episode: 2000, Mean reward: 0.014000000000024236, Epsilon: 0.6065306597126773\n",
            "Episode: 3000, Mean reward: 0.3898999999999906, Epsilon: 0.4723665527410655\n",
            "Episode: 4000, Mean reward: 0.6622999999999706, Epsilon: 0.36787944117149507\n",
            "Episode: 5000, Mean reward: 0.7655999999999777, Epsilon: 0.2865047968602415\n",
            "Episode: 6000, Mean reward: 0.8072999999999805, Epsilon: 0.22313016014847828\n",
            "Episode: 7000, Mean reward: 0.8397999999999844, Epsilon: 0.17377394345048924\n",
            "Episode: 8000, Mean reward: 0.9152999999999925, Epsilon: 0.13533528323665214\n",
            "Episode: 9000, Mean reward: 0.8784999999999931, Epsilon: 0.10539922456189901\n",
            "Episode: 10000, Mean reward: 0.8834999999999935, Epsilon: 0.0999835106590795\n",
            "Time: 72.65182423591614\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: -3.4005999999975582, Epsilon: 0.7788007830714335\n",
            "Episode: 2000, Mean reward: -1.6532999999993925, Epsilon: 0.6065306597126773\n",
            "Episode: 3000, Mean reward: -0.8300000000002479, Epsilon: 0.4723665527410655\n",
            "Episode: 4000, Mean reward: -0.4178000000001201, Epsilon: 0.36787944117149507\n",
            "Episode: 5000, Mean reward: 0.006200000000002651, Epsilon: 0.2865047968602415\n",
            "Episode: 6000, Mean reward: 0.3059999999999964, Epsilon: 0.22313016014847828\n",
            "Episode: 7000, Mean reward: 0.5312999999999757, Epsilon: 0.17377394345048924\n",
            "Episode: 8000, Mean reward: 0.49239999999997774, Epsilon: 0.13533528323665214\n",
            "Episode: 9000, Mean reward: 0.5531999999999856, Epsilon: 0.10539922456189901\n",
            "Episode: 10000, Mean reward: 0.7030999999999843, Epsilon: 0.0999835106590795\n",
            "Time: 107.41615772247314\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 1\n",
            "Episode: 1000, Mean reward: -6.669500000006829, Epsilon: 0.7788007830714335\n",
            "Episode: 2000, Mean reward: -4.175399999997626, Epsilon: 0.6065306597126773\n",
            "Episode: 3000, Mean reward: -2.6448999999986524, Epsilon: 0.4723665527410655\n",
            "Episode: 4000, Mean reward: -1.769599999999469, Epsilon: 0.36787944117149507\n",
            "Episode: 5000, Mean reward: -1.1939000000000168, Epsilon: 0.2865047968602415\n",
            "Episode: 6000, Mean reward: -0.8340000000001324, Epsilon: 0.22313016014847828\n",
            "Episode: 7000, Mean reward: -0.559800000000062, Epsilon: 0.17377394345048924\n",
            "Episode: 8000, Mean reward: -0.3019000000000012, Epsilon: 0.13533528323665214\n",
            "Episode: 9000, Mean reward: -0.1496999999999942, Epsilon: 0.10539922456189901\n",
            "Episode: 10000, Mean reward: -0.13929999999999665, Epsilon: 0.0999835106590795\n",
            "Time: 197.2619607448578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading SARSA trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "_r3rgdWRRgJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_s_simple = load('Simple - SARSA.pkl')\n",
        "print('simple', trained_s_simple)\n",
        "\n",
        "trained_s_mid = load('Mid - SARSA.pkl')\n",
        "print('mid', trained_s_mid)\n",
        "\n",
        "trained_s_hard = load('Hard - SARSA.pkl')\n",
        "print('hard',trained_s_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8usIp5HRq7K",
        "outputId": "865f0cbb-2db7-490c-9b92-28627f49604c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple [[0.44567177 0.44728616 0.44286552 0.81373316]\n",
            " [0.4501721  0.6978284  0.4445712  0.70594054]\n",
            " [0.44446135 0.68351907 0.44634077 0.69530284]\n",
            " [0.6652588  0.67394763 0.44448787 0.5021277 ]\n",
            " [0.504806   0.68046397 0.5083074  0.5097628 ]\n",
            " [0.5007196  0.4999843  0.8650847  0.3661518 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6634075  0.6457142  0.47332165 0.8003355 ]\n",
            " [0.66966087 0.80144984 0.67579293 0.66756135]\n",
            " [0.64987856 0.9199013  0.6313867  0.64306194]\n",
            " [0.44743183 0.4493168  0.44489297 0.4392594 ]\n",
            " [0.70790976 0.39580634 0.44302082 0.43136746]\n",
            " [0.68225974 0.40249524 0.44756815 0.5032215 ]\n",
            " [0.67955256 0.40019432 0.6793649  0.6803811 ]\n",
            " [0.68197215 0.6691524  0.6737774  0.67031896]\n",
            " [0.506075   0.6755831  0.67561656 0.6654265 ]\n",
            " [0.65725535 0.67022943 0.528631   0.8997505 ]\n",
            " [0.47207808 0.85975456 0.6521792  0.65015733]\n",
            " [0.682654   0.65441257 0.6669527  0.6702138 ]\n",
            " [0.67464066 0.8960379  0.64969885 0.68135995]\n",
            " [0.4472489  0.4395988  0.4448456  0.4194471 ]\n",
            " [0.39637545 0.62692505 0.4583643  0.42319477]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6751587  0.46334675 0.5768832  0.6634563 ]\n",
            " [0.5035569  0.4606547  0.6691587  0.6574348 ]\n",
            " [0.6640522  0.4884401  0.66330963 0.66284597]\n",
            " [0.6669873  0.92077506 0.79475355 0.8679143 ]\n",
            " [0.6814921  0.7142257  0.8622353  0.6525082 ]\n",
            " [0.6440053  0.8956823  0.66331226 0.65670484]\n",
            " [0.44355717 0.360578   0.36941013 0.37273198]\n",
            " [0.22617729 0.6028319  0.43357733 0.4104158 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.7184118  0.715154   0.6633051  0.7062432 ]\n",
            " [0.4617705  0.700397   0.7132428  0.8529414 ]\n",
            " [0.48667887 0.48930064 0.5042189  0.8839329 ]\n",
            " [0.6721523  0.8694387  0.7918634  0.9140254 ]\n",
            " [0.6536045  0.94039416 0.8687225  0.68584746]\n",
            " [0.6901672  0.90363485 0.86057794 0.8847945 ]\n",
            " [0.4405398  0.4413835  0.44169995 0.440124  ]\n",
            " [0.46501434 0.6007354  0.4429562  0.46693128]\n",
            " [0.40543732 0.8046945  0.4589269  0.4402955 ]\n",
            " [0.5124023  0.49271366 0.7248742  0.46262535]\n",
            " [0.71259516 0.70822936 0.60677487 0.48692313]\n",
            " [0.7061226  0.6700948  0.48472977 0.48913988]\n",
            " [0.64228505 0.4900257  0.5930425  0.88894415]\n",
            " [0.87760496 0.87094164 0.87037414 0.88677526]\n",
            " [0.8949708  0.950968   0.8947271  0.89470345]\n",
            " [0.86921996 0.92094207 0.90355045 0.90371305]\n",
            " [0.59096    0.42117876 0.4328027  0.43713483]\n",
            " [0.4620544  0.71162933 0.45551774 0.47300056]\n",
            " [0.46732083 0.61202157 0.55907434 0.71141577]\n",
            " [0.7175596  0.7604368  0.5553728  0.7256488 ]\n",
            " [0.70688415 0.57512206 0.70738494 0.48933867]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.68350035 0.8080901  0.7505975  0.91352737]\n",
            " [0.9042417  0.9418478  0.940232   0.9410858 ]\n",
            " [0.911584   0.92246807 0.9502551  0.91397816]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.43615875 0.45490193 0.35252568 0.45723107]\n",
            " [0.47387853 0.4591697  0.5626364  0.83100367]\n",
            " [0.752993   0.6171306  0.61788815 0.6372003 ]\n",
            " [0.63176674 0.53506577 0.8307374  0.57237446]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.9393929  0.960596   0.8148022  0.8172406 ]\n",
            " [0.93170905 0.97010773 0.95097905 0.9228541 ]\n",
            " [0.9230308  0.92380303 0.9420479  0.9316918 ]\n",
            " [0.403424   0.49637583 0.40021342 0.45739672]\n",
            " [0.45468238 0.4611935  0.8426293  0.4593485 ]\n",
            " [0.62595296 0.6411583  0.46889845 0.47984362]\n",
            " [0.6189963  0.47244427 0.48697382 0.57299787]\n",
            " [0.623646   0.9398477  0.79602003 0.8651562 ]\n",
            " [0.8201318  0.94988644 0.573021   0.6976185 ]\n",
            " [0.67247355 0.9232853  0.88773036 0.92348665]\n",
            " [0.9232024  0.9323641  0.93187815 0.97010976]\n",
            " [0.9605829  0.98010004 0.94169176 0.94186157]\n",
            " [0.95127827 0.9153193  0.96992165 0.979904  ]\n",
            " [0.47572944 0.4743231  0.47523397 0.65528834]\n",
            " [0.45522073 0.6199303  0.47481516 0.46547666]\n",
            " [0.81481206 0.89041907 0.47007293 0.47790983]\n",
            " [0.80931854 0.86273664 0.8786578  0.9403806 ]\n",
            " [0.8782084  0.895951   0.93039197 0.95078003]\n",
            " [0.88753456 0.8851859  0.88133043 0.95940155]\n",
            " [0.9140762  0.9512726  0.9129203  0.9129766 ]\n",
            " [0.923225   0.98010004 0.9216158  0.97950745]\n",
            " [0.97010976 0.99       0.97029895 0.9153193 ]\n",
            " [0.92380303 1.         0.98009807 0.99      ]\n",
            " [0.47096795 0.4706116  0.47341233 0.63805467]\n",
            " [0.45244077 0.46954498 0.4705245  0.86895275]\n",
            " [0.51313597 0.869321   0.47473496 0.869792  ]\n",
            " [0.92941964 0.5964805  0.87179786 0.597875  ]\n",
            " [0.86979717 0.6821411  0.6064649  0.600509  ]\n",
            " [0.6987155  0.87895566 0.6812865  0.9225777 ]\n",
            " [0.8885658  0.9043696  0.88819665 0.9703001 ]\n",
            " [0.969925   0.96022516 0.9321699  0.99      ]\n",
            " [0.9800962  0.99       0.9509148  1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "mid [[ 0.1424276   0.1431843   0.18298288  0.6003691 ]\n",
            " [ 0.5942043   0.20754096  0.14246525  0.5939285 ]\n",
            " [ 0.02428232  0.8056469   0.02883808  0.5975223 ]\n",
            " [ 0.12089164  0.8237561   0.12312717  0.02043976]\n",
            " [ 0.1243939   0.5561753   0.1197564   0.01957284]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.3257401   0.32294434  0.32740074  0.64273554]\n",
            " [ 0.4315584   0.69383675  0.51167524  0.37575454]\n",
            " [ 0.4352138   0.3749626   0.5134975   0.5237126 ]\n",
            " [ 0.21455836  0.14428902  0.14388026  0.14244786]\n",
            " [ 0.69177073  0.10180416  0.14208946  0.1201145 ]\n",
            " [ 0.03446975  0.11050113  0.10208285  0.5956718 ]\n",
            " [ 0.11972867  0.1260393   0.5927625   0.817537  ]\n",
            " [ 0.02488958  0.849364    0.11857031  0.01931834]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.32618192  0.44190064  0.44556487  0.51540196]\n",
            " [ 0.51826525  0.90083027  0.5569407   0.5170433 ]\n",
            " [ 0.59830284  0.91389567  0.3947066   0.37639537]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.11111978  0.7265389   0.0034893   0.10408388]\n",
            " [ 0.12757532  0.7265827   0.09726053  0.3994923 ]\n",
            " [ 0.408912    0.02463239  0.72272134  0.5645082 ]\n",
            " [ 0.21768706  0.32269192  0.13771237  0.7676143 ]\n",
            " [ 0.41125163  0.70253336  0.32028663  0.40742853]\n",
            " [ 0.44374925  0.5137206   0.8279445   0.586368  ]\n",
            " [ 0.7259382   0.5223062   0.72542197  0.5894631 ]\n",
            " [ 0.59229803  0.83111984  0.7855293   0.8783241 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.10997849  0.67586386  0.00939789  0.70600504]\n",
            " [ 0.49895343  0.0617434   0.7073993   0.42211178]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.5074498   0.52241296  0.5755792   0.6141895 ]\n",
            " [ 0.6194338   0.8240127   0.51595616  0.579376  ]\n",
            " [ 0.5816424   0.92281383  0.80622804  0.84218746]\n",
            " [ 0.8119066   0.9476137   0.79950476  0.8338338 ]\n",
            " [ 0.16942789  0.18413305  0.27277824  0.7181529 ]\n",
            " [ 0.20651297  0.20426169  0.40155444  0.6752924 ]\n",
            " [ 0.50319433  0.6822967   0.6507996   0.658734  ]\n",
            " [ 0.05388802  0.20372309  0.50800943 -0.04140861]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.6749109   0.54428804  0.52565795  0.5198694 ]\n",
            " [ 0.64621544  0.63933045  0.7733492   0.8268478 ]\n",
            " [ 0.8324994   0.9497972   0.8269725   0.8283893 ]\n",
            " [ 0.8353348   0.9605616   0.8271103   0.837208  ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.26106656  0.19732799  0.09889492  0.75185007]\n",
            " [-0.03382231  0.44825763  0.20105459  0.83770424]\n",
            " [ 0.70185333  0.707165    0.7433024   0.9151701 ]\n",
            " [ 0.70001966  0.711816    0.75830287  0.9319331 ]\n",
            " [ 0.57289416  0.62695986  0.45335448  0.92366123]\n",
            " [ 0.8281546   0.55058724  0.6436175   0.82223123]\n",
            " [ 0.6552246   0.7426048   0.64000046  0.9592809 ]\n",
            " [ 0.8283198   0.970299    0.8212965   0.95898783]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.35303232  0.19312921  0.4525183   0.76241136]\n",
            " [ 0.85625523  0.42333272  0.44857973  0.38242385]\n",
            " [ 0.71075076  0.3827519   0.83808714  0.71258855]\n",
            " [ 0.7731736   0.7180218   0.7008446   0.625611  ]\n",
            " [ 0.63430274  0.7182815   0.7699647   0.63085526]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.8374831   0.98010004  0.8605747   0.8531523 ]\n",
            " [ 0.07901178  0.5590758   0.16676395 -0.0725259 ]\n",
            " [-0.07429671  0.02337185  0.08320998  0.6548437 ]\n",
            " [ 0.77989256  0.19010964  0.4685094   0.45324627]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.78921187  0.8409293   0.7241116   0.795244  ]\n",
            " [ 0.7949015   0.96057385  0.8851968   0.72393304]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.97029805  0.99        0.8801      0.97029793]\n",
            " [ 0.55723417  0.55529463  0.5535597   0.4873905 ]\n",
            " [ 0.18042582  0.5788975  -0.04683734  0.6635701 ]\n",
            " [ 0.6026757  -0.0214261   0.18464035  0.36935875]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.9038978   0.81588155  0.8487977   0.96057385]\n",
            " [ 0.8197972   0.74435025  0.9465956   0.970299  ]\n",
            " [ 0.83176637  0.98010004  0.96059227  0.97902095]\n",
            " [ 0.8801      0.99        0.9692209   0.9702999 ]\n",
            " [ 0.9801      1.          0.98010004  0.99      ]\n",
            " [ 0.551755    0.55908006  0.5591326   0.5484724 ]\n",
            " [-0.03854797  0.5484979   0.55390024  0.8121775 ]\n",
            " [ 0.6772598   0.71184367 -0.0294175   0.7130007 ]\n",
            " [ 0.7341259   0.72481036  0.72014236  0.74168426]\n",
            " [ 0.69209695  0.6862458   0.7135785   0.7552878 ]\n",
            " [ 0.94687057  0.7371661   0.75513816  0.74435025]\n",
            " [ 0.9599309   0.9601243   0.7495636   0.98010004]\n",
            " [ 0.9702952   0.96078634  0.9702934   0.9703067 ]\n",
            " [ 0.9801      0.989999    0.97990686  1.        ]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "hard [[-0.01838733 -0.01267159 -0.01368699 -0.0193904 ]\n",
            " [-0.08163207 -0.08963685 -0.01793873 -0.068295  ]\n",
            " [-0.02293469 -0.06316753 -0.03451106 -0.06271549]\n",
            " [-0.10797756 -0.03310829 -0.06830779 -0.11895342]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.19165029 -0.26805323 -0.26799327 -0.383268  ]\n",
            " [-0.38752356 -0.40950683 -0.1916347  -0.6670537 ]\n",
            " [-0.7532703  -0.77512884 -0.3119838  -0.78315264]\n",
            " [-0.88924676 -0.80829334 -0.59357995 -0.75601625]\n",
            " [-0.01277604 -0.01627237 -0.03562086 -0.01358959]\n",
            " [-0.07458296 -0.11851329 -0.01276015 -0.09959544]\n",
            " [-0.03001312 -0.16631375 -0.10767863 -0.11270674]\n",
            " [-0.11684296 -0.09576972 -0.02196078 -0.13085954]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.18003866 -0.4352955  -0.40858302 -0.26186904]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.5665099  -0.68128663 -0.7542214  -0.66990155]\n",
            " [-0.04251118 -0.13932858 -0.13584866 -0.01233288]\n",
            " [-0.01007279 -0.13721226 -0.12312213 -0.12911966]\n",
            " [-0.07588761 -0.18258135 -0.14173882 -0.1350481 ]\n",
            " [-0.04085248 -0.14235985 -0.12426402 -0.14606646]\n",
            " [-0.1554751  -0.23623633 -0.10709427 -0.41972303]\n",
            " [-0.17754716 -0.14362882 -0.12151676 -0.459855  ]\n",
            " [-0.18060619 -0.1137665  -0.06592258 -0.17092289]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.57568216 -0.5645995  -0.72632444 -0.5308014 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.0373408  -0.18753786 -0.14767992 -0.16958502]\n",
            " [-0.06155614 -0.15680881 -0.18473905 -0.14107871]\n",
            " [-0.2329784  -0.24831592 -0.08084831 -0.17556581]\n",
            " [-0.1403379  -0.2812289  -0.20476851 -0.26827475]\n",
            " [-0.06682602 -0.29359868 -0.36124477 -0.51705104]\n",
            " [-0.5907472  -0.3640078  -0.37668937 -0.5417424 ]\n",
            " [-0.62929296 -0.57085377 -0.39056274 -0.61436564]\n",
            " [-0.6958564  -0.4593427  -0.6130374  -0.6303027 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.33998123 -0.5635427  -0.4970866  -0.5408644 ]\n",
            " [-0.38648885 -0.64370507 -0.6455399  -0.4753485 ]\n",
            " [-0.59811854 -0.58336645 -0.4714622  -0.5757587 ]\n",
            " [-0.9249125  -0.96306944 -1.0012532  -1.0993634 ]\n",
            " [-1.117732   -1.1440812  -0.93013453 -1.2191777 ]\n",
            " [-1.2201557  -1.2653303  -1.1907308  -1.1516272 ]\n",
            " [-1.2670816  -0.60381514 -1.161734   -1.5626174 ]\n",
            " [-1.6801662  -1.3983352  -1.0748496  -1.6923004 ]\n",
            " [-1.2510488  -1.1716808  -1.5870143  -1.3556466 ]\n",
            " [-0.7235278  -1.4681894  -0.74986243 -0.62446654]\n",
            " [-0.24313398 -0.70989823 -1.3696309  -0.6512715 ]\n",
            " [-0.5438348  -0.6623636  -1.271716   -0.5665411 ]\n",
            " [-0.58470464 -0.8543473  -0.561911   -0.5917745 ]\n",
            " [-0.99870545 -0.9000979  -1.041796   -1.0178258 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-1.2934679  -0.40709195 -1.3552151  -1.280146  ]\n",
            " [-1.5745934  -1.4852914  -1.0153427  -1.1496676 ]\n",
            " [-1.5453156  -1.4863265  -1.4364501  -1.1664237 ]\n",
            " [-1.3282877  -1.6444207  -1.5020407  -0.53083545]\n",
            " [-0.5923658  -0.718723   -0.6777216  -1.5658458 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-1.0326086  -0.880725   -1.056351   -1.1554664 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-1.162048   -0.42160943 -1.2349195  -1.6735494 ]\n",
            " [-1.4234067  -1.7882231  -1.177829   -1.1271453 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-1.04444    -0.89712346 -1.0064641  -1.0290519 ]\n",
            " [-0.9463652  -1.057297   -0.87536526 -0.9326911 ]\n",
            " [-1.0653975  -0.4476327  -0.8262168  -0.6206135 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.00353448 -0.2762897  -0.03957358  0.06457656]\n",
            " [-0.16385035  0.0822586   0.04902069  0.03263004]\n",
            " [-0.03291882 -0.02877124  0.03106229  0.9775181 ]\n",
            " [ 0.77047265  0.9745976   0.83926994  0.9899019 ]\n",
            " [ 0.88901097  1.          0.9268574   0.        ]\n",
            " [-0.8680957  -0.9213138  -0.9086234  -0.89971006]\n",
            " [-0.9294272  -0.91343427 -0.8508989  -0.31978184]\n",
            " [-0.45351294 -0.89835376 -0.6698833  -0.00956528]\n",
            " [-0.30453765 -0.28997317 -0.32205355 -0.686425  ]\n",
            " [-0.0880785   0.03984078 -0.29259223  0.06244925]\n",
            " [-0.03118046 -0.3303304  -0.3215702   0.03754476]\n",
            " [ 0.08158608 -0.0142335   0.00508927 -0.01232587]\n",
            " [-0.01436794 -0.02021754 -0.08918333  0.9796207 ]\n",
            " [ 0.951128   -0.04874479  0.9753454   1.        ]\n",
            " [ 0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - SARSA.pkl')\n",
        "files.download('Mid - SARSA.pkl')\n",
        "files.download('Hard - SARSA.pkl')\n",
        "\n",
        "files.download('Rewards - Simple - SARSA.pkl')\n",
        "files.download('Rewards - Mid - SARSA.pkl')\n",
        "files.download('Rewards - Hard - SARSA.pkl')\n",
        "\n",
        "files.download('Time - Simple - SARSA.pkl')\n",
        "files.download('Time - Mid - SARSA.pkl')\n",
        "files.download('Time - Hard - SARSA.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N2jNnqvmEh89",
        "outputId": "e770b062-e95a-4407-e46d-4f7a729ff5a4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cfa805cf-6a06-4568-bc0e-4d78ff0e7cff\", \"Simple - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4f0579a9-fe3f-4a75-8374-722483ea744a\", \"Mid - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_73f663ad-f654-4c63-a26b-9df3c75b3e0a\", \"Hard - SARSA.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3838897a-85d3-4c16-8839-0bb71b8deb7c\", \"Rewards - Simple - SARSA.pkl\", 89551)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c4c7378-9561-43ae-bfdf-dda9613f1e69\", \"Rewards - Mid - SARSA.pkl\", 89705)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b7cd1c8-d0f2-49f3-a783-339fb8230f8c\", \"Rewards - Hard - SARSA.pkl\", 80696)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4412da48-f02a-48db-bfcb-8c5c69b71507\", \"Time - Simple - SARSA.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc1c4fd1-d2ea-4a02-9939-a2193159aab3\", \"Time - Mid - SARSA.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e06e04a1-f16b-470a-8bbb-f1905ca440ec\", \"Time - Hard - SARSA.pkl\", 21)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Alternating Q-Learning / SARSA\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7wHNHgF7R0Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alternating(env, alpha=1, gamma=0.9,  epsilon=0.99, epsilon_decay=0.00025, episodes = 10001, max_iter_episode = 500):\n",
        "    start_time = time.time()\n",
        "    Q = np.zeros((env.grid_size[0]*env.grid_size[1], len(env.action_space)), dtype=np.float32) #Initialize the Q table to all 0s\n",
        "    rewards = []\n",
        "    mean_reward_for_1k_episode = 0\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state, _ = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        iteration = 0\n",
        "\n",
        "        if e % 1000 == 0:\n",
        "            mean_reward_for_1k_episode = float(mean_reward_for_1k_episode / 1000)\n",
        "            rewards.append(mean_reward_for_1k_episode)\n",
        "            print(f\"Episode: {e}, Mean reward: {mean_reward_for_1k_episode}, Epsilon: {epsilon}\")\n",
        "            mean_reward_for_1k_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "\n",
        "            random_num = random.random() # Generate a random number between 0 and 1\n",
        "\n",
        "            current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            action = compute_action(current_state_index, Q, epsilon, env) # Compute the action for the current state using Q-Table\n",
        "\n",
        "            posp1, _, reward, done = env.step(action) # Send the action to the environment and obtain the new position, the reward and the termination flag\n",
        "\n",
        "            state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0] # Compute the index of the state at t+1\n",
        "            action_tp1 = compute_action(state_tp1_index, Q, epsilon, env) # Compute the action for the next state using Q-Table\n",
        "\n",
        "            total_reward += reward # Increment the reward\n",
        "            mean_reward_for_1k_episode += reward\n",
        "\n",
        "            if (random_num <= 0.5): # We use Q-learning\n",
        "                Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma * np.max(Q[state_tp1_index]) - Q[current_state_index][action])\n",
        "\n",
        "            else: # We use SARSA\n",
        "                Q[current_state_index][action] = Q[current_state_index][action] + alpha * (reward + gamma*Q[state_tp1_index][action_tp1] - Q[current_state_index][action])\n",
        "\n",
        "            if done:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration >= max_iter_episode:\n",
        "                #print(f\"Episode: {e}, Reward: {total_reward}\")\n",
        "                break\n",
        "\n",
        "        if epsilon > 0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "    print(f\"Time: {delta_time}\")\n",
        "\n",
        "    return Q, rewards, delta_time"
      ],
      "metadata": {
        "id": "Fv7jMbGIR219"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective running of alternating Q-Learning/SARSA and saving of the trained Q-Table"
      ],
      "metadata": {
        "id": "n6YOUC1AccKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_simple, rewards_a_simple, time_a_simple = alternating(environment_simple)\n",
        "save('Simple - Alternating.pkl', a_simple)\n",
        "save('Rewards - Simple - Alternating.pkl', rewards_a_simple)\n",
        "save('Time - Simple - Alternating.pkl', time_a_simple)\n",
        "\n",
        "a_mid, rewards_a_mid, time_a_mid = alternating(environment_mid)\n",
        "save('Mid - Alternating.pkl', a_mid)\n",
        "save('Rewards - Mid - Alternating.pkl', rewards_a_mid)\n",
        "save('Time - Mid - Alternating.pkl', time_a_mid)\n",
        "\n",
        "a_hard, rewards_a_hard, time_a_hard = alternating(environment_hard)\n",
        "save('Hard - Alternating.pkl', a_hard)\n",
        "save('Rewards - Hard - Alternating.pkl', rewards_a_hard)\n",
        "save('Time - Hard - Alternating.pkl', time_a_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb-whO11ccrf",
        "outputId": "99175676-bcd3-49ee-ebb0-b23d2752ba90"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: -0.3400000000001813, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: 0.6193999999999744, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: 0.793299999999979, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: 0.8805999999999828, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: 0.9251999999999906, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: 0.9428999999999921, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: 0.9587999999999939, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.9723999999999964, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.9846999999999978, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: 0.9808999999999964, Epsilon: 0.09997847803039572\n",
            "Time: 36.44415831565857\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: -2.2387999999984456, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: -0.04959999999995778, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: 0.4400999999999785, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: 0.6513999999999676, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: 0.744899999999973, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: 0.8258999999999767, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: 0.8674999999999828, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.917299999999988, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.9218999999999895, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: 0.9350999999999914, Epsilon: 0.09997847803039572\n",
            "Time: 41.443246603012085\n",
            "Episode: 0, Mean reward: 0.0, Epsilon: 0.99\n",
            "Episode: 1000, Mean reward: -6.468900000006797, Epsilon: 0.7710127752407178\n",
            "Episode: 2000, Mean reward: -3.3507999999975584, Epsilon: 0.60046535311555\n",
            "Episode: 3000, Mean reward: -1.9339999999989932, Epsilon: 0.467642887213655\n",
            "Episode: 4000, Mean reward: -1.089000000000103, Epsilon: 0.36420064675978037\n",
            "Episode: 5000, Mean reward: -0.4485000000001307, Epsilon: 0.28363974889163973\n",
            "Episode: 6000, Mean reward: -0.36540000000001055, Epsilon: 0.22089885854699348\n",
            "Episode: 7000, Mean reward: -0.059699999999973025, Epsilon: 0.1720362040159844\n",
            "Episode: 8000, Mean reward: 0.044900000000008, Epsilon: 0.1339819304042855\n",
            "Episode: 9000, Mean reward: 0.23060000000001007, Epsilon: 0.10434523231627953\n",
            "Episode: 10000, Mean reward: -0.04900000000000072, Epsilon: 0.09997847803039572\n",
            "Time: 145.92025876045227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading alternating trained Q-Table and checking if successful"
      ],
      "metadata": {
        "id": "SpPjMa9NceFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_a_simple = load('Simple - Alternating.pkl')\n",
        "print(trained_a_simple)\n",
        "\n",
        "trained_a_mid = load('Mid - Alternating.pkl')\n",
        "print(trained_a_mid)\n",
        "\n",
        "trained_a_hard = load('Hard - Alternating.pkl')\n",
        "print(trained_a_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzTcbx-cdPk",
        "outputId": "c92dd2cf-1157-49d1-85b8-134e9bd2eee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.06461082 0.0717898  0.06461082 0.0717898 ]\n",
            " [0.0717898  0.06461082 0.07976644 0.07976644]\n",
            " [0.0717898  0.06461082 0.05814974 0.07976644]\n",
            " [0.09847709 0.05233477 0.08862938 0.10941899]\n",
            " [0.09847709 0.12157665 0.09847709 0.10941899]\n",
            " [0.12157665 0.18530202 0.09847709 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.16677181 0.22876792 0.25418657 0.16677181]\n",
            " [0.13508517 0.13508517 0.25418657 0.0717898 ]\n",
            " [0.12157665 0.28242952 0.07976644 0.0717898 ]\n",
            " [0.06461082 0.15009463 0.0717898  0.07976644]\n",
            " [0.0717898  0.05814974 0.04710129 0.0717898 ]\n",
            " [0.0717898  0.0717898  0.04239116 0.05233477]\n",
            " [0.09847709 0.09847709 0.09847709 0.05814974]\n",
            " [0.12157665 0.12157665 0.12157665 0.18530202]\n",
            " [0.13508517 0.13508517 0.16677181 0.20589113]\n",
            " [0.20589113 0.20589113 0.12157665 0.25418657]\n",
            " [0.25418657 0.3138106  0.22876792 0.25418657]\n",
            " [0.13508517 0.28242952 0.18530202 0.22876792]\n",
            " [0.20589113 0.34867844 0.25418657 0.25418657]\n",
            " [0.0717898  0.15009463 0.05814974 0.05814974]\n",
            " [0.04239116 0.06461082 0.06461082 0.05814974]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.16677181 0.15009463 0.13508517]\n",
            " [0.16677181 0.15009463 0.22876792 0.22876792]\n",
            " [0.22876792 0.3138106  0.22876792 0.20589113]\n",
            " [0.28242952 0.34867844 0.22876792 0.25418657]\n",
            " [0.25418657 0.47829688 0.28242952 0.25418657]\n",
            " [0.3138106  0.4304672  0.25418657 0.25418657]\n",
            " [0.05814974 0.08862938 0.16677181 0.16677181]\n",
            " [0.06461082 0.18530202 0.08862938 0.16677181]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.13508517 0.15009463 0.18530202]\n",
            " [0.12157665 0.18530202 0.20589113 0.28242952]\n",
            " [0.15009463 0.22876792 0.22876792 0.4304672 ]\n",
            " [0.3138106  0.25418657 0.28242952 0.38742048]\n",
            " [0.28242952 0.4304672  0.22876792 0.38742048]\n",
            " [0.25418657 0.22876792 0.38742048 0.38742048]\n",
            " [0.05233477 0.20589113 0.08862938 0.09847709]\n",
            " [0.16677181 0.15009463 0.10941899 0.16677181]\n",
            " [0.15009463 0.20589113 0.16677181 0.12157665]\n",
            " [0.20589113 0.25418657 0.16677181 0.16677181]\n",
            " [0.13508517 0.15009463 0.22876792 0.16677181]\n",
            " [0.22876792 0.18530202 0.18530202 0.18530202]\n",
            " [0.25418657 0.22876792 0.16677181 0.3138106 ]\n",
            " [0.28242952 0.4304672  0.28242952 0.4304672 ]\n",
            " [0.38742048 0.4304672  0.38742048 0.25418657]\n",
            " [0.20589113 0.531441   0.28242952 0.34867844]\n",
            " [0.09847709 0.0717898  0.22876792 0.15009463]\n",
            " [0.12157665 0.15009463 0.08862938 0.15009463]\n",
            " [0.16677181 0.22876792 0.15009463 0.18530202]\n",
            " [0.22876792 0.3138106  0.25418657 0.20589113]\n",
            " [0.18530202 0.16677181 0.22876792 0.16677181]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25418657 0.38742048 0.34867844 0.59049   ]\n",
            " [0.4304672  0.531441   0.34867844 0.34867844]\n",
            " [0.47829688 0.47829688 0.47829688 0.34867844]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.15009463 0.22876792 0.16677181 0.18530202]\n",
            " [0.16677181 0.22876792 0.18530202 0.18530202]\n",
            " [0.13508517 0.25418657 0.20589113 0.22876792]\n",
            " [0.16677181 0.38742048 0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.4304672  0.4304672  0.34867844]\n",
            " [0.4304672  0.47829688 0.4304672  0.47829688]\n",
            " [0.47829688 0.531441   0.34867844 0.531441  ]\n",
            " [0.16677181 0.13508517 0.15009463 0.20589113]\n",
            " [0.16677181 0.22876792 0.18530202 0.20589113]\n",
            " [0.20589113 0.22876792 0.16677181 0.28242952]\n",
            " [0.22876792 0.25418657 0.18530202 0.28242952]\n",
            " [0.28242952 0.25418657 0.25418657 0.3138106 ]\n",
            " [0.28242952 0.3138106  0.3138106  0.47829688]\n",
            " [0.38742048 0.3138106  0.34867844 0.6561    ]\n",
            " [0.47829688 0.729      0.47829688 0.729     ]\n",
            " [0.531441   0.531441   0.531441   0.6561    ]\n",
            " [0.47829688 0.9        0.59049    0.531441  ]\n",
            " [0.15009463 0.16677181 0.13508517 0.12157665]\n",
            " [0.22876792 0.18530202 0.15009463 0.15009463]\n",
            " [0.25418657 0.20589113 0.16677181 0.15009463]\n",
            " [0.16677181 0.22876792 0.18530202 0.28242952]\n",
            " [0.28242952 0.3138106  0.28242952 0.3138106 ]\n",
            " [0.4304672  0.34867844 0.34867844 0.25418657]\n",
            " [0.34867844 0.28242952 0.3138106  0.729     ]\n",
            " [0.4304672  0.81       0.4304672  0.6561    ]\n",
            " [0.59049    0.9        0.59049    0.729     ]\n",
            " [0.81       1.         0.81       0.9       ]\n",
            " [0.16677181 0.16677181 0.13508517 0.22876792]\n",
            " [0.22876792 0.20589113 0.16677181 0.18530202]\n",
            " [0.22876792 0.22876792 0.20589113 0.20589113]\n",
            " [0.25418657 0.22876792 0.25418657 0.25418657]\n",
            " [0.28242952 0.3138106  0.28242952 0.34867844]\n",
            " [0.38742048 0.34867844 0.3138106  0.3138106 ]\n",
            " [0.4304672  0.3138106  0.34867844 0.81      ]\n",
            " [0.47829688 0.4304672  0.729      0.9       ]\n",
            " [0.6561     0.9        0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.07976644 0.07976644 0.07976644 0.0717898 ]\n",
            " [0.07976644 0.07976644 0.07976644 0.10941899]\n",
            " [0.09847709 0.08862938 0.09847709 0.09847709]\n",
            " [0.10941899 0.10941899 0.10941899 0.13508517]\n",
            " [0.12157665 0.15009463 0.12157665 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.13508517 0.20589113 0.13508517 0.15009463]\n",
            " [0.18530202 0.22876792 0.15009463 0.13508517]\n",
            " [0.15009463 0.25418657 0.13508517 0.15009463]\n",
            " [0.07976644 0.0717898  0.07976644 0.09847709]\n",
            " [0.0717898  0.07976644 0.07976644 0.09847709]\n",
            " [0.10941899 0.09847709 0.06461082 0.09847709]\n",
            " [0.09847709 0.09847709 0.10941899 0.06461082]\n",
            " [0.13508517 0.28242952 0.16677181 0.15009463]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.22876792 0.22876792 0.22876792]\n",
            " [0.20589113 0.25418657 0.20589113 0.22876792]\n",
            " [0.25418657 0.4304672  0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.09847709 0.10941899 0.10941899 0.10941899]\n",
            " [0.08862938 0.20589113 0.09847709 0.08862938]\n",
            " [0.06461082 0.12157665 0.09847709 0.28242952]\n",
            " [0.18530202 0.18530202 0.13508517 0.18530202]\n",
            " [0.16677181 0.28242952 0.18530202 0.18530202]\n",
            " [0.20589113 0.20589113 0.20589113 0.25418657]\n",
            " [0.13508517 0.25418657 0.22876792 0.47829688]\n",
            " [0.28242952 0.38742048 0.25418657 0.22876792]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.10941899 0.25418657 0.12157665 0.12157665]\n",
            " [0.10941899 0.22876792 0.10941899 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28242952 0.20589113 0.3138106  0.18530202]\n",
            " [0.22876792 0.3138106  0.28242952 0.34867844]\n",
            " [0.22876792 0.34867844 0.25418657 0.20589113]\n",
            " [0.34867844 0.3138106  0.34867844 0.3138106 ]\n",
            " [0.13508517 0.07976644 0.07976644 0.18530202]\n",
            " [0.10941899 0.10941899 0.0717898  0.12157665]\n",
            " [0.10941899 0.10941899 0.12157665 0.3138106 ]\n",
            " [0.25418657 0.34867844 0.25418657 0.25418657]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.20589113 0.22876792 0.20589113]\n",
            " [0.25418657 0.22876792 0.22876792 0.34867844]\n",
            " [0.22876792 0.3138106  0.3138106  0.38742048]\n",
            " [0.3138106  0.38742048 0.34867844 0.34867844]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.15009463 0.25418657 0.34867844]\n",
            " [0.25418657 0.20589113 0.25418657 0.38742048]\n",
            " [0.20589113 0.4304672  0.34867844 0.4304672 ]\n",
            " [0.4304672  0.47829688 0.34867844 0.38742048]\n",
            " [0.20589113 0.531441   0.4304672  0.22876792]\n",
            " [0.38742048 0.25418657 0.38742048 0.18530202]\n",
            " [0.34867844 0.3138106  0.34867844 0.6561    ]\n",
            " [0.34867844 0.729      0.4304672  0.6561    ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25418657 0.16677181 0.16677181 0.16677181]\n",
            " [0.20589113 0.20589113 0.15009463 0.22876792]\n",
            " [0.16677181 0.18530202 0.16677181 0.4304672 ]\n",
            " [0.4304672  0.47829688 0.4304672  0.531441  ]\n",
            " [0.38742048 0.47829688 0.4304672  0.531441  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.47829688 0.47829688 0.59049   ]\n",
            " [0.09847709 0.08862938 0.10941899 0.10941899]\n",
            " [0.10941899 0.18530202 0.10941899 0.09847709]\n",
            " [0.15009463 0.12157665 0.10941899 0.09847709]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.20589113 0.531441   0.531441   0.59049   ]\n",
            " [0.47829688 0.6561     0.531441   0.47829688]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.4304672  0.9        0.47829688 0.531441  ]\n",
            " [0.09847709 0.18530202 0.12157665 0.16677181]\n",
            " [0.16677181 0.16677181 0.12157665 0.12157665]\n",
            " [0.13508517 0.09847709 0.12157665 0.10941899]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.34867844 0.531441   0.531441   0.6561    ]\n",
            " [0.47829688 0.59049    0.59049    0.729     ]\n",
            " [0.729      0.729      0.6561     0.38742048]\n",
            " [0.6561     0.9        0.6561     0.4304672 ]\n",
            " [0.81       1.         0.729      0.9       ]\n",
            " [0.12157665 0.16677181 0.16677181 0.34867844]\n",
            " [0.18530202 0.18530202 0.15009463 0.38742048]\n",
            " [0.10941899 0.22876792 0.13508517 0.3138106 ]\n",
            " [0.25418657 0.25418657 0.22876792 0.47829688]\n",
            " [0.34867844 0.34867844 0.3138106  0.531441  ]\n",
            " [0.38742048 0.25418657 0.47829688 0.47829688]\n",
            " [0.6561     0.531441   0.531441   0.47829688]\n",
            " [0.729      0.729      0.47829688 0.729     ]\n",
            " [0.81       0.9        0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.00785517 0.00872796 0.00872796 0.01077527]\n",
            " [0.01077527 0.00969774 0.00872796 0.01197252]\n",
            " [0.00706965 0.00706965 0.00872796 0.0133028 ]\n",
            " [0.0133028  0.01478088 0.00706965 0.01478088]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.01077527 0.00969774 0.01077527 0.02027556]\n",
            " [0.01077527 0.01077527 0.00969774 0.0225284 ]\n",
            " [0.00572642 0.0225284  0.00706965 0.0225284 ]\n",
            " [0.02027556 0.03433684 0.00636269 0.02027556]\n",
            " [0.00872796 0.00872796 0.00969774 0.00969774]\n",
            " [0.00969774 0.00969774 0.01077527 0.00785517]\n",
            " [0.01197252 0.01478088 0.00785517 0.01077527]\n",
            " [0.0133028  0.0164232  0.01077527 0.0164232 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.00969774 0.02503156 0.02503156 0.018248  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.03433684 0.03433684 0.03433684 0.03433684]\n",
            " [0.00872796 0.00969774 0.00872796 0.00969774]\n",
            " [0.00969774 0.00636269 0.00872796 0.01077527]\n",
            " [0.00969774 0.01197252 0.01077527 0.0133028 ]\n",
            " [0.01478088 0.01478088 0.01478088 0.018248  ]\n",
            " [0.018248   0.0133028  0.0164232  0.00636269]\n",
            " [0.00706965 0.01478088 0.018248   0.02027556]\n",
            " [0.0164232  0.0225284  0.018248   0.01478088]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.03433684 0.03433684 0.02781284 0.03815204]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.01197252 0.01197252 0.0133028  0.01478088]\n",
            " [0.0133028  0.0133028  0.01077527 0.03815204]\n",
            " [0.018248   0.01478088 0.01197252 0.04239116]\n",
            " [0.018248   0.0225284  0.0164232  0.05233477]\n",
            " [0.02027556 0.0225284  0.04239116 0.05814974]\n",
            " [0.02781284 0.05814974 0.03090315 0.03815204]\n",
            " [0.01478088 0.02503156 0.05233477 0.02027556]\n",
            " [0.03815204 0.0717898  0.0225284  0.0164232 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.02781284 0.08862938 0.05814974 0.02503156]\n",
            " [0.03815204 0.07976644 0.02781284 0.08862938]\n",
            " [0.06461082 0.0717898  0.07976644 0.03090315]\n",
            " [0.0717898  0.0717898  0.08862938 0.09847709]\n",
            " [0.09847709 0.09847709 0.08862938 0.10941899]\n",
            " [0.10941899 0.10941899 0.09847709 0.13508517]\n",
            " [0.09847709 0.10941899 0.10941899 0.10941899]\n",
            " [0.10941899 0.10941899 0.09847709 0.12157665]\n",
            " [0.09847709 0.07976644 0.10941899 0.05233477]\n",
            " [0.07976644 0.06461082 0.09847709 0.07976644]\n",
            " [0.03433684 0.08862938 0.08862938 0.07976644]\n",
            " [0.03433684 0.03090315 0.02781284 0.08862938]\n",
            " [0.02781284 0.03090315 0.07976644 0.07976644]\n",
            " [0.08862938 0.15009463 0.10941899 0.08862938]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.09847709 0.13508517 0.12157665 0.12157665]\n",
            " [0.10941899 0.12157665 0.12157665 0.12157665]\n",
            " [0.10941899 0.07976644 0.10941899 0.08862938]\n",
            " [0.08862938 0.09847709 0.10941899 0.04239116]\n",
            " [0.0717898  0.05814974 0.09847709 0.0717898 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.0717898  0.13508517 0.12157665 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.18530202 0.13508517 0.15009463]\n",
            " [0.12157665 0.10941899 0.13508517 0.13508517]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.12157665 0.13508517 0.12157665 0.15009463]\n",
            " [0.12157665 0.13508517 0.12157665 0.13508517]\n",
            " [0.13508517 0.10941899 0.13508517 0.12157665]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.59049    0.531441   0.47829688 0.47829688]\n",
            " [0.4304672  0.47829688 0.531441   0.729     ]\n",
            " [0.6561     0.729      0.47829688 0.81      ]\n",
            " [0.81       0.729      0.6561     0.9       ]\n",
            " [0.9        1.         0.81       0.9       ]\n",
            " [0.16677181 0.15009463 0.15009463 0.13508517]\n",
            " [0.13508517 0.13508517 0.13508517 0.22876792]\n",
            " [0.12157665 0.25418657 0.20589113 0.4304672 ]\n",
            " [0.38742048 0.38742048 0.25418657 0.4304672 ]\n",
            " [0.38742048 0.34867844 0.38742048 0.47829688]\n",
            " [0.47829688 0.38742048 0.47829688 0.38742048]\n",
            " [0.6561     0.729      0.47829688 0.81      ]\n",
            " [0.729      0.81       0.6561     0.9       ]\n",
            " [0.729      0.729      0.81       1.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Simple - Alternating.pkl')\n",
        "files.download('Mid - Alternating.pkl')\n",
        "files.download('Hard - Alternating.pkl')\n",
        "\n",
        "files.download('Rewards - Simple - Alternating.pkl')\n",
        "files.download('Rewards - Mid - Alternating.pkl')\n",
        "files.download('Rewards - Hard - Alternating.pkl')\n",
        "\n",
        "files.download('Time - Simple - Alternating.pkl')\n",
        "files.download('Time - Mid - Alternating.pkl')\n",
        "files.download('Time - Hard - Alternating.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vUP5r9NFqT1f",
        "outputId": "9e9ed37b-6192-4ded-8cb1-3703dccddbf8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9300ac15-d762-4e68-b1a6-20fd3f6c6c7b\", \"Simple - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4d49559-fc74-4d1c-83dc-69439cb66071\", \"Mid - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6240c317-1e83-4d53-bfe5-72b8a0e953e3\", \"Hard - Alternating.pkl\", 1752)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f18b2b34-f25d-4d10-a10b-1339ac667801\", \"Rewards - Simple - Alternating.pkl\", 90153)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ea4b6d9-62c5-49d0-b0ef-04529e0a17cd\", \"Rewards - Mid - Alternating.pkl\", 90153)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fce8e133-e2ce-43ee-b869-8eb0b1a20d5f\", \"Rewards - Hard - Alternating.pkl\", 85463)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2370ef0d-add1-4c59-a862-8fc0f7f30eab\", \"Time - Simple - Alternating.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36da0eaf-29a9-4b01-b655-6e0583f8f50a\", \"Time - Mid - Alternating.pkl\", 21)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_96bd6cb8-1b9f-4e6d-8c91-2d335846a846\", \"Time - Hard - Alternating.pkl\", 21)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Deep Q-Learning\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bhy-qxHIR45Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "36TWCaB8R8ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking availability of CUDA"
      ],
      "metadata": {
        "id": "c3GfUBB_Jhey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP8ku5ZJJpK_",
        "outputId": "61d7d2eb-b576-423d-c239-751fa7a83f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the neural network"
      ],
      "metadata": {
        "id": "zmF91Wy1KSP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepQNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(DeepQNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "xx6AEfJJKYW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the exploration-exploit function\n"
      ],
      "metadata": {
        "id": "CSA3fLnAlB8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_action_torch(environment, epsilon, policy_net):\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "        return np.random.choice(range(len(environment.action_space))) # Exploration\n",
        "\n",
        "    else:\n",
        "        current_state = torch.FloatTensor(environment.grid).unsqueeze(0)\n",
        "        q = policy_net(current_state)\n",
        "        return torch.argmax(q).item() # Exploit"
      ],
      "metadata": {
        "id": "XIhsEsI5lGFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the optimizing function\n"
      ],
      "metadata": {
        "id": "Mk0msX6Om8yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(memory, policy_net, target_net, gamma, optimizer, batch_size = 32):\n",
        "\n",
        "    if len(memory) < batch_size:\n",
        "        return\n",
        "\n",
        "    batch = random.sample(memory, batch_size)\n",
        "    state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
        "\n",
        "    state_batch = torch.FloatTensor(np.array(state_batch))\n",
        "    action_batch = torch.LongTensor(np.array(action_batch)).unsqueeze(1)\n",
        "    reward_batch = torch.FloatTensor(np.array(reward_batch))\n",
        "    next_state_batch = torch.FloatTensor(np.array(next_state_batch))\n",
        "    done_batch = torch.FloatTensor(np.array(done_batch))\n",
        "\n",
        "    # Compute Q-values for current states\n",
        "    q_values = policy_net(state_batch).gather(1, action_batch).squeeze()\n",
        "\n",
        "    # Compute target Q-values using the target network\n",
        "    with torch.no_grad():\n",
        "        max_next_q_values = target_net(next_state_batch).max(1)[0]\n",
        "        target_q_values = reward_batch + gamma * max_next_q_values * (1 - done_batch)\n",
        "\n",
        "    loss = nn.MSELoss()(q_values, target_q_values)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "sGvxmkdVm76A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Deep Q-Learning function"
      ],
      "metadata": {
        "id": "jEilwyivJrVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_q_learning(env, memory, policy_net, target_net, optimizer, alpha=0.01, gamma=0.9,  epsilon=1, epsilon_decay=0.005, target_update_freq = 400, episodes = 1000):\n",
        "\n",
        "    steps = 0\n",
        "    rewards = []\n",
        "\n",
        "    for e in range(episodes): #Run 1k training runs\n",
        "\n",
        "        state = env.reset() #Part of OpenAI where you need to reset at the start of each run\n",
        "        total_reward = 0 #Set initial reward to 0\n",
        "        step_per_episode = 0\n",
        "\n",
        "        while True: #Loop until done == True\n",
        "            #IF random number is less than epsilon grab the random action else grab the argument max of Q[state]\n",
        "\n",
        "            #current_state_index = env.current_pos[0] + env.current_pos[1]*env.observation_space[0] # Obtain the index of the state\n",
        "\n",
        "            current_state = np.copy(env.grid)\n",
        "\n",
        "            action = compute_action_torch(env, epsilon, policy_net) # Compute the action for the current state in function of the epsilon_greedy\n",
        "\n",
        "            posp1, new_state, reward, done = env.step(action)\n",
        "\n",
        "            #state_tp1_index = posp1[0] + posp1[1]*env.observation_space[0]\n",
        "\n",
        "            memory.append((current_state, action, reward, new_state, done))\n",
        "\n",
        "            total_reward += reward #Increment your reward\n",
        "\n",
        "            optimize(memory, policy_net, target_net, gamma, optimizer)\n",
        "\n",
        "            if steps % target_update_freq == 0:\n",
        "                target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                print(f\"Episode: {e}, Reward: {total_reward}, Steps in the episode: {step_per_episode}\")\n",
        "                break\n",
        "\n",
        "            steps += 1\n",
        "            step_per_episode += 1\n",
        "\n",
        "\n",
        "        if epsilon>0.1:\n",
        "            epsilon *= np.exp(-epsilon_decay)\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "    return rewards, steps"
      ],
      "metadata": {
        "id": "nuiIigURJqfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to save the weights of the policy_net and the target_net"
      ],
      "metadata": {
        "id": "aBmAU6Cro-Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_weights(filename, neural_net):\n",
        "    torch.save(neural_net.state_dict(), filename)"
      ],
      "metadata": {
        "id": "rSC-D-bbtv3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights(filename, blank_net):\n",
        "    blank_net.load_state_dict(torch.load(filename))"
      ],
      "metadata": {
        "id": "ogARufmHumjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the agent"
      ],
      "metadata": {
        "id": "zh97o3FTvXvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_net = DeepQNetwork(STATE_SIZE[0]*STATE_SIZE[1], 100, ACTION_SIZE)\n",
        "target_net = DeepQNetwork(STATE_SIZE[0]*STATE_SIZE[1], 100, ACTION_SIZE)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "learning_rate = 0.001\n",
        "memory_size = 300\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr = learning_rate)\n",
        "memory = deque(maxlen = memory_size)"
      ],
      "metadata": {
        "id": "ap4CE5jVvbXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running of the training"
      ],
      "metadata": {
        "id": "1SK1Fj59xU8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dql_simple = deep_q_learning(environment_simple, memory, policy_net, target_net, optimizer)\n",
        "#dql_mid = deep_q_learning(environment_mid, memory, policy_net, target_net, optimizer)\n",
        "#dql_hard = deep_q_learning(environment_hard, memory, policy_net, target_net, optimizer)"
      ],
      "metadata": {
        "id": "vzag5RVNxWXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c9362d-bbc3-4c63-c040-88e5dec44f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Reward: 1.0, Steps in the episode: 1342\n",
            "Episode: 1, Reward: 1.0, Steps in the episode: 262\n",
            "Episode: 2, Reward: 1.0, Steps in the episode: 90\n",
            "Episode: 3, Reward: 1.0, Steps in the episode: 349\n",
            "Episode: 4, Reward: 1.0, Steps in the episode: 1219\n",
            "Episode: 5, Reward: 1.0, Steps in the episode: 574\n",
            "Episode: 6, Reward: 1.0, Steps in the episode: 495\n",
            "Episode: 7, Reward: 1.0, Steps in the episode: 1049\n",
            "Episode: 8, Reward: 1.0, Steps in the episode: 1572\n",
            "Episode: 9, Reward: 1.0, Steps in the episode: 300\n",
            "Episode: 10, Reward: 1.0, Steps in the episode: 777\n",
            "Episode: 11, Reward: 1.0, Steps in the episode: 529\n",
            "Episode: 12, Reward: 1.0, Steps in the episode: 764\n",
            "Episode: 13, Reward: 1.0, Steps in the episode: 226\n",
            "Episode: 14, Reward: 1.0, Steps in the episode: 2435\n",
            "Episode: 15, Reward: 1.0, Steps in the episode: 451\n",
            "Episode: 16, Reward: 1.0, Steps in the episode: 294\n",
            "Episode: 17, Reward: 1.0, Steps in the episode: 153\n",
            "Episode: 18, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 19, Reward: 1.0, Steps in the episode: 523\n",
            "Episode: 20, Reward: 1.0, Steps in the episode: 218\n",
            "Episode: 21, Reward: 1.0, Steps in the episode: 452\n",
            "Episode: 22, Reward: 1.0, Steps in the episode: 137\n",
            "Episode: 23, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 24, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 25, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 26, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 27, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 28, Reward: 1.0, Steps in the episode: 829\n",
            "Episode: 29, Reward: 1.0, Steps in the episode: 805\n",
            "Episode: 30, Reward: 1.0, Steps in the episode: 542\n",
            "Episode: 31, Reward: 1.0, Steps in the episode: 576\n",
            "Episode: 32, Reward: 1.0, Steps in the episode: 781\n",
            "Episode: 33, Reward: 1.0, Steps in the episode: 515\n",
            "Episode: 34, Reward: 1.0, Steps in the episode: 183\n",
            "Episode: 35, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 36, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 37, Reward: 1.0, Steps in the episode: 292\n",
            "Episode: 38, Reward: 1.0, Steps in the episode: 183\n",
            "Episode: 39, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 40, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 41, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 42, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 43, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 44, Reward: 1.0, Steps in the episode: 474\n",
            "Episode: 45, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 46, Reward: 1.0, Steps in the episode: 485\n",
            "Episode: 47, Reward: 1.0, Steps in the episode: 59\n",
            "Episode: 48, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 49, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 50, Reward: 1.0, Steps in the episode: 216\n",
            "Episode: 51, Reward: 1.0, Steps in the episode: 114\n",
            "Episode: 52, Reward: 1.0, Steps in the episode: 414\n",
            "Episode: 53, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 54, Reward: 1.0, Steps in the episode: 119\n",
            "Episode: 55, Reward: 1.0, Steps in the episode: 117\n",
            "Episode: 56, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 57, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 58, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 59, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 60, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 61, Reward: 1.0, Steps in the episode: 103\n",
            "Episode: 62, Reward: 1.0, Steps in the episode: 282\n",
            "Episode: 63, Reward: 1.0, Steps in the episode: 268\n",
            "Episode: 64, Reward: 1.0, Steps in the episode: 447\n",
            "Episode: 65, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 66, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 67, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 68, Reward: 1.0, Steps in the episode: 168\n",
            "Episode: 69, Reward: 1.0, Steps in the episode: 186\n",
            "Episode: 70, Reward: 1.0, Steps in the episode: 303\n",
            "Episode: 71, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 72, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 73, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 74, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 75, Reward: 1.0, Steps in the episode: 77\n",
            "Episode: 76, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 77, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 78, Reward: 1.0, Steps in the episode: 79\n",
            "Episode: 79, Reward: 1.0, Steps in the episode: 350\n",
            "Episode: 80, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 81, Reward: 1.0, Steps in the episode: 98\n",
            "Episode: 82, Reward: 1.0, Steps in the episode: 196\n",
            "Episode: 83, Reward: 1.0, Steps in the episode: 49\n",
            "Episode: 84, Reward: 1.0, Steps in the episode: 256\n",
            "Episode: 85, Reward: 1.0, Steps in the episode: 344\n",
            "Episode: 86, Reward: 1.0, Steps in the episode: 223\n",
            "Episode: 87, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 88, Reward: 1.0, Steps in the episode: 105\n",
            "Episode: 89, Reward: 1.0, Steps in the episode: 614\n",
            "Episode: 90, Reward: 1.0, Steps in the episode: 189\n",
            "Episode: 91, Reward: 1.0, Steps in the episode: 81\n",
            "Episode: 92, Reward: 1.0, Steps in the episode: 188\n",
            "Episode: 93, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 94, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 95, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 96, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 97, Reward: 1.0, Steps in the episode: 136\n",
            "Episode: 98, Reward: 1.0, Steps in the episode: 236\n",
            "Episode: 99, Reward: 1.0, Steps in the episode: 179\n",
            "Episode: 100, Reward: 1.0, Steps in the episode: 264\n",
            "Episode: 101, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 102, Reward: 1.0, Steps in the episode: 30\n",
            "Episode: 103, Reward: 1.0, Steps in the episode: 232\n",
            "Episode: 104, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 105, Reward: 1.0, Steps in the episode: 158\n",
            "Episode: 106, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 107, Reward: 1.0, Steps in the episode: 49\n",
            "Episode: 108, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 109, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 110, Reward: 1.0, Steps in the episode: 160\n",
            "Episode: 111, Reward: 1.0, Steps in the episode: 141\n",
            "Episode: 112, Reward: 1.0, Steps in the episode: 163\n",
            "Episode: 113, Reward: 1.0, Steps in the episode: 81\n",
            "Episode: 114, Reward: 1.0, Steps in the episode: 381\n",
            "Episode: 115, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 116, Reward: 1.0, Steps in the episode: 136\n",
            "Episode: 117, Reward: 1.0, Steps in the episode: 180\n",
            "Episode: 118, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 119, Reward: 1.0, Steps in the episode: 570\n",
            "Episode: 120, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 121, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 122, Reward: 1.0, Steps in the episode: 62\n",
            "Episode: 123, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 124, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 125, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 126, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 127, Reward: 1.0, Steps in the episode: 113\n",
            "Episode: 128, Reward: 1.0, Steps in the episode: 57\n",
            "Episode: 129, Reward: 1.0, Steps in the episode: 74\n",
            "Episode: 130, Reward: 1.0, Steps in the episode: 27\n",
            "Episode: 131, Reward: 1.0, Steps in the episode: 354\n",
            "Episode: 132, Reward: 1.0, Steps in the episode: 344\n",
            "Episode: 133, Reward: 1.0, Steps in the episode: 477\n",
            "Episode: 134, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 135, Reward: 1.0, Steps in the episode: 97\n",
            "Episode: 136, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 137, Reward: 1.0, Steps in the episode: 135\n",
            "Episode: 138, Reward: 1.0, Steps in the episode: 161\n",
            "Episode: 139, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 140, Reward: 1.0, Steps in the episode: 663\n",
            "Episode: 141, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 142, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 143, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 144, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 145, Reward: 1.0, Steps in the episode: 22\n",
            "Episode: 146, Reward: 1.0, Steps in the episode: 685\n",
            "Episode: 147, Reward: 1.0, Steps in the episode: 46\n",
            "Episode: 148, Reward: 1.0, Steps in the episode: 358\n",
            "Episode: 149, Reward: 1.0, Steps in the episode: 321\n",
            "Episode: 150, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 151, Reward: 1.0, Steps in the episode: 184\n",
            "Episode: 152, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 153, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 154, Reward: 1.0, Steps in the episode: 118\n",
            "Episode: 155, Reward: 1.0, Steps in the episode: 119\n",
            "Episode: 156, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 157, Reward: 1.0, Steps in the episode: 208\n",
            "Episode: 158, Reward: 1.0, Steps in the episode: 163\n",
            "Episode: 159, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 160, Reward: 1.0, Steps in the episode: 331\n",
            "Episode: 161, Reward: 1.0, Steps in the episode: 175\n",
            "Episode: 162, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 163, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 164, Reward: 1.0, Steps in the episode: 379\n",
            "Episode: 165, Reward: 1.0, Steps in the episode: 461\n",
            "Episode: 166, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 167, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 168, Reward: 1.0, Steps in the episode: 96\n",
            "Episode: 169, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 170, Reward: 1.0, Steps in the episode: 245\n",
            "Episode: 171, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 172, Reward: 1.0, Steps in the episode: 155\n",
            "Episode: 173, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 174, Reward: 1.0, Steps in the episode: 154\n",
            "Episode: 175, Reward: 1.0, Steps in the episode: 157\n",
            "Episode: 176, Reward: 1.0, Steps in the episode: 644\n",
            "Episode: 177, Reward: 1.0, Steps in the episode: 266\n",
            "Episode: 178, Reward: 1.0, Steps in the episode: 24\n",
            "Episode: 179, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 180, Reward: 1.0, Steps in the episode: 68\n",
            "Episode: 181, Reward: 1.0, Steps in the episode: 754\n",
            "Episode: 182, Reward: 1.0, Steps in the episode: 591\n",
            "Episode: 183, Reward: 1.0, Steps in the episode: 294\n",
            "Episode: 184, Reward: 1.0, Steps in the episode: 27\n",
            "Episode: 185, Reward: 1.0, Steps in the episode: 154\n",
            "Episode: 186, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 187, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 188, Reward: 1.0, Steps in the episode: 166\n",
            "Episode: 189, Reward: 1.0, Steps in the episode: 373\n",
            "Episode: 190, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 191, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 192, Reward: 1.0, Steps in the episode: 144\n",
            "Episode: 193, Reward: 1.0, Steps in the episode: 124\n",
            "Episode: 194, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 195, Reward: 1.0, Steps in the episode: 185\n",
            "Episode: 196, Reward: 1.0, Steps in the episode: 93\n",
            "Episode: 197, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 198, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 199, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 200, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 201, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 202, Reward: 1.0, Steps in the episode: 142\n",
            "Episode: 203, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 204, Reward: 1.0, Steps in the episode: 87\n",
            "Episode: 205, Reward: 1.0, Steps in the episode: 309\n",
            "Episode: 206, Reward: 1.0, Steps in the episode: 68\n",
            "Episode: 207, Reward: 1.0, Steps in the episode: 327\n",
            "Episode: 208, Reward: 1.0, Steps in the episode: 253\n",
            "Episode: 209, Reward: 1.0, Steps in the episode: 415\n",
            "Episode: 210, Reward: 1.0, Steps in the episode: 785\n",
            "Episode: 211, Reward: 1.0, Steps in the episode: 277\n",
            "Episode: 212, Reward: 1.0, Steps in the episode: 72\n",
            "Episode: 213, Reward: 1.0, Steps in the episode: 204\n",
            "Episode: 214, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 215, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 216, Reward: 1.0, Steps in the episode: 197\n",
            "Episode: 217, Reward: 1.0, Steps in the episode: 275\n",
            "Episode: 218, Reward: 1.0, Steps in the episode: 212\n",
            "Episode: 219, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 220, Reward: 1.0, Steps in the episode: 201\n",
            "Episode: 221, Reward: 1.0, Steps in the episode: 935\n",
            "Episode: 222, Reward: 1.0, Steps in the episode: 347\n",
            "Episode: 223, Reward: 1.0, Steps in the episode: 350\n",
            "Episode: 224, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 225, Reward: 1.0, Steps in the episode: 375\n",
            "Episode: 226, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 227, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 228, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 229, Reward: 1.0, Steps in the episode: 199\n",
            "Episode: 230, Reward: 1.0, Steps in the episode: 121\n",
            "Episode: 231, Reward: 1.0, Steps in the episode: 46\n",
            "Episode: 232, Reward: 1.0, Steps in the episode: 641\n",
            "Episode: 233, Reward: 1.0, Steps in the episode: 35\n",
            "Episode: 234, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 235, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 236, Reward: 1.0, Steps in the episode: 131\n",
            "Episode: 237, Reward: 1.0, Steps in the episode: 153\n",
            "Episode: 238, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 239, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 240, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 241, Reward: 1.0, Steps in the episode: 182\n",
            "Episode: 242, Reward: 1.0, Steps in the episode: 211\n",
            "Episode: 243, Reward: 1.0, Steps in the episode: 544\n",
            "Episode: 244, Reward: 1.0, Steps in the episode: 406\n",
            "Episode: 245, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 246, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 247, Reward: 1.0, Steps in the episode: 152\n",
            "Episode: 248, Reward: 1.0, Steps in the episode: 113\n",
            "Episode: 249, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 250, Reward: 1.0, Steps in the episode: 251\n",
            "Episode: 251, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 252, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 253, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 254, Reward: 1.0, Steps in the episode: 61\n",
            "Episode: 255, Reward: 1.0, Steps in the episode: 337\n",
            "Episode: 256, Reward: 1.0, Steps in the episode: 369\n",
            "Episode: 257, Reward: 1.0, Steps in the episode: 338\n",
            "Episode: 258, Reward: 1.0, Steps in the episode: 186\n",
            "Episode: 259, Reward: 1.0, Steps in the episode: 72\n",
            "Episode: 260, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 261, Reward: 1.0, Steps in the episode: 358\n",
            "Episode: 262, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 263, Reward: 1.0, Steps in the episode: 111\n",
            "Episode: 264, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 265, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 266, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 267, Reward: 1.0, Steps in the episode: 123\n",
            "Episode: 268, Reward: 1.0, Steps in the episode: 242\n",
            "Episode: 269, Reward: 1.0, Steps in the episode: 156\n",
            "Episode: 270, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 271, Reward: 1.0, Steps in the episode: 371\n",
            "Episode: 272, Reward: 1.0, Steps in the episode: 1017\n",
            "Episode: 273, Reward: 1.0, Steps in the episode: 65\n",
            "Episode: 274, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 275, Reward: 1.0, Steps in the episode: 172\n",
            "Episode: 276, Reward: 1.0, Steps in the episode: 334\n",
            "Episode: 277, Reward: 1.0, Steps in the episode: 647\n",
            "Episode: 278, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 279, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 280, Reward: 1.0, Steps in the episode: 52\n",
            "Episode: 281, Reward: 1.0, Steps in the episode: 317\n",
            "Episode: 282, Reward: 1.0, Steps in the episode: 29\n",
            "Episode: 283, Reward: 1.0, Steps in the episode: 520\n",
            "Episode: 284, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 285, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 286, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 287, Reward: 1.0, Steps in the episode: 115\n",
            "Episode: 288, Reward: 1.0, Steps in the episode: 215\n",
            "Episode: 289, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 290, Reward: 1.0, Steps in the episode: 490\n",
            "Episode: 291, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 292, Reward: 1.0, Steps in the episode: 335\n",
            "Episode: 293, Reward: 1.0, Steps in the episode: 252\n",
            "Episode: 294, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 295, Reward: 1.0, Steps in the episode: 64\n",
            "Episode: 296, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 297, Reward: 1.0, Steps in the episode: 132\n",
            "Episode: 298, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 299, Reward: 1.0, Steps in the episode: 52\n",
            "Episode: 300, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 301, Reward: 1.0, Steps in the episode: 280\n",
            "Episode: 302, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 303, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 304, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 305, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 306, Reward: 1.0, Steps in the episode: 1141\n",
            "Episode: 307, Reward: 1.0, Steps in the episode: 359\n",
            "Episode: 308, Reward: 1.0, Steps in the episode: 224\n",
            "Episode: 309, Reward: 1.0, Steps in the episode: 231\n",
            "Episode: 310, Reward: 1.0, Steps in the episode: 288\n",
            "Episode: 311, Reward: 1.0, Steps in the episode: 169\n",
            "Episode: 312, Reward: 1.0, Steps in the episode: 209\n",
            "Episode: 313, Reward: 1.0, Steps in the episode: 84\n",
            "Episode: 314, Reward: 1.0, Steps in the episode: 107\n",
            "Episode: 315, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 316, Reward: 1.0, Steps in the episode: 255\n",
            "Episode: 317, Reward: 1.0, Steps in the episode: 280\n",
            "Episode: 318, Reward: 1.0, Steps in the episode: 337\n",
            "Episode: 319, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 320, Reward: 1.0, Steps in the episode: 121\n",
            "Episode: 321, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 322, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 323, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 324, Reward: 1.0, Steps in the episode: 104\n",
            "Episode: 325, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 326, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 327, Reward: 1.0, Steps in the episode: 313\n",
            "Episode: 328, Reward: 1.0, Steps in the episode: 790\n",
            "Episode: 329, Reward: 1.0, Steps in the episode: 212\n",
            "Episode: 330, Reward: 1.0, Steps in the episode: 92\n",
            "Episode: 331, Reward: 1.0, Steps in the episode: 117\n",
            "Episode: 332, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 333, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 334, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 335, Reward: 1.0, Steps in the episode: 56\n",
            "Episode: 336, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 337, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 338, Reward: 1.0, Steps in the episode: 228\n",
            "Episode: 339, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 340, Reward: 1.0, Steps in the episode: 40\n",
            "Episode: 341, Reward: 1.0, Steps in the episode: 159\n",
            "Episode: 342, Reward: 1.0, Steps in the episode: 33\n",
            "Episode: 343, Reward: 1.0, Steps in the episode: 94\n",
            "Episode: 344, Reward: 1.0, Steps in the episode: 100\n",
            "Episode: 345, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 346, Reward: 1.0, Steps in the episode: 60\n",
            "Episode: 347, Reward: 1.0, Steps in the episode: 139\n",
            "Episode: 348, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 349, Reward: 1.0, Steps in the episode: 58\n",
            "Episode: 350, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 351, Reward: 1.0, Steps in the episode: 507\n",
            "Episode: 352, Reward: 1.0, Steps in the episode: 131\n",
            "Episode: 353, Reward: 1.0, Steps in the episode: 51\n",
            "Episode: 354, Reward: 1.0, Steps in the episode: 672\n",
            "Episode: 355, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 356, Reward: 1.0, Steps in the episode: 482\n",
            "Episode: 357, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 358, Reward: 1.0, Steps in the episode: 26\n",
            "Episode: 359, Reward: 1.0, Steps in the episode: 402\n",
            "Episode: 360, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 361, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 362, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 363, Reward: 1.0, Steps in the episode: 576\n",
            "Episode: 364, Reward: 1.0, Steps in the episode: 416\n",
            "Episode: 365, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 366, Reward: 1.0, Steps in the episode: 129\n",
            "Episode: 367, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 368, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 369, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 370, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 371, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 372, Reward: 1.0, Steps in the episode: 106\n",
            "Episode: 373, Reward: 1.0, Steps in the episode: 167\n",
            "Episode: 374, Reward: 1.0, Steps in the episode: 37\n",
            "Episode: 375, Reward: 1.0, Steps in the episode: 1219\n",
            "Episode: 376, Reward: 1.0, Steps in the episode: 783\n",
            "Episode: 377, Reward: 1.0, Steps in the episode: 333\n",
            "Episode: 378, Reward: 1.0, Steps in the episode: 285\n",
            "Episode: 379, Reward: 1.0, Steps in the episode: 55\n",
            "Episode: 380, Reward: 1.0, Steps in the episode: 244\n",
            "Episode: 381, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 382, Reward: 1.0, Steps in the episode: 34\n",
            "Episode: 383, Reward: 1.0, Steps in the episode: 102\n",
            "Episode: 384, Reward: 1.0, Steps in the episode: 97\n",
            "Episode: 385, Reward: 1.0, Steps in the episode: 31\n",
            "Episode: 386, Reward: 1.0, Steps in the episode: 764\n",
            "Episode: 387, Reward: 1.0, Steps in the episode: 743\n",
            "Episode: 388, Reward: 1.0, Steps in the episode: 306\n",
            "Episode: 389, Reward: 1.0, Steps in the episode: 500\n",
            "Episode: 390, Reward: 1.0, Steps in the episode: 314\n",
            "Episode: 391, Reward: 1.0, Steps in the episode: 302\n",
            "Episode: 392, Reward: 1.0, Steps in the episode: 226\n",
            "Episode: 393, Reward: 1.0, Steps in the episode: 216\n",
            "Episode: 394, Reward: 1.0, Steps in the episode: 217\n",
            "Episode: 395, Reward: 1.0, Steps in the episode: 366\n",
            "Episode: 396, Reward: 1.0, Steps in the episode: 600\n",
            "Episode: 397, Reward: 1.0, Steps in the episode: 347\n",
            "Episode: 398, Reward: 1.0, Steps in the episode: 359\n",
            "Episode: 399, Reward: 1.0, Steps in the episode: 388\n",
            "Episode: 400, Reward: 1.0, Steps in the episode: 325\n",
            "Episode: 401, Reward: 1.0, Steps in the episode: 335\n",
            "Episode: 402, Reward: 1.0, Steps in the episode: 1052\n",
            "Episode: 403, Reward: 1.0, Steps in the episode: 293\n",
            "Episode: 404, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 405, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 406, Reward: 1.0, Steps in the episode: 295\n",
            "Episode: 407, Reward: 1.0, Steps in the episode: 150\n",
            "Episode: 408, Reward: 1.0, Steps in the episode: 214\n",
            "Episode: 409, Reward: 1.0, Steps in the episode: 187\n",
            "Episode: 410, Reward: 1.0, Steps in the episode: 91\n",
            "Episode: 411, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 412, Reward: 1.0, Steps in the episode: 50\n",
            "Episode: 413, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 414, Reward: 1.0, Steps in the episode: 144\n",
            "Episode: 415, Reward: 1.0, Steps in the episode: 76\n",
            "Episode: 416, Reward: 1.0, Steps in the episode: 336\n",
            "Episode: 417, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 418, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 419, Reward: 1.0, Steps in the episode: 281\n",
            "Episode: 420, Reward: 1.0, Steps in the episode: 18\n",
            "Episode: 421, Reward: 1.0, Steps in the episode: 774\n",
            "Episode: 422, Reward: 1.0, Steps in the episode: 826\n",
            "Episode: 423, Reward: 1.0, Steps in the episode: 555\n",
            "Episode: 424, Reward: 1.0, Steps in the episode: 341\n",
            "Episode: 425, Reward: 1.0, Steps in the episode: 449\n",
            "Episode: 426, Reward: 1.0, Steps in the episode: 274\n",
            "Episode: 427, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 428, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 429, Reward: 1.0, Steps in the episode: 134\n",
            "Episode: 430, Reward: 1.0, Steps in the episode: 79\n",
            "Episode: 431, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 432, Reward: 1.0, Steps in the episode: 35\n",
            "Episode: 433, Reward: 1.0, Steps in the episode: 77\n",
            "Episode: 434, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 435, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 436, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 437, Reward: 1.0, Steps in the episode: 660\n",
            "Episode: 438, Reward: 1.0, Steps in the episode: 667\n",
            "Episode: 439, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 440, Reward: 1.0, Steps in the episode: 274\n",
            "Episode: 441, Reward: 1.0, Steps in the episode: 248\n",
            "Episode: 442, Reward: 1.0, Steps in the episode: 66\n",
            "Episode: 443, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 444, Reward: 1.0, Steps in the episode: 299\n",
            "Episode: 445, Reward: 1.0, Steps in the episode: 109\n",
            "Episode: 446, Reward: 1.0, Steps in the episode: 145\n",
            "Episode: 447, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 448, Reward: 1.0, Steps in the episode: 130\n",
            "Episode: 449, Reward: 1.0, Steps in the episode: 366\n",
            "Episode: 450, Reward: 1.0, Steps in the episode: 318\n",
            "Episode: 451, Reward: 1.0, Steps in the episode: 879\n",
            "Episode: 452, Reward: 1.0, Steps in the episode: 1233\n",
            "Episode: 453, Reward: 1.0, Steps in the episode: 179\n",
            "Episode: 454, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 455, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 456, Reward: 1.0, Steps in the episode: 140\n",
            "Episode: 457, Reward: 1.0, Steps in the episode: 160\n",
            "Episode: 458, Reward: 1.0, Steps in the episode: 41\n",
            "Episode: 459, Reward: 1.0, Steps in the episode: 86\n",
            "Episode: 460, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 461, Reward: 1.0, Steps in the episode: 307\n",
            "Episode: 462, Reward: 1.0, Steps in the episode: 319\n",
            "Episode: 463, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 464, Reward: 1.0, Steps in the episode: 306\n",
            "Episode: 465, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 466, Reward: 1.0, Steps in the episode: 386\n",
            "Episode: 467, Reward: 1.0, Steps in the episode: 1199\n",
            "Episode: 468, Reward: 1.0, Steps in the episode: 400\n",
            "Episode: 469, Reward: 1.0, Steps in the episode: 1407\n",
            "Episode: 470, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 471, Reward: 1.0, Steps in the episode: 42\n",
            "Episode: 472, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 473, Reward: 1.0, Steps in the episode: 30\n",
            "Episode: 474, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 475, Reward: 1.0, Steps in the episode: 39\n",
            "Episode: 476, Reward: 1.0, Steps in the episode: 177\n",
            "Episode: 477, Reward: 1.0, Steps in the episode: 550\n",
            "Episode: 478, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 479, Reward: 1.0, Steps in the episode: 461\n",
            "Episode: 480, Reward: 1.0, Steps in the episode: 744\n",
            "Episode: 481, Reward: 1.0, Steps in the episode: 353\n",
            "Episode: 482, Reward: 1.0, Steps in the episode: 162\n",
            "Episode: 483, Reward: 1.0, Steps in the episode: 688\n",
            "Episode: 484, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 485, Reward: 1.0, Steps in the episode: 69\n",
            "Episode: 486, Reward: 1.0, Steps in the episode: 135\n",
            "Episode: 487, Reward: 1.0, Steps in the episode: 83\n",
            "Episode: 488, Reward: 1.0, Steps in the episode: 1000\n",
            "Episode: 489, Reward: 1.0, Steps in the episode: 814\n",
            "Episode: 490, Reward: 1.0, Steps in the episode: 389\n",
            "Episode: 491, Reward: 1.0, Steps in the episode: 247\n",
            "Episode: 492, Reward: 1.0, Steps in the episode: 355\n",
            "Episode: 493, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 494, Reward: 1.0, Steps in the episode: 75\n",
            "Episode: 495, Reward: 1.0, Steps in the episode: 48\n",
            "Episode: 496, Reward: 1.0, Steps in the episode: 233\n",
            "Episode: 497, Reward: 1.0, Steps in the episode: 621\n",
            "Episode: 498, Reward: 1.0, Steps in the episode: 767\n",
            "Episode: 499, Reward: 1.0, Steps in the episode: 234\n",
            "Episode: 500, Reward: 1.0, Steps in the episode: 554\n",
            "Episode: 501, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 502, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 503, Reward: 1.0, Steps in the episode: 864\n",
            "Episode: 504, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 505, Reward: 1.0, Steps in the episode: 290\n",
            "Episode: 506, Reward: 1.0, Steps in the episode: 225\n",
            "Episode: 507, Reward: 1.0, Steps in the episode: 450\n",
            "Episode: 508, Reward: 1.0, Steps in the episode: 174\n",
            "Episode: 509, Reward: 1.0, Steps in the episode: 612\n",
            "Episode: 510, Reward: 1.0, Steps in the episode: 322\n",
            "Episode: 511, Reward: 1.0, Steps in the episode: 479\n",
            "Episode: 512, Reward: 1.0, Steps in the episode: 398\n",
            "Episode: 513, Reward: 1.0, Steps in the episode: 403\n",
            "Episode: 514, Reward: 1.0, Steps in the episode: 1598\n",
            "Episode: 515, Reward: 1.0, Steps in the episode: 310\n",
            "Episode: 516, Reward: 1.0, Steps in the episode: 488\n",
            "Episode: 517, Reward: 1.0, Steps in the episode: 1202\n",
            "Episode: 518, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 519, Reward: 1.0, Steps in the episode: 475\n",
            "Episode: 520, Reward: 1.0, Steps in the episode: 474\n",
            "Episode: 521, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 522, Reward: 1.0, Steps in the episode: 320\n",
            "Episode: 523, Reward: 1.0, Steps in the episode: 247\n",
            "Episode: 524, Reward: 1.0, Steps in the episode: 123\n",
            "Episode: 525, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 526, Reward: 1.0, Steps in the episode: 108\n",
            "Episode: 527, Reward: 1.0, Steps in the episode: 23\n",
            "Episode: 528, Reward: 1.0, Steps in the episode: 88\n",
            "Episode: 529, Reward: 1.0, Steps in the episode: 185\n",
            "Episode: 530, Reward: 1.0, Steps in the episode: 71\n",
            "Episode: 531, Reward: 1.0, Steps in the episode: 195\n",
            "Episode: 532, Reward: 1.0, Steps in the episode: 708\n",
            "Episode: 533, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 534, Reward: 1.0, Steps in the episode: 383\n",
            "Episode: 535, Reward: 1.0, Steps in the episode: 662\n",
            "Episode: 536, Reward: 1.0, Steps in the episode: 360\n",
            "Episode: 537, Reward: 1.0, Steps in the episode: 90\n",
            "Episode: 538, Reward: 1.0, Steps in the episode: 88\n",
            "Episode: 539, Reward: 1.0, Steps in the episode: 64\n",
            "Episode: 540, Reward: 1.0, Steps in the episode: 152\n",
            "Episode: 541, Reward: 1.0, Steps in the episode: 130\n",
            "Episode: 542, Reward: 1.0, Steps in the episode: 853\n",
            "Episode: 543, Reward: 1.0, Steps in the episode: 631\n",
            "Episode: 544, Reward: 1.0, Steps in the episode: 170\n",
            "Episode: 545, Reward: 1.0, Steps in the episode: 38\n",
            "Episode: 546, Reward: 1.0, Steps in the episode: 70\n",
            "Episode: 547, Reward: 1.0, Steps in the episode: 58\n",
            "Episode: 548, Reward: 1.0, Steps in the episode: 633\n",
            "Episode: 549, Reward: 1.0, Steps in the episode: 199\n",
            "Episode: 550, Reward: 1.0, Steps in the episode: 89\n",
            "Episode: 551, Reward: 1.0, Steps in the episode: 53\n",
            "Episode: 552, Reward: 1.0, Steps in the episode: 456\n",
            "Episode: 553, Reward: 1.0, Steps in the episode: 411\n",
            "Episode: 554, Reward: 1.0, Steps in the episode: 44\n",
            "Episode: 555, Reward: 1.0, Steps in the episode: 747\n",
            "Episode: 556, Reward: 1.0, Steps in the episode: 209\n",
            "Episode: 557, Reward: 1.0, Steps in the episode: 219\n",
            "Episode: 558, Reward: 1.0, Steps in the episode: 45\n",
            "Episode: 559, Reward: 1.0, Steps in the episode: 331\n",
            "Episode: 560, Reward: 1.0, Steps in the episode: 796\n",
            "Episode: 561, Reward: 1.0, Steps in the episode: 246\n",
            "Episode: 562, Reward: 1.0, Steps in the episode: 724\n",
            "Episode: 563, Reward: 1.0, Steps in the episode: 281\n",
            "Episode: 564, Reward: 1.0, Steps in the episode: 255\n",
            "Episode: 565, Reward: 1.0, Steps in the episode: 222\n",
            "Episode: 566, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 567, Reward: 1.0, Steps in the episode: 2255\n",
            "Episode: 568, Reward: 1.0, Steps in the episode: 450\n",
            "Episode: 569, Reward: 1.0, Steps in the episode: 1147\n",
            "Episode: 570, Reward: 1.0, Steps in the episode: 423\n",
            "Episode: 571, Reward: 1.0, Steps in the episode: 150\n",
            "Episode: 572, Reward: 1.0, Steps in the episode: 96\n",
            "Episode: 573, Reward: 1.0, Steps in the episode: 329\n",
            "Episode: 574, Reward: 1.0, Steps in the episode: 605\n",
            "Episode: 575, Reward: 1.0, Steps in the episode: 1196\n",
            "Episode: 576, Reward: 1.0, Steps in the episode: 1981\n",
            "Episode: 577, Reward: 1.0, Steps in the episode: 816\n",
            "Episode: 578, Reward: 1.0, Steps in the episode: 636\n",
            "Episode: 579, Reward: 1.0, Steps in the episode: 327\n",
            "Episode: 580, Reward: 1.0, Steps in the episode: 1042\n",
            "Episode: 581, Reward: 1.0, Steps in the episode: 339\n",
            "Episode: 582, Reward: 1.0, Steps in the episode: 383\n",
            "Episode: 583, Reward: 1.0, Steps in the episode: 128\n",
            "Episode: 584, Reward: 1.0, Steps in the episode: 59\n",
            "Episode: 585, Reward: 1.0, Steps in the episode: 36\n",
            "Episode: 586, Reward: 1.0, Steps in the episode: 43\n",
            "Episode: 587, Reward: 1.0, Steps in the episode: 78\n",
            "Episode: 588, Reward: 1.0, Steps in the episode: 203\n",
            "Episode: 589, Reward: 1.0, Steps in the episode: 93\n",
            "Episode: 590, Reward: 1.0, Steps in the episode: 230\n",
            "Episode: 591, Reward: 1.0, Steps in the episode: 406\n",
            "Episode: 592, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 593, Reward: 1.0, Steps in the episode: 352\n",
            "Episode: 594, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 595, Reward: 1.0, Steps in the episode: 145\n",
            "Episode: 596, Reward: 1.0, Steps in the episode: 1061\n",
            "Episode: 597, Reward: 1.0, Steps in the episode: 323\n",
            "Episode: 598, Reward: 1.0, Steps in the episode: 499\n",
            "Episode: 599, Reward: 1.0, Steps in the episode: 125\n",
            "Episode: 600, Reward: 1.0, Steps in the episode: 18\n",
            "Episode: 601, Reward: 1.0, Steps in the episode: 122\n",
            "Episode: 602, Reward: 1.0, Steps in the episode: 515\n",
            "Episode: 603, Reward: 1.0, Steps in the episode: 151\n",
            "Episode: 604, Reward: 1.0, Steps in the episode: 147\n",
            "Episode: 605, Reward: 1.0, Steps in the episode: 304\n",
            "Episode: 606, Reward: 1.0, Steps in the episode: 332\n",
            "Episode: 607, Reward: 1.0, Steps in the episode: 324\n",
            "Episode: 608, Reward: 1.0, Steps in the episode: 343\n",
            "Episode: 609, Reward: 1.0, Steps in the episode: 1196\n",
            "Episode: 610, Reward: 1.0, Steps in the episode: 317\n",
            "Episode: 611, Reward: 1.0, Steps in the episode: 563\n",
            "Episode: 612, Reward: 1.0, Steps in the episode: 275\n",
            "Episode: 613, Reward: 1.0, Steps in the episode: 633\n",
            "Episode: 614, Reward: 1.0, Steps in the episode: 328\n",
            "Episode: 615, Reward: 1.0, Steps in the episode: 257\n",
            "Episode: 616, Reward: 1.0, Steps in the episode: 54\n",
            "Episode: 617, Reward: 1.0, Steps in the episode: 320\n",
            "Episode: 618, Reward: 1.0, Steps in the episode: 326\n",
            "Episode: 619, Reward: 1.0, Steps in the episode: 775\n",
            "Episode: 620, Reward: 1.0, Steps in the episode: 554\n",
            "Episode: 621, Reward: 1.0, Steps in the episode: 439\n",
            "Episode: 622, Reward: 1.0, Steps in the episode: 262\n",
            "Episode: 623, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 624, Reward: 1.0, Steps in the episode: 63\n",
            "Episode: 625, Reward: 1.0, Steps in the episode: 114\n",
            "Episode: 626, Reward: 1.0, Steps in the episode: 116\n",
            "Episode: 627, Reward: 1.0, Steps in the episode: 161\n",
            "Episode: 628, Reward: 1.0, Steps in the episode: 67\n",
            "Episode: 629, Reward: 1.0, Steps in the episode: 299\n",
            "Episode: 630, Reward: 1.0, Steps in the episode: 654\n",
            "Episode: 631, Reward: 1.0, Steps in the episode: 303\n",
            "Episode: 632, Reward: 1.0, Steps in the episode: 178\n",
            "Episode: 633, Reward: 1.0, Steps in the episode: 23\n",
            "Episode: 634, Reward: 1.0, Steps in the episode: 605\n",
            "Episode: 635, Reward: 1.0, Steps in the episode: 400\n",
            "Episode: 636, Reward: 1.0, Steps in the episode: 631\n",
            "Episode: 637, Reward: 1.0, Steps in the episode: 159\n",
            "Episode: 638, Reward: 1.0, Steps in the episode: 22\n",
            "Episode: 639, Reward: 1.0, Steps in the episode: 305\n",
            "Episode: 640, Reward: 1.0, Steps in the episode: 315\n",
            "Episode: 641, Reward: 1.0, Steps in the episode: 224\n",
            "Episode: 642, Reward: 1.0, Steps in the episode: 741\n",
            "Episode: 643, Reward: 1.0, Steps in the episode: 319\n",
            "Episode: 644, Reward: 1.0, Steps in the episode: 727\n",
            "Episode: 645, Reward: 1.0, Steps in the episode: 581\n",
            "Episode: 646, Reward: 1.0, Steps in the episode: 32\n",
            "Episode: 647, Reward: 1.0, Steps in the episode: 349\n",
            "Episode: 648, Reward: 1.0, Steps in the episode: 21\n",
            "Episode: 649, Reward: 1.0, Steps in the episode: 329\n",
            "Episode: 650, Reward: 1.0, Steps in the episode: 258\n",
            "Episode: 651, Reward: 1.0, Steps in the episode: 599\n",
            "Episode: 652, Reward: 1.0, Steps in the episode: 85\n",
            "Episode: 653, Reward: 1.0, Steps in the episode: 251\n",
            "Episode: 654, Reward: 1.0, Steps in the episode: 851\n",
            "Episode: 655, Reward: 1.0, Steps in the episode: 877\n",
            "Episode: 656, Reward: 1.0, Steps in the episode: 446\n",
            "Episode: 657, Reward: 1.0, Steps in the episode: 316\n",
            "Episode: 658, Reward: 1.0, Steps in the episode: 1562\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6e21233bf3d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdql_simple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_q_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dql_mid = deep_q_learning(environment_mid, memory, policy_net, target_net, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dql_hard = deep_q_learning(environment_hard, memory, policy_net, target_net, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-3dabd1928bbb>\u001b[0m in \u001b[0;36mdeep_q_learning\u001b[0;34m(env, memory, policy_net, target_net, optimizer, alpha, gamma, epsilon, epsilon_decay, target_update_freq, episodes)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;31m#Increment your reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtarget_update_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-80112b421041>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(memory, policy_net, target_net, gamma, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Spatial Computing for Path Planning - SCPP - Personalized algorithm\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2F69AEnJR85v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tqdk5DiyG2Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking availability of CUDA"
      ],
      "metadata": {
        "id": "JZ0LGCpfIltd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63O6X_KHIlZs",
        "outputId": "bb694669-21ec-471d-fe9f-a19d0e41a464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the neural network"
      ],
      "metadata": {
        "id": "TluBOVXiG2tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralAgent(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralAgent, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2W0_1r92HzDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute the input tensor during training"
      ],
      "metadata": {
        "id": "H4hTNDcOIYXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_input_tensor(env):\n",
        "    # Get the dimensions of the grid\n",
        "    height, width = env.observation_space\n",
        "\n",
        "    # Get the agent's position\n",
        "    x, y = env.current_pos\n",
        "\n",
        "    # Initialize the input tensor with zeros\n",
        "    input_tensor = np.zeros(6)\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the left direction\n",
        "    for i in range(x-1, -1, -1):\n",
        "        if env.grid[i, y] == 1:\n",
        "            input_tensor[0] = x - i\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the right direction\n",
        "    for i in range(x+1, height):\n",
        "        if env.grid[i, y] == 1:\n",
        "            input_tensor[1] = i - x\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the up direction\n",
        "    for j in range(y-1, -1, -1):\n",
        "        if env.grid[x, j] == 1:\n",
        "            input_tensor[2] = y - j\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the nearest obstacle in the down direction\n",
        "    for j in range(y+1, width):\n",
        "        if env.grid[x, j] == 1:\n",
        "            input_tensor[3] = j - y\n",
        "            break\n",
        "\n",
        "    # Calculate the distance to the goal in the horizontal direction\n",
        "    goal_position = np.argwhere(env.grid == 2)[0]\n",
        "    input_tensor[4] = goal_position[1] - y\n",
        "\n",
        "    # Calculate the distance to the goal in the vertical direction\n",
        "    input_tensor[5] = goal_position[0] - x\n",
        "\n",
        "    # Convert the input tensor to a PyTorch tensor\n",
        "    input_tensor = torch.tensor(input_tensor, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    return input_tensor"
      ],
      "metadata": {
        "id": "jz9K3bMWIX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of the training"
      ],
      "metadata": {
        "id": "j1CH12riHz1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scpp(agent, env, num_episodes, criterion, optimizer):\n",
        "    # Train the agent for a specified number of episodes\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset the environment\n",
        "        state = env.reset()\n",
        "\n",
        "        # Initialize the episode reward\n",
        "        episode_reward = 0\n",
        "\n",
        "        # Loop through the episode\n",
        "        while True:\n",
        "            # Convert the state to a PyTorch tensor\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            # Forward pass\n",
        "            action_probs = agent(state_tensor)\n",
        "\n",
        "            # Sample an action from the action probabilities\n",
        "            action = torch.multinomial(action_probs, num_samples=1).item()\n",
        "\n",
        "            # Take the action and observe the next state and reward\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # Update the episode reward\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Convert the next state to a PyTorch tensor\n",
        "            next_state_tensor = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            # Calculate the target tensor\n",
        "            with torch.no_grad():\n",
        "                next_action_probs = agent(next_state_tensor)\n",
        "                target = reward + 0.99 * torch.max(next_action_probs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(action_probs[0, action], target)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the state\n",
        "            state = next_state\n",
        "\n",
        "            # Check if the episode is done\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Print the episode reward every 100 episodes\n",
        "        if (episode + 1) % 100 == 0:\n",
        "            print(f'Episode [{episode+1}/{num_episodes}], Episode Reward: {episode_reward:.2f}')"
      ],
      "metadata": {
        "id": "KSyym_qEH3w0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}